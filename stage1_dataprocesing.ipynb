{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n",
      "\n",
      "================================================================================\n",
      "STEP 1: MOVIE TEXT FEATURE EXTRACTION\n",
      "================================================================================\n",
      "Loaded 15597 movies from MovieLens dataset\n",
      "   movieId                    title  \\\n",
      "0        1         Toy Story (1995)   \n",
      "1        2           Jumanji (1995)   \n",
      "2        3  Grumpier Old Men (1995)   \n",
      "\n",
      "                                        genres  \n",
      "0  Adventure|Animation|Children|Comedy|Fantasy  \n",
      "1                   Adventure|Children|Fantasy  \n",
      "2                               Comedy|Romance  \n",
      "\n",
      "Loaded 1069382 movies from TMDB dataset\n",
      "   id           tmdb_title                                           overview\n",
      "0   2                Ariel  A Finnish man goes to the city to find a job a...\n",
      "1   3  Shadows in Paradise  Nikander, a rubbish collector and would-be ent...\n",
      "2   5           Four Rooms  It's Ted the Bellhop's first night on the job....\n",
      "\n",
      "Loaded 15597 movie links\n",
      "   movieId  imdbId   tmdbId\n",
      "0        1  114709    862.0\n",
      "1        2  113497   8844.0\n",
      "2        3  113228  15602.0\n",
      "\n",
      "Loaded 38735 movie tags\n",
      "   userId  movieId          tag            timestamp\n",
      "0      18     4141  Mark Waters  2009-04-24 18:19:40\n",
      "1      65      208    dark hero  2013-05-10 01:41:18\n",
      "2      65      353    dark hero  2013-05-10 01:41:19\n",
      "\n",
      "Sample movie text corpus:\n",
      "Movie: Toy Story (1995)\n",
      "Text corpus: Toy Story (1995) Led by Woody, Andy's toys live happily in his room until Andy's birthday brings Buzz Lightyear onto the scene. Afraid of losing his place in Andy's heart, Woody plots against Buzz. But when circumstances separate Buzz and Woody from their owner, the duo eventually learns to put asid...\n",
      "\n",
      "Created text corpus for 15597 movies\n",
      "   movieId                    title  \\\n",
      "0        1         Toy Story (1995)   \n",
      "1        2           Jumanji (1995)   \n",
      "2        3  Grumpier Old Men (1995)   \n",
      "\n",
      "                                         text_corpus  \n",
      "0  Toy Story (1995) Led by Woody, Andy's toys liv...  \n",
      "1  Jumanji (1995) When siblings Judy and Peter di...  \n",
      "2  Grumpier Old Men (1995) A family wedding reign...  \n",
      "\n",
      "================================================================================\n",
      "STEP 2: TEXT PREPROCESSING\n",
      "================================================================================\n",
      "Cleaning and tokenizing text corpus...\n",
      "\n",
      "Sample of preprocessed text:\n",
      "Movie: Toy Story (1995)\n",
      "Original text: Toy Story (1995) Led by Woody, Andy's toys live happily in his room until Andy's birthday brings Buz...\n",
      "Cleaned text: toy_story led by woody andy s toys live happily in his room until andy s birthday brings buzz_lighty...\n",
      "Tokens: ['toy story', 'led', 'woody', 'andy', 'toy', 'live', 'happily', 'room', 'andy', 'birthday', 'brings', 'buzz lightyear', 'onto', 'scene', 'afraid', 'losing', 'place', 'andy', 'heart', 'woody']...\n",
      "\n",
      "Vocabulary size: 56636 unique words\n",
      "Top 20 most common words: [('life', 3552), ('find', 2317), ('one', 2158), ('young', 2116), ('year', 1952), ('man', 1919), ('family', 1790), ('woman', 1765), ('love', 1747), ('two', 1674), ('friend', 1660), ('story', 1598), ('get', 1457), ('time', 1438), ('take', 1412), ('world', 1350), ('new', 1254), ('film', 1234), ('old', 1221), ('father', 1207)]\n",
      "\n",
      "Document frequency of top words:\n",
      "'life' appears in 2969 documents\n",
      "'find' appears in 2113 documents\n",
      "'young' appears in 1989 documents\n",
      "'one' appears in 1893 documents\n",
      "'year' appears in 1750 documents\n",
      "'man' appears in 1696 documents\n",
      "'woman' appears in 1546 documents\n",
      "'two' appears in 1531 documents\n",
      "'love' appears in 1501 documents\n",
      "'friend' appears in 1500 documents\n",
      "\n",
      "Preprocessed movie text data:\n",
      "   movieId                    title  \\\n",
      "0        1         Toy Story (1995)   \n",
      "1        2           Jumanji (1995)   \n",
      "2        3  Grumpier Old Men (1995)   \n",
      "\n",
      "                                              tokens  \n",
      "0  [toy story, led, woody, andy, toy, live, happi...  \n",
      "1  [jumanji, sibling, judy, peter, discover, ench...  \n",
      "2  [grumpier old men, family, wedding, reignites,...  \n",
      "\n",
      "Token distribution plot saved as 'token_distribution.png'\n",
      "\n",
      "================================================================================\n",
      "STEP 3: DATA NORMALIZATION\n",
      "================================================================================\n",
      "Loaded 1476401 ratings from 10000 users\n",
      "   userId  movieId  rating            timestamp\n",
      "0       1        2     3.5  2005-04-02 23:53:47\n",
      "1       1       29     3.5  2005-04-02 23:31:16\n",
      "2       1       32     3.5  2005-04-02 23:33:39\n",
      "3       1       47     3.5  2005-04-02 23:32:07\n",
      "4       1       50     3.5  2005-04-02 23:29:40\n",
      "\n",
      "User rating statistics:\n",
      "   userId  rating_count  rating_mean  rating_std\n",
      "0       1           175     3.742857    0.382284\n",
      "1       2            61     4.000000    1.064581\n",
      "2       3           187     4.122995    0.910427\n",
      "3       4            28     3.571429    0.790151\n",
      "4       5            66     4.272727    0.969464\n",
      "\n",
      "User rating statistics plot saved as 'user_rating_stats.png'\n",
      "\n",
      "Normalizing ratings...\n",
      "\n",
      "Original vs. Normalized ratings:\n",
      "   userId  movieId  rating  normalized_rating\n",
      "0       1        2     3.5           0.666667\n",
      "1       1       29     3.5           0.666667\n",
      "2       1       32     3.5           0.666667\n",
      "3       1       47     3.5           0.666667\n",
      "4       1       50     3.5           0.666667\n",
      "5       1      112     3.5           0.666667\n",
      "6       1      151     4.0           0.777778\n",
      "7       1      223     4.0           0.777778\n",
      "8       1      253     4.0           0.777778\n",
      "9       1      260     4.0           0.777778\n",
      "\n",
      "Rating normalization plot saved as 'rating_normalization.png'\n",
      "\n",
      "Normalized ratings data:\n",
      "   userId  movieId  rating  normalized_rating\n",
      "0       1        2     3.5           0.666667\n",
      "1       1       29     3.5           0.666667\n",
      "2       1       32     3.5           0.666667\n",
      "3       1       47     3.5           0.666667\n",
      "4       1       50     3.5           0.666667\n",
      "\n",
      "================================================================================\n",
      "STEP 4: GENRE ENCODING\n",
      "================================================================================\n",
      "\n",
      "Example of raw genres format:\n",
      "   movieId                               title  \\\n",
      "0        1                    Toy Story (1995)   \n",
      "1        2                      Jumanji (1995)   \n",
      "2        3             Grumpier Old Men (1995)   \n",
      "3        4            Waiting to Exhale (1995)   \n",
      "4        5  Father of the Bride Part II (1995)   \n",
      "\n",
      "                                        genres  \n",
      "0  Adventure|Animation|Children|Comedy|Fantasy  \n",
      "1                   Adventure|Children|Fantasy  \n",
      "2                               Comedy|Romance  \n",
      "3                         Comedy|Drama|Romance  \n",
      "4                                       Comedy  \n",
      "\n",
      "Found 20 unique genres: ['(no genres listed)', 'Action', 'Adventure', 'Animation', 'Children', 'Comedy', 'Crime', 'Documentary', 'Drama', 'Fantasy', 'Film-Noir', 'Horror', 'IMAX', 'Musical', 'Mystery', 'Romance', 'Sci-Fi', 'Thriller', 'War', 'Western']\n",
      "\n",
      "One-hot encoded genres (sample):\n",
      "   movieId  (no genres listed)  Action  Adventure  Animation  Children  \\\n",
      "0        1                   0       0          1          1         1   \n",
      "1        2                   0       0          1          0         1   \n",
      "2        3                   0       0          0          0         0   \n",
      "3        4                   0       0          0          0         0   \n",
      "4        5                   0       0          0          0         0   \n",
      "\n",
      "   Comedy  Crime  Documentary  Drama  ...  Film-Noir  Horror  IMAX  Musical  \\\n",
      "0       1      0            0      0  ...          0       0     0        0   \n",
      "1       0      0            0      0  ...          0       0     0        0   \n",
      "2       1      0            0      0  ...          0       0     0        0   \n",
      "3       1      0            0      1  ...          0       0     0        0   \n",
      "4       1      0            0      0  ...          0       0     0        0   \n",
      "\n",
      "   Mystery  Romance  Sci-Fi  Thriller  War  Western  \n",
      "0        0        0       0         0    0        0  \n",
      "1        0        0       0         0    0        0  \n",
      "2        0        1       0         0    0        0  \n",
      "3        0        1       0         0    0        0  \n",
      "4        0        0       0         0    0        0  \n",
      "\n",
      "[5 rows x 21 columns]\n",
      "\n",
      "Movies with genre encodings (sample):\n",
      "   movieId                               title  (no genres listed)  Action  \\\n",
      "0        1                    Toy Story (1995)                   0       0   \n",
      "1        2                      Jumanji (1995)                   0       0   \n",
      "2        3             Grumpier Old Men (1995)                   0       0   \n",
      "3        4            Waiting to Exhale (1995)                   0       0   \n",
      "4        5  Father of the Bride Part II (1995)                   0       0   \n",
      "\n",
      "   Adventure  Animation  Children  Comedy  Crime  Documentary  ...  Film-Noir  \\\n",
      "0          1          1         1       1      0            0  ...          0   \n",
      "1          1          0         1       0      0            0  ...          0   \n",
      "2          0          0         0       1      0            0  ...          0   \n",
      "3          0          0         0       1      0            0  ...          0   \n",
      "4          0          0         0       1      0            0  ...          0   \n",
      "\n",
      "   Horror  IMAX  Musical  Mystery  Romance  Sci-Fi  Thriller  War  Western  \n",
      "0       0     0        0        0        0       0         0    0        0  \n",
      "1       0     0        0        0        0       0         0    0        0  \n",
      "2       0     0        0        0        1       0         0    0        0  \n",
      "3       0     0        0        0        1       0         0    0        0  \n",
      "4       0     0        0        0        0       0         0    0        0  \n",
      "\n",
      "[5 rows x 22 columns]\n",
      "\n",
      "Genre distribution plot saved as 'genre_distribution.png'\n",
      "\n",
      "Final genre-encoded data:\n",
      "   movieId                               title  (no genres listed)  Action  \\\n",
      "0        1                    Toy Story (1995)                   0       0   \n",
      "1        2                      Jumanji (1995)                   0       0   \n",
      "2        3             Grumpier Old Men (1995)                   0       0   \n",
      "3        4            Waiting to Exhale (1995)                   0       0   \n",
      "4        5  Father of the Bride Part II (1995)                   0       0   \n",
      "\n",
      "   Adventure  Animation  Children  Comedy  Crime  Documentary  ...  Film-Noir  \\\n",
      "0          1          1         1       1      0            0  ...          0   \n",
      "1          1          0         1       0      0            0  ...          0   \n",
      "2          0          0         0       1      0            0  ...          0   \n",
      "3          0          0         0       1      0            0  ...          0   \n",
      "4          0          0         0       1      0            0  ...          0   \n",
      "\n",
      "   Horror  IMAX  Musical  Mystery  Romance  Sci-Fi  Thriller  War  Western  \n",
      "0       0     0        0        0        0       0         0    0        0  \n",
      "1       0     0        0        0        0       0         0    0        0  \n",
      "2       0     0        0        0        1       0         0    0        0  \n",
      "3       0     0        0        0        1       0         0    0        0  \n",
      "4       0     0        0        0        0       0         0    0        0  \n",
      "\n",
      "[5 rows x 22 columns]\n",
      "\n",
      "================================================================================\n",
      "FINAL OUTPUT: COMBINED MOVIE FEATURES\n",
      "================================================================================\n",
      "\n",
      "Final movie features (sample):\n",
      "   movieId                               title  (no genres listed)  Action  \\\n",
      "0        1                    Toy Story (1995)                   0       0   \n",
      "1        2                      Jumanji (1995)                   0       0   \n",
      "2        3             Grumpier Old Men (1995)                   0       0   \n",
      "3        4            Waiting to Exhale (1995)                   0       0   \n",
      "4        5  Father of the Bride Part II (1995)                   0       0   \n",
      "\n",
      "   Adventure  Animation  Children  Comedy  Crime  Documentary  ...  IMAX  \\\n",
      "0          1          1         1       1      0            0  ...     0   \n",
      "1          1          0         1       0      0            0  ...     0   \n",
      "2          0          0         0       1      0            0  ...     0   \n",
      "3          0          0         0       1      0            0  ...     0   \n",
      "4          0          0         0       1      0            0  ...     0   \n",
      "\n",
      "   Musical  Mystery  Romance  Sci-Fi  Thriller  War  Western  token_count  \\\n",
      "0        0        0        0       0         0    0        0           51   \n",
      "1        0        0        0       0         0    0        0           65   \n",
      "2        0        0        1       0         0    0        0           39   \n",
      "3        0        0        1       0         0    0        0           32   \n",
      "4        0        0        0       0         0    0        0           28   \n",
      "\n",
      "                                      top_keywords  \n",
      "0            [woody, andy, animation, pixar, buzz]  \n",
      "1                [game, time, board, travel, alan]  \n",
      "2  [max, local, grumpier old men, family, wedding]  \n",
      "3  [waiting, exhale, cheated, mistreated, stepped]  \n",
      "4        [wedding, george, father, bride part, ii]  \n",
      "\n",
      "[5 rows x 24 columns]\n",
      "\n",
      "Processed data saved to 'processed_movie_features.csv' and 'normalized_ratings.csv'\n",
      "\n",
      "================================================================================\n",
      "SUMMARY OF STAGE 1 DATA PROCESSING\n",
      "================================================================================\n",
      "1. Extracted text features for 15597 movies\n",
      "2. Preprocessed text resulting in a vocabulary of 56636 unique words\n",
      "3. Normalized 1476401 ratings from 10000 users\n",
      "4. Created one-hot encodings for 20 genres\n",
      "5. Final dataset contains 15597 movies with complete feature sets\n",
      "================================================================================\n",
      "\n",
      "Actor name statistics:\n",
      "- Total tokens: 495561\n",
      "- Actor name tokens: 34031 (6.87%)\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.corpus import wordnet\n",
    "from collections import Counter\n",
    "import seaborn as sns\n",
    "\n",
    "# Download necessary NLTK resources\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('wordnet', quiet=True)\n",
    "nltk.download('averaged_perceptron_tagger', quiet=True)\n",
    "nltk.download('maxent_ne_chunker', quiet=True)\n",
    "nltk.download('words', quiet=True)\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "\n",
    "# Step 1: Movie Text Feature Extraction\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 1: MOVIE TEXT FEATURE EXTRACTION\")\n",
    "print(\"=\"*80)\n",
    "# Load MovieLens movie data\n",
    "movies_df = pd.read_csv('./extracted_data/extracted_movies.csv')\n",
    "print(f\"Loaded {len(movies_df)} movies from MovieLens dataset\")\n",
    "print(movies_df.head(3))\n",
    "\n",
    "# Load TMDB data (containing movie overviews, cast, director)\n",
    "tmdb_df = pd.read_csv('./extracted_data/tmdb.csv') \n",
    "print(f\"\\nLoaded {len(tmdb_df)} movies from TMDB dataset\")\n",
    "print(tmdb_df.head(3)[['id', 'tmdb_title', 'overview']])\n",
    "\n",
    "# Load links data to connect MovieLens IDs with TMDB IDs\n",
    "links_df = pd.read_csv('./extracted_data/extracted_links.csv')\n",
    "print(f\"\\nLoaded {len(links_df)} movie links\")\n",
    "print(links_df.head(3))\n",
    "\n",
    "# Load tags data for additional text information\n",
    "tags_df = pd.read_csv('./extracted_data/extracted_tags.csv')\n",
    "print(f\"\\nLoaded {len(tags_df)} movie tags\")\n",
    "print(tags_df.head(3))\n",
    "# Merge movie data with TMDB data via links_df\n",
    "movie_data = pd.merge(movies_df, links_df, on='movieId', how='left')\n",
    "movie_data = pd.merge(movie_data, tmdb_df, left_on='tmdbId', right_on='id', how='left')\n",
    "# Create text corpus for each movie\n",
    "movie_data['text_corpus'] = \"\"\n",
    "\n",
    "# Add title to corpus\n",
    "movie_data['text_corpus'] += movie_data['title'].fillna(\"\")\n",
    "\n",
    "# Add TMDB overview to corpus\n",
    "movie_data['text_corpus'] += \" \" + movie_data['overview'].fillna(\"\")\n",
    "\n",
    "# # Add TMDB cast to corpus\n",
    "# movie_data['text_corpus'] += \" \" + movie_data['cast'].fillna(\"\")\n",
    "\n",
    "# # Add TMDB director to corpus\n",
    "# movie_data['text_corpus'] += \" \" + movie_data['director'].fillna(\"\")\n",
    "\n",
    "# movie_data['text_corpus'] += \" \" + movie_data['keywords'].fillna(\"\")\n",
    "\n",
    "# Aggregate tags by movieId\n",
    "tags_by_movie = tags_df.groupby('movieId')['tag'].apply(lambda x: ' '.join(x.fillna(''))).reset_index()\n",
    "\n",
    "# Merge tags with movies\n",
    "movie_data = pd.merge(movie_data, tags_by_movie, on='movieId', how='left')\n",
    "\n",
    "# Add tags to corpus\n",
    "movie_data['text_corpus'] += \" \" + movie_data['tag'].fillna(\"\")\n",
    "\n",
    "# Display a sample text corpus\n",
    "print(\"\\nSample movie text corpus:\")\n",
    "sample_movie = movie_data.iloc[0]\n",
    "print(f\"Movie: {sample_movie['title']}\")\n",
    "print(f\"Text corpus: {sample_movie['text_corpus'][:300]}...\")\n",
    "\n",
    "# Output: Movie text corpus data\n",
    "print(f\"\\nCreated text corpus for {len(movie_data)} movies\")\n",
    "movie_corpus_df = movie_data[['movieId', 'title', 'text_corpus']]\n",
    "print(movie_corpus_df.head(3))\n",
    "\n",
    "# Step 2: Text Preprocessing\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 2: TEXT PREPROCESSING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Define helper functions for text preprocessing\n",
    "def get_wordnet_pos(tag):\n",
    "    \"\"\"Map POS tag to WordNet POS tag\"\"\"\n",
    "    tag_dict = {\n",
    "        \"J\": wordnet.ADJ,\n",
    "        \"N\": wordnet.NOUN,\n",
    "        \"V\": wordnet.VERB,\n",
    "        \"R\": wordnet.ADV\n",
    "    }\n",
    "    return tag_dict.get(tag[0].upper(), wordnet.NOUN)\n",
    "\n",
    "def preserve_full_names(text):\n",
    "    \"\"\"Preserve full names as single tokens by replacing spaces with underscores\"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    \n",
    "    # Pattern to identify potential names (two or more capitalized words in sequence)\n",
    "    # This will match names like \"Tom Hanks\", \"Robert De Niro\", etc.\n",
    "    name_pattern = r'\\b([A-Z][a-z]+(?:\\s+[A-Z][a-z]+)+)\\b'\n",
    "    \n",
    "    # Find all matches\n",
    "    matches = re.findall(name_pattern, text)\n",
    "    \n",
    "    # Replace spaces with underscores in the matched names\n",
    "    for name in matches:\n",
    "        text = text.replace(name, name.replace(' ', '_'))\n",
    "    \n",
    "    return text\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"Clean and normalize text\"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    \n",
    "    # First preserve full names\n",
    "    text = preserve_full_names(text)\n",
    "    \n",
    "    # Remove HTML tags\n",
    "    text = re.sub(r'<.*?>', ' ', text)\n",
    "    \n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove special characters but keep underscores (for preserved names)\n",
    "    text = re.sub(r'[^\\w\\s_]', ' ', text)\n",
    "    text = re.sub(r'\\d+', ' ', text)  # Remove digits\n",
    "    \n",
    "    # Remove extra spaces\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    \n",
    "    return text.strip()\n",
    "\n",
    "def preprocess_text(text, stop_words, lemmatizer):\n",
    "    \"\"\"Tokenize, remove stopwords, and lemmatize text\"\"\"\n",
    "    if not isinstance(text, str) or text == \"\":\n",
    "        return []\n",
    "    \n",
    "    # Clean the text\n",
    "    cleaned_text = clean_text(text)\n",
    "    \n",
    "    # Tokenize text\n",
    "    tokens = word_tokenize(cleaned_text)\n",
    "    \n",
    "    # Remove stopwords and short words, but keep tokens with underscores (names)\n",
    "    tokens = [word for word in tokens if (word not in stop_words and len(word) > 1) or '_' in word]\n",
    "    \n",
    "    try:\n",
    "        # Try lemmatizing tokens with POS tagging, but don't lemmatize names with underscores\n",
    "        lemmatized_tokens = []\n",
    "        for word in tokens:\n",
    "            if '_' in word:\n",
    "                # Don't lemmatize names, just replace underscores with spaces\n",
    "                lemmatized_tokens.append(word.replace('_', ' '))\n",
    "            else:\n",
    "                # Get POS tag for regular words\n",
    "                pos = pos_tag([word])\n",
    "                lemmatized_tokens.append(lemmatizer.lemmatize(word, get_wordnet_pos(pos[0][1])))\n",
    "    except LookupError:\n",
    "        # Fallback to simple lemmatization without POS tagging\n",
    "        lemmatized_tokens = []\n",
    "        for word in tokens:\n",
    "            if '_' in word:\n",
    "                lemmatized_tokens.append(word.replace('_', ' '))\n",
    "            else:\n",
    "                lemmatized_tokens.append(lemmatizer.lemmatize(word))\n",
    "    \n",
    "    return lemmatized_tokens\n",
    "\n",
    "# Initialize NLTK tools\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Apply preprocessing to movie text corpus\n",
    "print(\"Cleaning and tokenizing text corpus...\")\n",
    "movie_data['cleaned_text'] = movie_data['text_corpus'].apply(clean_text)\n",
    "movie_data['tokens'] = movie_data['cleaned_text'].apply(lambda x: preprocess_text(x, stop_words, lemmatizer))\n",
    "\n",
    "# Display sample of preprocessed text\n",
    "print(\"\\nSample of preprocessed text:\")\n",
    "sample_idx = 0\n",
    "print(f\"Movie: {movie_data.iloc[sample_idx]['title']}\")\n",
    "print(f\"Original text: {movie_data.iloc[sample_idx]['text_corpus'][:100]}...\")\n",
    "print(f\"Cleaned text: {movie_data.iloc[sample_idx]['cleaned_text'][:100]}...\")\n",
    "print(f\"Tokens: {movie_data.iloc[sample_idx]['tokens'][:20]}...\")\n",
    "\n",
    "# Count corpus words\n",
    "all_words = []\n",
    "for tokens in movie_data['tokens']:\n",
    "    all_words.extend(tokens)\n",
    "\n",
    "corpus_word_counts = Counter(all_words)\n",
    "print(f\"\\nVocabulary size: {len(corpus_word_counts)} unique words\")\n",
    "print(f\"Top 20 most common words: {corpus_word_counts.most_common(20)}\")\n",
    "\n",
    "# Calculate document frequency (number of documents containing each word)\n",
    "doc_freq = {}\n",
    "for tokens in movie_data['tokens']:\n",
    "    for word in set(tokens):  # Count each word only once per document\n",
    "        doc_freq[word] = doc_freq.get(word, 0) + 1\n",
    "\n",
    "print(f\"\\nDocument frequency of top words:\")\n",
    "for word, count in sorted(doc_freq.items(), key=lambda x: x[1], reverse=True)[:10]:\n",
    "    print(f\"'{word}' appears in {count} documents\")\n",
    "\n",
    "# Output: Preprocessed text data\n",
    "preprocessed_df = movie_data[['movieId', 'title', 'tokens']]\n",
    "print(\"\\nPreprocessed movie text data:\")\n",
    "print(preprocessed_df.head(3))\n",
    "\n",
    "# Plot token length distribution\n",
    "token_lengths = [len(tokens) for tokens in movie_data['tokens']]\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(token_lengths, bins=30, color='skyblue', edgecolor='black')\n",
    "plt.title('Distribution of Token Count per Movie')\n",
    "plt.xlabel('Number of Tokens')\n",
    "plt.ylabel('Number of Movies')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.savefig('./processed/istribution.png')\n",
    "print(\"\\nToken distribution plot saved as 'token_distribution.png'\")\n",
    "plt.close()\n",
    "\n",
    "# Step 3: Data Normalization\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 3: DATA NORMALIZATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Load user ratings data\n",
    "ratings_df = pd.read_csv('./extracted_data/extracted_ratings.csv')\n",
    "print(f\"Loaded {len(ratings_df)} ratings from {len(ratings_df['userId'].unique())} users\")\n",
    "print(ratings_df.head())\n",
    "\n",
    "# Calculate rating statistics by user\n",
    "user_stats = ratings_df.groupby('userId').agg({\n",
    "    'rating': ['count', 'mean', 'std']\n",
    "}).reset_index()\n",
    "user_stats.columns = ['userId', 'rating_count', 'rating_mean', 'rating_std']\n",
    "\n",
    "# Fill NA values in std with 0 (for users with only one rating)\n",
    "user_stats['rating_std'] = user_stats['rating_std'].fillna(0)\n",
    "\n",
    "print(\"\\nUser rating statistics:\")\n",
    "print(user_stats.head())\n",
    "\n",
    "# Plot user rating distributions\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.hist(user_stats['rating_mean'], bins=20, color='skyblue', edgecolor='black')\n",
    "plt.title('Distribution of Mean Ratings per User')\n",
    "plt.xlabel('Mean Rating')\n",
    "plt.ylabel('Number of Users')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.hist(user_stats['rating_std'], bins=20, color='lightgreen', edgecolor='black')\n",
    "plt.title('Distribution of Rating Standard Deviation per User')\n",
    "plt.xlabel('Rating Standard Deviation')\n",
    "plt.ylabel('Number of Users')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.hist(user_stats['rating_count'], bins=20, color='salmon', edgecolor='black')\n",
    "plt.title('Distribution of Rating Count per User')\n",
    "plt.xlabel('Number of Ratings')\n",
    "plt.ylabel('Number of Users')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('./processed/user_rating_stats.png')\n",
    "print(\"\\nUser rating statistics plot saved as 'user_rating_stats.png'\")\n",
    "plt.close()\n",
    "\n",
    "def normalize_ratings(ratings_df):\n",
    "    \"\"\"Normalize ratings using a consistent global Min-Max scaling from [0.5-5.0] to [0-1]\"\"\"\n",
    "    # Create a copy to avoid affecting the original data\n",
    "    result_df = ratings_df.copy()\n",
    "    \n",
    "    # Define global min and max for the rating scale\n",
    "    global_min = 0.5  # Minimum possible rating in MovieLens dataset\n",
    "    global_max = 5.0  # Maximum possible rating in MovieLens dataset\n",
    "    \n",
    "    # Apply global min-max scaling\n",
    "    result_df['normalized_rating'] = (result_df['rating'] - global_min) / (global_max - global_min)\n",
    "    \n",
    "    return result_df[['userId', 'movieId', 'rating', 'normalized_rating']]\n",
    "\n",
    "# Apply normalization\n",
    "print(\"\\nNormalizing ratings...\")\n",
    "normalized_ratings = normalize_ratings(ratings_df)\n",
    "\n",
    "print(\"\\nOriginal vs. Normalized ratings:\")\n",
    "print(normalized_ratings[['userId', 'movieId', 'rating', 'normalized_rating']].head(10))\n",
    "\n",
    "# Plot original vs normalized ratings\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(ratings_df['rating'], bins=9, color='skyblue', edgecolor='black', alpha=0.7)\n",
    "plt.title('Distribution of Original Ratings')\n",
    "plt.xlabel('Rating')\n",
    "plt.ylabel('Count')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(normalized_ratings['normalized_rating'], bins=20, color='salmon', edgecolor='black', alpha=0.7)\n",
    "plt.title('Distribution of Normalized Ratings')\n",
    "plt.xlabel('Normalized Rating')\n",
    "plt.ylabel('Count')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('./processed/rating_normalization.png')\n",
    "print(\"\\nRating normalization plot saved as 'rating_normalization.png'\")\n",
    "plt.close()\n",
    "\n",
    "# Output: Normalized ratings data\n",
    "print(\"\\nNormalized ratings data:\")\n",
    "print(normalized_ratings.head())\n",
    "\n",
    "# Step 4: Genre Encoding (Binary Representation)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 4: GENRE ENCODING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Extract genres from movies dataframe\n",
    "print(\"\\nExample of raw genres format:\")\n",
    "print(movies_df[['movieId', 'title', 'genres']].head())\n",
    "\n",
    "# Count total unique genres\n",
    "all_genres = set()\n",
    "for genres in movies_df['genres'].str.split('|'):\n",
    "    if isinstance(genres, list):\n",
    "        all_genres.update(genres)\n",
    "\n",
    "print(f\"\\nFound {len(all_genres)} unique genres: {sorted(all_genres)}\")\n",
    "\n",
    "# One-hot encode genres\n",
    "# First, create a DataFrame with movieId and genre columns\n",
    "genre_data = []\n",
    "for _, movie in movies_df.iterrows():\n",
    "    movie_id = movie['movieId']\n",
    "    genres = movie['genres'].split('|') if isinstance(movie['genres'], str) else []\n",
    "    \n",
    "    for genre in genres:\n",
    "        genre_data.append({'movieId': movie_id, 'genre': genre})\n",
    "\n",
    "# Convert to DataFrame\n",
    "genre_df = pd.DataFrame(genre_data)\n",
    "\n",
    "# Create pivot table for one-hot encoding\n",
    "genre_one_hot = pd.pivot_table(\n",
    "    genre_df, \n",
    "    index='movieId', \n",
    "    columns='genre', \n",
    "    aggfunc=lambda x: 1, \n",
    "    fill_value=0\n",
    ").reset_index()\n",
    "\n",
    "# Flatten the column names\n",
    "genre_one_hot.columns.name = None\n",
    "\n",
    "print(\"\\nOne-hot encoded genres (sample):\")\n",
    "print(genre_one_hot.head())\n",
    "\n",
    "# Merge with original movie data\n",
    "movie_genres = pd.merge(\n",
    "    movies_df[['movieId', 'title']], \n",
    "    genre_one_hot, \n",
    "    on='movieId', \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Fill NaN values with 0\n",
    "for genre in all_genres:\n",
    "    if genre in movie_genres.columns:\n",
    "        movie_genres[genre] = movie_genres[genre].fillna(0).astype(int)\n",
    "\n",
    "print(\"\\nMovies with genre encodings (sample):\")\n",
    "print(movie_genres.head())\n",
    "\n",
    "# Plot genre distribution\n",
    "genre_counts = {}\n",
    "for genre in all_genres:\n",
    "    if genre in movie_genres.columns:\n",
    "        genre_counts[genre] = movie_genres[genre].sum()\n",
    "\n",
    "# Sort genres by count\n",
    "sorted_genres = sorted(genre_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.bar([x[0] for x in sorted_genres], [x[1] for x in sorted_genres], color='skyblue', edgecolor='black')\n",
    "plt.title('Distribution of Movies by Genre')\n",
    "plt.xlabel('Genre')\n",
    "plt.ylabel('Number of Movies')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.grid(True, axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('./processed/genre_distribution.png')\n",
    "print(\"\\nGenre distribution plot saved as 'genre_distribution.png'\")\n",
    "plt.close()\n",
    "\n",
    "# Output: Genre-encoded data\n",
    "print(\"\\nFinal genre-encoded data:\")\n",
    "print(movie_genres.head())\n",
    "\n",
    "# Final Output: Combined Movie Features\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FINAL OUTPUT: COMBINED MOVIE FEATURES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Combine all features into one DataFrame\n",
    "movie_features = pd.merge(\n",
    "    movie_genres,  # Contains movieId, title, and genre encodings\n",
    "    preprocessed_df[['movieId', 'tokens']],  # Contains preprocessed text tokens\n",
    "    on='movieId',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Add a column for text corpus length (token count)\n",
    "movie_features['token_count'] = movie_features['tokens'].apply(lambda x: len(x) if isinstance(x, list) else 0)\n",
    "\n",
    "# Add a column for the top 5 keywords for each movie (based on frequency)\n",
    "def get_top_keywords(tokens, n=5):\n",
    "    if not isinstance(tokens, list) or len(tokens) == 0:\n",
    "        return []\n",
    "    \n",
    "    word_counts = Counter(tokens)\n",
    "    return [word for word, _ in word_counts.most_common(n)]\n",
    "\n",
    "movie_features['top_keywords'] = movie_features['tokens'].apply(get_top_keywords)\n",
    "\n",
    "# Drop the tokens column to make the DataFrame more readable for display\n",
    "display_features = movie_features.drop(columns=['tokens'])\n",
    "\n",
    "print(\"\\nFinal movie features (sample):\")\n",
    "print(display_features.head())\n",
    "\n",
    "# Save the processed data for later use\n",
    "movie_features.to_csv('./processed/processed_movie_features.csv', index=False)\n",
    "normalized_ratings.to_csv('./processed/normalized_ratings.csv', index=False)\n",
    "\n",
    "print(\"\\nProcessed data saved to 'processed_movie_features.csv' and 'normalized_ratings.csv'\")\n",
    "\n",
    "# Summary of the data processing pipeline\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SUMMARY OF STAGE 1 DATA PROCESSING\")\n",
    "print(\"=\"*80)\n",
    "print(f\"1. Extracted text features for {len(movie_data)} movies\")\n",
    "print(f\"2. Preprocessed text resulting in a vocabulary of {len(corpus_word_counts)} unique words\")\n",
    "print(f\"3. Normalized {len(normalized_ratings)} ratings from {len(user_stats)} users\")\n",
    "print(f\"4. Created one-hot encodings for {len(all_genres)} genres\")\n",
    "print(f\"5. Final dataset contains {len(movie_features)} movies with complete feature sets\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Count the number of actor names preserved in the tokens\n",
    "actor_name_count = 0\n",
    "total_tokens = 0\n",
    "\n",
    "for tokens in movie_features['tokens']:\n",
    "    if isinstance(tokens, list):\n",
    "        for token in tokens:\n",
    "            total_tokens += 1\n",
    "            if ' ' in token:  # Tokens with spaces are preserved actor names\n",
    "                actor_name_count += 1\n",
    "\n",
    "actor_name_percentage = (actor_name_count / total_tokens) * 100 if total_tokens > 0 else 0\n",
    "print(f\"\\nActor name statistics:\")\n",
    "print(f\"- Total tokens: {total_tokens}\")\n",
    "print(f\"- Actor name tokens: {actor_name_count} ({actor_name_percentage:.2f}%)\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
