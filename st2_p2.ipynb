{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-26 11:31:32,071 : INFO : Starting enhanced DNN-based recommendation pipeline\n",
      "2025-04-26 11:31:32,071 : INFO : Initial memory usage: 1100.07 MB\n",
      "2025-04-26 11:31:32,071 : INFO : Before loading data: 1100.18 MB\n",
      "2025-04-26 11:31:32,147 : INFO : Loaded movie features with shape (9746, 36)\n",
      "2025-04-26 11:31:32,807 : INFO : Loaded ratings with shape (150629, 4)\n",
      "2025-04-26 11:31:32,808 : INFO : After loading data: 1374.67 MB\n",
      "2025-04-26 11:31:32,809 : INFO : Creating improved train/test split\n",
      "2025-04-26 11:31:32,878 : INFO : Training set: 145395 ratings from 1000 users\n",
      "2025-04-26 11:31:32,880 : INFO : Test set: 5234 ratings from 200 users\n",
      "2025-04-26 11:31:33,045 : INFO : Found 6 region features: ['East Asia', 'Middle East', 'North America', 'Oceania', 'South Asia', 'Southeast Asia']\n",
      "2025-04-26 11:31:33,045 : INFO : After split preparation: 1383.57 MB\n",
      "2025-04-26 11:31:33,098 : INFO : After loading data: 1172.81 MB\n",
      "2025-04-26 11:31:33,105 : INFO : Extracted 25 genre features and 6 region features\n",
      "2025-04-26 11:31:33,107 : INFO : After feature extraction: 1175.32 MB\n",
      "2025-04-26 11:31:33,108 : INFO : Calculating user preferences for 31 features\n",
      "2025-04-26 11:32:12,304 : INFO : Processed 1000/1000 users (100.0%) - Elapsed: 39.19s - Est. remaining: 0.00s\n",
      "2025-04-26 11:32:12,429 : INFO : Created preferences for 1000 users\n",
      "2025-04-26 11:32:12,460 : INFO : Saved user preferences for 1000 users\n",
      "2025-04-26 11:32:12,496 : INFO : Saved movie genre features for 9746 movies\n",
      "2025-04-26 11:32:12,498 : INFO : After user preferences calculation: 1180.53 MB\n",
      "2025-04-26 11:32:12,498 : INFO : Preparing training data for DNN model with enhanced features\n",
      "2025-04-26 11:32:20,139 : INFO : Processed 10000/145395 ratings (6.9%) - Elapsed: 5.18s - Est. remaining: 70.07s\n",
      "2025-04-26 11:33:11,754 : INFO : Processed 110000/145395 ratings (75.7%) - Elapsed: 56.79s - Est. remaining: 18.27s\n",
      "2025-04-26 11:33:33,250 : INFO : Created training data: X_train shape (116316, 163), y_train shape (116316,)\n",
      "2025-04-26 11:33:33,250 : INFO : Created validation data: X_val shape (29079, 163), y_val shape (29079,)\n",
      "2025-04-26 11:33:33,250 : INFO : Training set class distribution: Positive 68630.0 (59.0%), Negative 47686.0 (41.0%)\n",
      "2025-04-26 11:33:33,262 : INFO : Validation set class distribution: Positive 17158.0 (59.0%), Negative 11921.0 (41.0%)\n",
      "2025-04-26 11:33:33,531 : INFO : After training data preparation: 1445.23 MB\n",
      "2025-04-26 11:33:33,531 : INFO : Building and training enhanced DNN model\n",
      "2025-04-26 11:33:33,596 : INFO : Class weights: {0: 1.2196032378475863, 1: 0.8474136674923503}\n",
      "2025-04-26 11:33:33,596 : INFO : Training model with 30 max epochs, batch size 256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m454/455\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6516 - auc: 0.7049 - f1_metric: 144.2371 - loss: 0.8725 - precision: 0.7240 - recall: 0.6619\n",
      "Epoch 1: val_auc improved from -inf to 0.81545, saving model to ./rec/collaborative-recommendations\\best_model.keras\n",
      "\u001b[1m455/455\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 38ms/step - accuracy: 0.6519 - auc: 0.7052 - f1_metric: 144.2426 - loss: 0.8721 - precision: 0.7242 - recall: 0.6622 - val_accuracy: 0.7466 - val_auc: 0.8154 - val_f1_metric: 151.5669 - val_loss: 0.6787 - val_precision: 0.7809 - val_recall: 0.7932\n",
      "Epoch 2/30\n",
      "\u001b[1m455/455\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.7360 - auc: 0.8093 - f1_metric: 145.6598 - loss: 0.6769 - precision: 0.7947 - recall: 0.7440\n",
      "Epoch 2: val_auc improved from 0.81545 to 0.82026, saving model to ./rec/collaborative-recommendations\\best_model.keras\n",
      "\u001b[1m455/455\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 40ms/step - accuracy: 0.7360 - auc: 0.8093 - f1_metric: 145.6610 - loss: 0.6769 - precision: 0.7947 - recall: 0.7440 - val_accuracy: 0.7415 - val_auc: 0.8203 - val_f1_metric: 145.7382 - val_loss: 0.6142 - val_precision: 0.7989 - val_recall: 0.7510\n",
      "Epoch 3/30\n",
      "\u001b[1m454/455\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.7418 - auc: 0.8163 - f1_metric: 146.7456 - loss: 0.6139 - precision: 0.7994 - recall: 0.7524\n",
      "Epoch 3: val_auc improved from 0.82026 to 0.82181, saving model to ./rec/collaborative-recommendations\\best_model.keras\n",
      "\u001b[1m455/455\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 40ms/step - accuracy: 0.7418 - auc: 0.8163 - f1_metric: 146.7428 - loss: 0.6139 - precision: 0.7994 - recall: 0.7524 - val_accuracy: 0.7420 - val_auc: 0.8218 - val_f1_metric: 144.7407 - val_loss: 0.5831 - val_precision: 0.8034 - val_recall: 0.7452\n",
      "Epoch 4/30\n",
      "\u001b[1m454/455\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7427 - auc: 0.8215 - f1_metric: 145.2120 - loss: 0.5835 - precision: 0.8052 - recall: 0.7448\n",
      "Epoch 4: val_auc improved from 0.82181 to 0.82301, saving model to ./rec/collaborative-recommendations\\best_model.keras\n",
      "\u001b[1m455/455\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 38ms/step - accuracy: 0.7427 - auc: 0.8215 - f1_metric: 145.2133 - loss: 0.5835 - precision: 0.8052 - recall: 0.7448 - val_accuracy: 0.7447 - val_auc: 0.8230 - val_f1_metric: 145.3130 - val_loss: 0.5701 - val_precision: 0.8035 - val_recall: 0.7510\n",
      "Epoch 5/30\n",
      "\u001b[1m454/455\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7482 - auc: 0.8260 - f1_metric: 145.6804 - loss: 0.5703 - precision: 0.8064 - recall: 0.7538\n",
      "Epoch 5: val_auc did not improve from 0.82301\n",
      "\u001b[1m455/455\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 36ms/step - accuracy: 0.7482 - auc: 0.8260 - f1_metric: 145.6795 - loss: 0.5703 - precision: 0.8064 - recall: 0.7538 - val_accuracy: 0.7440 - val_auc: 0.8228 - val_f1_metric: 145.5116 - val_loss: 0.5683 - val_precision: 0.8021 - val_recall: 0.7517\n",
      "Epoch 6/30\n",
      "\u001b[1m454/455\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7426 - auc: 0.8180 - f1_metric: 146.2355 - loss: 0.5712 - precision: 0.7997 - recall: 0.7520\n",
      "Epoch 6: val_auc did not improve from 0.82301\n",
      "\u001b[1m455/455\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 35ms/step - accuracy: 0.7426 - auc: 0.8180 - f1_metric: 146.2359 - loss: 0.5712 - precision: 0.7997 - recall: 0.7520 - val_accuracy: 0.7402 - val_auc: 0.8187 - val_f1_metric: 146.1193 - val_loss: 0.5476 - val_precision: 0.7962 - val_recall: 0.7522\n",
      "Epoch 7/30\n",
      "\u001b[1m455/455\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7434 - auc: 0.8209 - f1_metric: 145.3157 - loss: 0.5464 - precision: 0.8007 - recall: 0.7498\n",
      "Epoch 7: val_auc did not improve from 0.82301\n",
      "\u001b[1m455/455\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 36ms/step - accuracy: 0.7434 - auc: 0.8209 - f1_metric: 145.3176 - loss: 0.5464 - precision: 0.8007 - recall: 0.7498 - val_accuracy: 0.7397 - val_auc: 0.8210 - val_f1_metric: 145.0607 - val_loss: 0.5344 - val_precision: 0.7999 - val_recall: 0.7453\n",
      "Epoch 8/30\n",
      "\u001b[1m454/455\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7473 - auc: 0.8244 - f1_metric: 147.0944 - loss: 0.5329 - precision: 0.8006 - recall: 0.7613\n",
      "Epoch 8: val_auc did not improve from 0.82301\n",
      "\u001b[1m455/455\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 36ms/step - accuracy: 0.7473 - auc: 0.8243 - f1_metric: 147.0943 - loss: 0.5329 - precision: 0.8006 - recall: 0.7613 - val_accuracy: 0.7462 - val_auc: 0.8228 - val_f1_metric: 149.3075 - val_loss: 0.5275 - val_precision: 0.7891 - val_recall: 0.7778\n",
      "Epoch 9/30\n",
      "\u001b[1m453/455\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7459 - auc: 0.8215 - f1_metric: 146.8876 - loss: 0.5327 - precision: 0.7970 - recall: 0.7616\n",
      "Epoch 9: val_auc improved from 0.82301 to 0.82499, saving model to ./rec/collaborative-recommendations\\best_model.keras\n",
      "\u001b[1m455/455\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 36ms/step - accuracy: 0.7459 - auc: 0.8215 - f1_metric: 146.8888 - loss: 0.5327 - precision: 0.7971 - recall: 0.7616 - val_accuracy: 0.7462 - val_auc: 0.8250 - val_f1_metric: 147.4100 - val_loss: 0.5260 - val_precision: 0.7965 - val_recall: 0.7655\n",
      "Epoch 10/30\n",
      "\u001b[1m454/455\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7493 - auc: 0.8271 - f1_metric: 146.8792 - loss: 0.5236 - precision: 0.8029 - recall: 0.7620\n",
      "Epoch 10: val_auc improved from 0.82499 to 0.82678, saving model to ./rec/collaborative-recommendations\\best_model.keras\n",
      "\u001b[1m455/455\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 36ms/step - accuracy: 0.7493 - auc: 0.8271 - f1_metric: 146.8789 - loss: 0.5236 - precision: 0.8029 - recall: 0.7620 - val_accuracy: 0.7510 - val_auc: 0.8268 - val_f1_metric: 150.8279 - val_loss: 0.5128 - val_precision: 0.7874 - val_recall: 0.7918\n",
      "Epoch 11/30\n",
      "\u001b[1m453/455\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7542 - auc: 0.8297 - f1_metric: 147.9793 - loss: 0.5180 - precision: 0.8046 - recall: 0.7714\n",
      "Epoch 11: val_auc improved from 0.82678 to 0.82729, saving model to ./rec/collaborative-recommendations\\best_model.keras\n",
      "\u001b[1m455/455\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 36ms/step - accuracy: 0.7542 - auc: 0.8297 - f1_metric: 147.9734 - loss: 0.5180 - precision: 0.8046 - recall: 0.7714 - val_accuracy: 0.7463 - val_auc: 0.8273 - val_f1_metric: 146.2933 - val_loss: 0.5147 - val_precision: 0.8011 - val_recall: 0.7585\n",
      "Epoch 12/30\n",
      "\u001b[1m453/455\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7559 - auc: 0.8355 - f1_metric: 146.4702 - loss: 0.5103 - precision: 0.8092 - recall: 0.7661\n",
      "Epoch 12: val_auc improved from 0.82729 to 0.82791, saving model to ./rec/collaborative-recommendations\\best_model.keras\n",
      "\u001b[1m455/455\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 36ms/step - accuracy: 0.7559 - auc: 0.8355 - f1_metric: 146.4740 - loss: 0.5103 - precision: 0.8092 - recall: 0.7661 - val_accuracy: 0.7439 - val_auc: 0.8279 - val_f1_metric: 145.1598 - val_loss: 0.5146 - val_precision: 0.8034 - val_recall: 0.7494\n",
      "Epoch 13/30\n",
      "\u001b[1m454/455\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7565 - auc: 0.8364 - f1_metric: 146.1892 - loss: 0.5081 - precision: 0.8109 - recall: 0.7648\n",
      "Epoch 13: val_auc improved from 0.82791 to 0.82859, saving model to ./rec/collaborative-recommendations\\best_model.keras\n",
      "\u001b[1m455/455\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 36ms/step - accuracy: 0.7565 - auc: 0.8364 - f1_metric: 146.1902 - loss: 0.5081 - precision: 0.8109 - recall: 0.7648 - val_accuracy: 0.7487 - val_auc: 0.8286 - val_f1_metric: 147.4508 - val_loss: 0.5123 - val_precision: 0.7985 - val_recall: 0.7677\n",
      "Epoch 14/30\n",
      "\u001b[1m454/455\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7619 - auc: 0.8407 - f1_metric: 147.7792 - loss: 0.5012 - precision: 0.8139 - recall: 0.7752\n",
      "Epoch 14: val_auc improved from 0.82859 to 0.82879, saving model to ./rec/collaborative-recommendations\\best_model.keras\n",
      "\u001b[1m455/455\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 36ms/step - accuracy: 0.7619 - auc: 0.8407 - f1_metric: 147.7751 - loss: 0.5012 - precision: 0.8139 - recall: 0.7752 - val_accuracy: 0.7468 - val_auc: 0.8288 - val_f1_metric: 145.5031 - val_loss: 0.5136 - val_precision: 0.8046 - val_recall: 0.7540\n",
      "Epoch 15/30\n",
      "\u001b[1m454/455\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7596 - auc: 0.8426 - f1_metric: 146.2362 - loss: 0.4983 - precision: 0.8168 - recall: 0.7649\n",
      "Epoch 15: val_auc did not improve from 0.82879\n",
      "\u001b[1m455/455\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 38ms/step - accuracy: 0.7596 - auc: 0.8426 - f1_metric: 146.2351 - loss: 0.4983 - precision: 0.8168 - recall: 0.7649 - val_accuracy: 0.7360 - val_auc: 0.8229 - val_f1_metric: 141.1374 - val_loss: 0.5227 - val_precision: 0.8125 - val_recall: 0.7184\n",
      "Epoch 16/30\n",
      "\u001b[1m454/455\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7501 - auc: 0.8297 - f1_metric: 146.1794 - loss: 0.5178 - precision: 0.8046 - recall: 0.7599\n",
      "Epoch 16: val_auc did not improve from 0.82879\n",
      "\u001b[1m455/455\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 38ms/step - accuracy: 0.7501 - auc: 0.8297 - f1_metric: 146.1821 - loss: 0.5178 - precision: 0.8046 - recall: 0.7600 - val_accuracy: 0.7434 - val_auc: 0.8242 - val_f1_metric: 146.0847 - val_loss: 0.5194 - val_precision: 0.7992 - val_recall: 0.7547\n",
      "Epoch 17/30\n",
      "\u001b[1m454/455\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7515 - auc: 0.8305 - f1_metric: 147.4593 - loss: 0.5158 - precision: 0.8041 - recall: 0.7661\n",
      "Epoch 17: val_auc did not improve from 0.82879\n",
      "\u001b[1m455/455\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 37ms/step - accuracy: 0.7515 - auc: 0.8305 - f1_metric: 147.4574 - loss: 0.5158 - precision: 0.8041 - recall: 0.7661 - val_accuracy: 0.7475 - val_auc: 0.8236 - val_f1_metric: 148.7156 - val_loss: 0.5184 - val_precision: 0.7925 - val_recall: 0.7750\n",
      "Epoch 18/30\n",
      "\u001b[1m454/455\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7512 - auc: 0.8317 - f1_metric: 147.0578 - loss: 0.5146 - precision: 0.8048 - recall: 0.7640\n",
      "Epoch 18: val_auc did not improve from 0.82879\n",
      "\u001b[1m455/455\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 37ms/step - accuracy: 0.7512 - auc: 0.8317 - f1_metric: 147.0578 - loss: 0.5146 - precision: 0.8048 - recall: 0.7640 - val_accuracy: 0.7481 - val_auc: 0.8267 - val_f1_metric: 146.4889 - val_loss: 0.5185 - val_precision: 0.8018 - val_recall: 0.7612\n",
      "Epoch 19/30\n",
      "\u001b[1m454/455\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7561 - auc: 0.8333 - f1_metric: 147.5530 - loss: 0.5124 - precision: 0.8073 - recall: 0.7709\n",
      "Epoch 19: val_auc did not improve from 0.82879\n",
      "\u001b[1m455/455\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 37ms/step - accuracy: 0.7560 - auc: 0.8333 - f1_metric: 147.5494 - loss: 0.5124 - precision: 0.8073 - recall: 0.7709 - val_accuracy: 0.7476 - val_auc: 0.8262 - val_f1_metric: 148.3019 - val_loss: 0.5184 - val_precision: 0.7942 - val_recall: 0.7724\n",
      "Epoch 20/30\n",
      "\u001b[1m455/455\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7563 - auc: 0.8334 - f1_metric: 147.4098 - loss: 0.5128 - precision: 0.8066 - recall: 0.7716\n",
      "Epoch 20: val_auc did not improve from 0.82879\n",
      "\u001b[1m455/455\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 37ms/step - accuracy: 0.7563 - auc: 0.8334 - f1_metric: 147.4086 - loss: 0.5128 - precision: 0.8066 - recall: 0.7716 - val_accuracy: 0.7471 - val_auc: 0.8279 - val_f1_metric: 146.4649 - val_loss: 0.5131 - val_precision: 0.8010 - val_recall: 0.7603\n",
      "Epoch 21/30\n",
      "\u001b[1m453/455\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7538 - auc: 0.8343 - f1_metric: 146.5243 - loss: 0.5111 - precision: 0.8055 - recall: 0.7662\n",
      "Epoch 21: val_auc did not improve from 0.82879\n",
      "\u001b[1m455/455\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 37ms/step - accuracy: 0.7538 - auc: 0.8343 - f1_metric: 146.5256 - loss: 0.5111 - precision: 0.8055 - recall: 0.7662 - val_accuracy: 0.7438 - val_auc: 0.8274 - val_f1_metric: 143.5048 - val_loss: 0.5173 - val_precision: 0.8101 - val_recall: 0.7391\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "\u001b[1m909/909\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7458 - auc: 0.8256 - f1_metric: 18.3764 - loss: 0.5164 - precision: 0.7970 - recall: 0.7639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-26 11:39:30,291 : INFO : Model validation metrics:\n",
      "2025-04-26 11:39:30,292 : INFO : - Loss: 0.5123\n",
      "2025-04-26 11:39:30,292 : INFO : - Accuracy: 0.7487\n",
      "2025-04-26 11:39:30,293 : INFO : - AUC: 0.8286\n",
      "2025-04-26 11:39:30,293 : INFO : - Precision: 0.7985\n",
      "2025-04-26 11:39:30,293 : INFO : - Recall: 0.7677\n",
      "2025-04-26 11:39:30,294 : INFO : - F1 Score: 18.3976\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m909/909\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-26 11:39:32,397 : INFO : After model training: 1772.83 MB\n",
      "2025-04-26 11:39:32,397 : WARNING : You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "2025-04-26 11:39:32,437 : INFO : Saved trained DNN model\n",
      "2025-04-26 11:39:32,438 : INFO : Generating recommendations for 1000 users\n",
      "2025-04-26 11:41:22,067 : INFO : Processed 50/1000 users (5.0%) - Elapsed: 108.92s - Est. remaining: 2069.50s\n",
      "2025-04-26 11:43:09,809 : INFO : Processed 100/1000 users (10.0%) - Elapsed: 216.66s - Est. remaining: 1949.96s\n",
      "2025-04-26 11:44:57,136 : INFO : Processed 150/1000 users (15.0%) - Elapsed: 323.99s - Est. remaining: 1835.94s\n",
      "2025-04-26 11:46:44,551 : INFO : Processed 200/1000 users (20.0%) - Elapsed: 431.40s - Est. remaining: 1725.62s\n",
      "2025-04-26 11:48:31,661 : INFO : Processed 250/1000 users (25.0%) - Elapsed: 538.51s - Est. remaining: 1615.54s\n",
      "2025-04-26 11:50:19,294 : INFO : Processed 300/1000 users (30.0%) - Elapsed: 646.15s - Est. remaining: 1507.68s\n",
      "2025-04-26 11:52:06,814 : INFO : Processed 350/1000 users (35.0%) - Elapsed: 753.67s - Est. remaining: 1399.67s\n",
      "2025-04-26 11:53:54,725 : INFO : Processed 400/1000 users (40.0%) - Elapsed: 861.58s - Est. remaining: 1292.37s\n",
      "2025-04-26 11:55:42,465 : INFO : Processed 450/1000 users (45.0%) - Elapsed: 969.32s - Est. remaining: 1184.72s\n",
      "2025-04-26 11:57:30,172 : INFO : Processed 500/1000 users (50.0%) - Elapsed: 1077.03s - Est. remaining: 1077.03s\n",
      "2025-04-26 11:59:18,076 : INFO : Processed 550/1000 users (55.0%) - Elapsed: 1184.93s - Est. remaining: 969.49s\n",
      "2025-04-26 12:01:05,554 : INFO : Processed 600/1000 users (60.0%) - Elapsed: 1292.41s - Est. remaining: 861.61s\n",
      "2025-04-26 12:02:53,326 : INFO : Processed 650/1000 users (65.0%) - Elapsed: 1400.18s - Est. remaining: 753.94s\n",
      "2025-04-26 12:04:40,871 : INFO : Processed 700/1000 users (70.0%) - Elapsed: 1507.72s - Est. remaining: 646.17s\n",
      "2025-04-26 12:06:28,797 : INFO : Processed 750/1000 users (75.0%) - Elapsed: 1615.65s - Est. remaining: 538.55s\n",
      "2025-04-26 12:08:17,555 : INFO : Processed 800/1000 users (80.0%) - Elapsed: 1724.41s - Est. remaining: 431.10s\n",
      "2025-04-26 12:10:05,403 : INFO : Processed 850/1000 users (85.0%) - Elapsed: 1832.26s - Est. remaining: 323.34s\n",
      "2025-04-26 12:11:47,251 : INFO : Processed 900/1000 users (90.0%) - Elapsed: 1934.11s - Est. remaining: 214.90s\n",
      "2025-04-26 12:13:29,309 : INFO : Processed 950/1000 users (95.0%) - Elapsed: 2036.16s - Est. remaining: 107.17s\n",
      "2025-04-26 12:15:11,316 : INFO : Processed 1000/1000 users (100.0%) - Elapsed: 2138.17s - Est. remaining: 0.00s\n",
      "2025-04-26 12:15:11,481 : INFO : Generated recommendations for 1000/1000 users\n",
      "2025-04-26 12:15:11,485 : INFO : After generating recommendations: 1708.31 MB\n",
      "2025-04-26 12:15:11,516 : INFO : Saved recommendations for 1000 users\n",
      "2025-04-26 12:15:26,968 : INFO : Saved 20000 recommendations to CSV\n",
      "2025-04-26 12:15:26,968 : INFO : After saving recommendations: 1708.52 MB\n",
      "2025-04-26 12:15:26,969 : INFO : Evaluating DNN recommendations with enhanced metrics\n",
      "2025-04-26 12:15:26,969 : INFO : Evaluating recommendations with comprehensive metrics\n",
      "2025-04-26 12:15:26,970 : INFO : Test users: 200, Users with recommendations: 1000\n",
      "2025-04-26 12:15:26,971 : INFO : Common users for evaluation: 200\n",
      "2025-04-26 12:18:22,402 : INFO : Evaluation completed:\n",
      "2025-04-26 12:18:22,402 : INFO : Accuracy: 0.7041\n",
      "2025-04-26 12:18:22,402 : INFO : Precision: 0.7350\n",
      "2025-04-26 12:18:22,403 : INFO : Recall: 0.8148\n",
      "2025-04-26 12:18:22,403 : INFO : F1 Score: 0.7728\n",
      "2025-04-26 12:18:22,404 : INFO : RMSE: 1.1711\n",
      "2025-04-26 12:18:22,404 : INFO : MAE: 0.9105\n",
      "2025-04-26 12:18:22,404 : INFO : NDCG: 0.3155\n",
      "2025-04-26 12:18:22,404 : INFO : MAP: 1.0000\n",
      "2025-04-26 12:18:22,405 : INFO : MRR: 0.1250\n",
      "2025-04-26 12:18:22,406 : INFO : Predictions: 5234\n",
      "2025-04-26 12:18:22,682 : INFO : After evaluation: 1738.20 MB\n",
      "2025-04-26 12:18:22,685 : INFO : Saved evaluation metrics\n",
      "2025-04-26 12:18:22,688 : INFO : Saved per-user metrics for 200 users\n",
      "C:\\Users\\NCPC\\AppData\\Local\\Temp\\ipykernel_33180\\4058965897.py:1826: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  metrics_by_count = user_analysis.groupby('rating_count_bin').agg({\n",
      "2025-04-26 12:18:22,812 : WARNING : posx and posy should be finite values\n",
      "2025-04-26 12:18:22,829 : WARNING : posx and posy should be finite values\n",
      "2025-04-26 12:18:22,842 : WARNING : posx and posy should be finite values\n",
      "2025-04-26 12:18:22,855 : WARNING : posx and posy should be finite values\n",
      "2025-04-26 12:18:22,866 : WARNING : posx and posy should be finite values\n",
      "2025-04-26 12:18:22,881 : WARNING : posx and posy should be finite values\n",
      "2025-04-26 12:18:22,897 : WARNING : posx and posy should be finite values\n",
      "2025-04-26 12:18:22,913 : WARNING : posx and posy should be finite values\n",
      "2025-04-26 12:18:22,928 : WARNING : posx and posy should be finite values\n",
      "2025-04-26 12:18:22,943 : WARNING : posx and posy should be finite values\n",
      "2025-04-26 12:18:23,000 : WARNING : posx and posy should be finite values\n",
      "2025-04-26 12:18:23,014 : WARNING : posx and posy should be finite values\n",
      "2025-04-26 12:18:23,027 : WARNING : posx and posy should be finite values\n",
      "2025-04-26 12:18:23,043 : WARNING : posx and posy should be finite values\n",
      "2025-04-26 12:18:23,070 : WARNING : posx and posy should be finite values\n",
      "2025-04-26 12:18:23,076 : INFO : Created metrics analysis by user rating count\n",
      "2025-04-26 12:18:23,077 : INFO : \n",
      "Sample recommendation for exploration:\n",
      "2025-04-26 12:18:23,081 : INFO : \n",
      "User 65 Preferences:\n",
      "2025-04-26 12:18:23,082 : INFO : - Most liked genres: Drama (0.66), Action (0.42), Thriller (0.39)\n",
      "2025-04-26 12:18:23,083 : INFO : - Most disliked genres: \n",
      "2025-04-26 12:18:23,083 : INFO : - Preferred regions: North America (1.00), Oceania (0.13), East Asia (0.01)\n",
      "2025-04-26 12:18:23,084 : INFO : \n",
      "Top 10 recommendations for user 65:\n",
      "2025-04-26 12:18:23,087 : INFO : 1. Mind Game (2004) - Rating: 5.00 - Genres: Adventure, Animation, Comedy, ...\n",
      "2025-04-26 12:18:23,090 : INFO : 2. Dear Diary (Caro Diario) (1994) - Rating: 5.00 - Genres: Comedy, Drama, Western Europe\n",
      "2025-04-26 12:18:23,093 : INFO : 3. Harakiri (Seppuku) (1962) - Rating: 5.00 - Genres: Drama\n",
      "2025-04-26 12:18:23,093 : INFO : 4. Singapore Sling (Singapore sling: O anthropos pou agapise ena ptoma) (1990) - Rating: 5.00 - Genres: Crime, Film-Noir, Horror, ...\n",
      "2025-04-26 12:18:23,096 : INFO : 5. Eyes Without a Face (Yeux sans visage, Les) (1959) - Rating: 5.00 - Genres: Horror, Western Europe\n",
      "2025-04-26 12:18:23,097 : INFO : 6. Sorrow and the Pity, The (Le chagrin et la pitié) (1969) - Rating: 4.99 - Genres: Documentary, War, Western Europe\n",
      "2025-04-26 12:18:23,100 : INFO : 7. Mesrine: Killer Instinct (L'instinct de mort) (2008) - Rating: 4.99 - Genres: Action, Crime, Drama, ...\n",
      "2025-04-26 12:18:23,103 : INFO : 8. Unforgettable Summer, An (Un été inoubliable) (1994) - Rating: 4.99 - Genres: Drama, Eastern Europe, Western Europe\n",
      "2025-04-26 12:18:23,105 : INFO : 9. Callas Forever (2002) - Rating: 4.99 - Genres: Drama, Eastern Europe, Western Europe\n",
      "2025-04-26 12:18:23,106 : INFO : 10. Royal Affair, A (Kongelig affære, En) (2012) - Rating: 4.99 - Genres: Drama, Romance, Eastern Europe, ...\n",
      "2025-04-26 12:18:23,106 : INFO : \n",
      "Evaluation metrics for user 65:\n",
      "2025-04-26 12:18:23,107 : INFO : - RMSE: 1.0098\n",
      "2025-04-26 12:18:23,107 : INFO : - Accuracy: 0.9375\n",
      "2025-04-26 12:18:23,107 : INFO : - F1 Score: 0.9677\n",
      "2025-04-26 12:18:23,108 : INFO : - Number of predictions: 16\n",
      "2025-04-26 12:18:23,108 : INFO : Final memory usage: 1744.31 MB\n",
      "2025-04-26 12:18:23,109 : INFO : Enhanced DNN-based recommendation pipeline completed successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import logging\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, Input, Concatenate, Embedding, Flatten, Add\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter, defaultdict\n",
    "import time\n",
    "import gc\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "input_path = \"./processed/\"\n",
    "output_path = \"./rec/collaborative-recommendations\"\n",
    "top_n = 20\n",
    "\n",
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)\n",
    "\n",
    "# Optimized hyperparameters based on extensive testing\n",
    "dnn_hidden_layers = [256, 128, 64, 32]  # Deeper network\n",
    "dnn_dropout_rate = 0.35  # Increased dropout for better generalization\n",
    "dnn_l2_reg = 0.0005  # L2 regularization to prevent overfitting\n",
    "dnn_learning_rate = 0.001  # Lower learning rate for more stable convergence\n",
    "dnn_batch_size = 256  # Larger batch size for better gradient estimates\n",
    "dnn_epochs = 30 # More epochs with early stopping\n",
    "threshold_rating = 3  # Rating threshold for binary classification\n",
    "early_stopping_patience = 8  # Wait longer for improvement\n",
    "use_cosine_annealing = True  # Use cosine annealing learning rate schedule\n",
    "use_attention_mechanism = True  # Use attention mechanism for feature interaction\n",
    "\n",
    "def log_memory_usage(message=\"Current memory usage\"):\n",
    "    \"\"\"Log current memory usage\"\"\"\n",
    "    try:\n",
    "        import psutil\n",
    "        process = psutil.Process(os.getpid())\n",
    "        memory_info = process.memory_info()\n",
    "        memory_usage_mb = memory_info.rss / 1024 / 1024\n",
    "        logger.info(f\"{message}: {memory_usage_mb:.2f} MB\")\n",
    "    except ImportError:\n",
    "        logger.warning(\"psutil not available for memory monitoring\")\n",
    "\n",
    "def load_data():\n",
    "    \"\"\"\n",
    "    Load and prepare data for model training with improved memory management\n",
    "    \"\"\"\n",
    "    data = {}\n",
    "    log_memory_usage(\"Before loading data\")\n",
    "    \n",
    "    movie_features_path = os.path.join(input_path, 'processed_movie_features.csv')\n",
    "    if os.path.exists(movie_features_path):\n",
    "        # Use optimized loading for large CSV files with appropriate dtypes\n",
    "        data['movie_features'] = pd.read_csv(movie_features_path, \n",
    "                                            dtype={'movieId': int, 'token_count': int})\n",
    "        logger.info(f\"Loaded movie features with shape {data['movie_features'].shape}\")\n",
    "    else:\n",
    "        logger.error(f\"File not found: {movie_features_path}\")\n",
    "        return None\n",
    "    \n",
    "    ratings_path = os.path.join(input_path, 'normalized_ratings.csv')\n",
    "    if os.path.exists(ratings_path):\n",
    "        # Load ratings in chunks to manage memory better\n",
    "        chunk_size = 100000\n",
    "        chunks = []\n",
    "        for chunk in pd.read_csv(ratings_path, chunksize=chunk_size):\n",
    "            chunks.append(chunk)\n",
    "            # Force garbage collection after each chunk\n",
    "            gc.collect()\n",
    "        \n",
    "        data['ratings'] = pd.concat(chunks)\n",
    "        logger.info(f\"Loaded ratings with shape {data['ratings'].shape}\")\n",
    "    else:\n",
    "        logger.error(f\"File not found: {ratings_path}\")\n",
    "        return None\n",
    "    \n",
    "    log_memory_usage(\"After loading data\")\n",
    "    \n",
    "    if 'ratings' in data:\n",
    "        # Create improved train/test split\n",
    "        logger.info(\"Creating improved train/test split\")\n",
    "        \n",
    "        # Set seed for reproducibility\n",
    "        np.random.seed(42)\n",
    "        \n",
    "        # First split: separate users for training and testing\n",
    "        all_user_ids = data['ratings']['userId'].unique()\n",
    "        np.random.shuffle(all_user_ids)\n",
    "        \n",
    "        # Use 80% of users for complete training\n",
    "        split_idx = int(len(all_user_ids) * 0.8)\n",
    "        train_users = all_user_ids[:split_idx]\n",
    "        test_users = all_user_ids[split_idx:]\n",
    "        \n",
    "        # Full training data from train users\n",
    "        train_ratings_main = data['ratings'][data['ratings']['userId'].isin(train_users)]\n",
    "        \n",
    "        # For users in test set, split their ratings temporally\n",
    "        test_user_ratings = data['ratings'][data['ratings']['userId'].isin(test_users)]\n",
    "        train_chunks = []\n",
    "        test_chunks = []\n",
    "        \n",
    "        # Process each test user\n",
    "        for user_id in test_users:\n",
    "            user_data = test_user_ratings[test_user_ratings['userId'] == user_id]\n",
    "            \n",
    "            # Skip users with too few ratings\n",
    "            if len(user_data) < 5:\n",
    "                continue\n",
    "                \n",
    "            # Sort by timestamp if available\n",
    "            if 'timestamp' in user_data.columns:\n",
    "                user_data = user_data.sort_values('timestamp')\n",
    "            \n",
    "            # Take first 80% for training, last 20% for testing (temporal split)\n",
    "            split_idx = int(len(user_data) * 0.8)\n",
    "            train_chunks.append(user_data.iloc[:split_idx])\n",
    "            test_chunks.append(user_data.iloc[split_idx:])\n",
    "        \n",
    "        # Combine training data from both sources\n",
    "        data['train_ratings'] = pd.concat([train_ratings_main] + train_chunks) if train_chunks else train_ratings_main\n",
    "        data['test_ratings'] = pd.concat(test_chunks) if test_chunks else pd.DataFrame()\n",
    "        \n",
    "        # Log split statistics\n",
    "        logger.info(f\"Training set: {len(data['train_ratings'])} ratings from {len(data['train_ratings']['userId'].unique())} users\")\n",
    "        logger.info(f\"Test set: {len(data['test_ratings'])} ratings from {len(data['test_ratings']['userId'].unique())} users\")\n",
    "        \n",
    "        # Force garbage collection\n",
    "        del train_ratings_main, test_user_ratings, train_chunks, test_chunks\n",
    "        gc.collect()\n",
    "    \n",
    "    # Extract region columns with better handling\n",
    "    region_columns = [col for col in data['movie_features'].columns \n",
    "                     if col in ['North America', 'Europe', 'East Asia', 'South Asia', \n",
    "                               'Southeast Asia', 'Oceania', 'Middle East', 'Africa', \n",
    "                               'Latin America', 'Other']]\n",
    "    \n",
    "    if region_columns:\n",
    "        logger.info(f\"Found {len(region_columns)} region features: {region_columns}\")\n",
    "        data['region_columns'] = region_columns\n",
    "    \n",
    "    log_memory_usage(\"After split preparation\")\n",
    "    return data\n",
    "\n",
    "def extract_genre_and_region_features(movie_features):\n",
    "    \"\"\"\n",
    "    Extract enhanced genre and region features from movie data\n",
    "    \"\"\"\n",
    "    # Better identification of genre columns\n",
    "    genre_columns = [col for col in movie_features.columns if col not in \n",
    "                     ['movieId', 'title', 'tokens', 'token_count', 'top_keywords'] and\n",
    "                     col not in ['North America', 'Europe', 'East Asia', 'South Asia', \n",
    "                                'Southeast Asia', 'Oceania', 'Middle East', 'Africa', \n",
    "                                'Latin America', 'Other']]\n",
    "    \n",
    "    region_columns = [col for col in movie_features.columns \n",
    "                     if col in ['North America', 'Europe', 'East Asia', 'South Asia', \n",
    "                               'Southeast Asia', 'Oceania', 'Middle East', 'Africa', \n",
    "                               'Latin America', 'Other']]\n",
    "    \n",
    "    if not genre_columns:\n",
    "        logger.error(\"No genre columns found in movie features\")\n",
    "        return None\n",
    "    \n",
    "    # Extract features\n",
    "    movie_genre_features = movie_features[['movieId'] + genre_columns].copy()\n",
    "    \n",
    "    # Add region features if available\n",
    "    if region_columns:\n",
    "        movie_region_features = movie_features[['movieId'] + region_columns].copy()\n",
    "        # Combine with genre features\n",
    "        movie_features_combined = pd.merge(\n",
    "            movie_genre_features,\n",
    "            movie_region_features,\n",
    "            on='movieId',\n",
    "            how='left'\n",
    "        )\n",
    "        \n",
    "        # Fill NaN values with 0\n",
    "        for col in region_columns:\n",
    "            if col in movie_features_combined.columns:\n",
    "                movie_features_combined[col] = movie_features_combined[col].fillna(0).astype(int)\n",
    "                \n",
    "        logger.info(f\"Extracted {len(genre_columns)} genre features and {len(region_columns)} region features\")\n",
    "        return movie_features_combined, genre_columns, region_columns\n",
    "    \n",
    "    logger.info(f\"Extracted {len(genre_columns)} genre features (no region features found)\")\n",
    "    return movie_genre_features, genre_columns, []\n",
    "\n",
    "def calculate_user_preferences(train_ratings, movie_features, feature_columns, rating_threshold=3):\n",
    "    \"\"\"\n",
    "    Calculate enhanced user preferences with improved weighting scheme\n",
    "    \"\"\"\n",
    "    logger.info(f\"Calculating user preferences for {len(feature_columns)} features\")\n",
    "    \n",
    "    user_preferences = []\n",
    "    \n",
    "    total_users = len(train_ratings['userId'].unique())\n",
    "    processed_users = 0\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Calculate global average rating\n",
    "    global_avg_rating = train_ratings['rating'].mean()\n",
    "    \n",
    "    # Process users in batches to manage memory\n",
    "    user_batch_size = 1000\n",
    "    user_batches = np.array_split(train_ratings['userId'].unique(), \n",
    "                                max(1, total_users // user_batch_size))\n",
    "    \n",
    "    for batch_idx, user_batch in enumerate(user_batches):\n",
    "        batch_preferences = []\n",
    "        \n",
    "        for user_id in user_batch:\n",
    "            user_ratings = train_ratings[train_ratings['userId'] == user_id]\n",
    "            \n",
    "            if len(user_ratings) == 0:\n",
    "                continue\n",
    "            \n",
    "            # Calculate user's average rating and bias\n",
    "            user_avg_rating = user_ratings['rating'].mean()\n",
    "            user_bias = user_avg_rating - global_avg_rating\n",
    "            \n",
    "            # Split into liked and disliked movies with more granular approach\n",
    "            # Use original unbiased ratings\n",
    "            strongly_liked_movies = user_ratings[user_ratings['rating'] >= rating_threshold + 0.5]['movieId'].values\n",
    "            liked_movies = user_ratings[(user_ratings['rating'] >= rating_threshold) & \n",
    "                                        (user_ratings['rating'] < rating_threshold + 0.5)]['movieId'].values\n",
    "            neutral_movies = user_ratings[(user_ratings['rating'] >= rating_threshold - 0.5) & \n",
    "                                         (user_ratings['rating'] < rating_threshold)]['movieId'].values\n",
    "            disliked_movies = user_ratings[user_ratings['rating'] < rating_threshold - 0.5]['movieId'].values\n",
    "            \n",
    "            feature_preferences = {}\n",
    "            \n",
    "            for feature in feature_columns:\n",
    "                # Calculate weighted feature preference\n",
    "                strongly_liked_feature = movie_features[movie_features['movieId'].isin(strongly_liked_movies)][feature].sum()\n",
    "                liked_feature = movie_features[movie_features['movieId'].isin(liked_movies)][feature].sum()\n",
    "                neutral_feature = movie_features[movie_features['movieId'].isin(neutral_movies)][feature].sum()\n",
    "                disliked_feature = movie_features[movie_features['movieId'].isin(disliked_movies)][feature].sum()\n",
    "                \n",
    "                # Count movies in each category\n",
    "                strongly_liked_count = len(strongly_liked_movies) if len(strongly_liked_movies) > 0 else 1\n",
    "                liked_count = len(liked_movies) if len(liked_movies) > 0 else 1\n",
    "                neutral_count = len(neutral_movies) if len(neutral_movies) > 0 else 1\n",
    "                disliked_count = len(disliked_movies) if len(disliked_movies) > 0 else 1\n",
    "                \n",
    "                # Apply progressive weighting\n",
    "                strongly_liked_weight = 1.0\n",
    "                liked_weight = 0.7\n",
    "                neutral_weight = 0.2\n",
    "                disliked_weight = -0.8\n",
    "                \n",
    "                # Calculate weighted feature preference\n",
    "                preference = (\n",
    "                    strongly_liked_weight * (strongly_liked_feature / strongly_liked_count) +\n",
    "                    liked_weight * (liked_feature / liked_count) -\n",
    "                    neutral_weight * (neutral_feature / neutral_count) -\n",
    "                    disliked_weight * (disliked_feature / disliked_count)\n",
    "                )\n",
    "                \n",
    "                feature_preferences[feature] = preference\n",
    "            \n",
    "            # Normalize preferences to -1 to 1 range\n",
    "            max_abs_preference = max(abs(val) for val in feature_preferences.values()) if feature_preferences else 1\n",
    "            \n",
    "            for feature in feature_preferences:\n",
    "                feature_preferences[feature] = feature_preferences[feature] / max_abs_preference if max_abs_preference > 0 else 0\n",
    "            \n",
    "            feature_preferences['userId'] = user_id\n",
    "            \n",
    "            batch_preferences.append(feature_preferences)\n",
    "            \n",
    "            processed_users += 1\n",
    "        \n",
    "        # Add batch to main list\n",
    "        user_preferences.extend(batch_preferences)\n",
    "        \n",
    "        # Log progress\n",
    "        progress = processed_users / total_users * 100\n",
    "        elapsed = time.time() - start_time\n",
    "        remaining = elapsed * (total_users - processed_users) / processed_users if processed_users > 0 else 0\n",
    "        \n",
    "        logger.info(f\"Processed {processed_users}/{total_users} users ({progress:.1f}%) - Elapsed: {elapsed:.2f}s - Est. remaining: {remaining:.2f}s\")\n",
    "        \n",
    "        # Force garbage collection\n",
    "        gc.collect()\n",
    "    \n",
    "    user_preferences_df = pd.DataFrame(user_preferences)\n",
    "    logger.info(f\"Created preferences for {len(user_preferences_df)} users\")\n",
    "    \n",
    "    return user_preferences_df\n",
    "\n",
    "def prepare_dnn_training_data(train_ratings, user_preferences, movie_features, genre_columns, region_columns=None, threshold=3, max_samples=1000000):\n",
    "    \"\"\"\n",
    "    Prepare enhanced training data for DNN model with improved feature engineering\n",
    "    \"\"\"\n",
    "    logger.info(\"Preparing training data for DNN model with enhanced features\")\n",
    "    \n",
    "    # Include both genre and region columns for feature vectors\n",
    "    feature_columns = genre_columns.copy()\n",
    "    if region_columns:\n",
    "        feature_columns.extend(region_columns)\n",
    "    \n",
    "    features = []\n",
    "    labels = []\n",
    "    \n",
    "    # Calculate global stats\n",
    "    global_avg_rating = train_ratings['rating'].mean()\n",
    "    \n",
    "    # Calculate user stats\n",
    "    user_stats = {}\n",
    "    for user_id in user_preferences['userId'].unique():\n",
    "        user_ratings = train_ratings[train_ratings['userId'] == user_id]\n",
    "        if len(user_ratings) > 0:\n",
    "            user_stats[user_id] = {\n",
    "                'avg': user_ratings['rating'].mean(),\n",
    "                'std': user_ratings['rating'].std(),\n",
    "                'count': len(user_ratings)\n",
    "            }\n",
    "    \n",
    "    # Calculate movie stats\n",
    "    movie_stats = {}\n",
    "    for movie_id in movie_features['movieId'].unique():\n",
    "        movie_ratings = train_ratings[train_ratings['movieId'] == movie_id]\n",
    "        if len(movie_ratings) > 0:\n",
    "            movie_stats[movie_id] = {\n",
    "                'avg': movie_ratings['rating'].mean(),\n",
    "                'std': movie_ratings['rating'].std(),\n",
    "                'count': len(movie_ratings)\n",
    "            }\n",
    "    \n",
    "    # Limit sample size for memory efficiency with stratification\n",
    "    if len(train_ratings) > max_samples:\n",
    "        # Stratify by rating to maintain distribution\n",
    "        bin_edges = [0, 1.5, 2.5, 3, 4.5, 5.1]  # Bins for ratings\n",
    "        train_ratings['rating_bin'] = pd.cut(train_ratings['rating'], bins=bin_edges, labels=False)\n",
    "        \n",
    "        # Sample from each bin proportionally\n",
    "        sampled_ratings = pd.DataFrame()\n",
    "        for bin_id in range(len(bin_edges)-1):\n",
    "            bin_data = train_ratings[train_ratings['rating_bin'] == bin_id]\n",
    "            bin_sample_size = int(max_samples * (len(bin_data) / len(train_ratings)))\n",
    "            \n",
    "            if len(bin_data) > bin_sample_size:\n",
    "                bin_sampled = bin_data.sample(bin_sample_size, random_state=42)\n",
    "            else:\n",
    "                bin_sampled = bin_data\n",
    "                \n",
    "            sampled_ratings = pd.concat([sampled_ratings, bin_sampled])\n",
    "        \n",
    "        # Clean up\n",
    "        sampled_ratings = sampled_ratings.drop(columns=['rating_bin'])\n",
    "    else:\n",
    "        sampled_ratings = train_ratings\n",
    "    \n",
    "    # Process in batches for memory efficiency\n",
    "    batch_size = 10000\n",
    "    total_ratings = len(sampled_ratings)\n",
    "    processed_ratings = 0\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for batch_start in range(0, total_ratings, batch_size):\n",
    "        batch_end = min(batch_start + batch_size, total_ratings)\n",
    "        ratings_batch = sampled_ratings.iloc[batch_start:batch_end]\n",
    "        \n",
    "        batch_features = []\n",
    "        batch_labels = []\n",
    "        \n",
    "        for _, row in ratings_batch.iterrows():\n",
    "            user_id = row['userId']\n",
    "            movie_id = row['movieId']\n",
    "            rating = row['rating']\n",
    "            \n",
    "            # Convert rating to binary label based on threshold\n",
    "            binary_label = 1 if rating > threshold else 0\n",
    "            \n",
    "            if user_id not in user_preferences['userId'].values or \\\n",
    "               movie_id not in movie_features['movieId'].values:\n",
    "                continue\n",
    "            \n",
    "            user_prefs = user_preferences[user_preferences['userId'] == user_id].iloc[0]\n",
    "            \n",
    "            movie_row = movie_features[movie_features['movieId'] == movie_id]\n",
    "            if movie_row.empty:\n",
    "                continue\n",
    "                \n",
    "            movie_features_row = movie_row.iloc[0]\n",
    "            \n",
    "            # Create enhanced feature vector with rating context\n",
    "            feature_vector = []\n",
    "            \n",
    "            # Add user and movie bias features\n",
    "            user_info = user_stats.get(user_id, {'avg': global_avg_rating, 'std': 0.5, 'count': 0})\n",
    "            movie_info = movie_stats.get(movie_id, {'avg': global_avg_rating, 'std': 0.5, 'count': 0})\n",
    "            \n",
    "            # Add global context features\n",
    "            feature_vector.append(global_avg_rating / 5.0)  # Normalize to 0-1\n",
    "            \n",
    "            # Add user context features (normalized)\n",
    "            feature_vector.append(user_info['avg'] / 5.0)  # User average rating\n",
    "            feature_vector.append(min(1.0, user_info['std'] / 2.0))  # User rating variability\n",
    "            feature_vector.append(min(1.0, np.log1p(user_info['count']) / 10.0))  # User experience\n",
    "            \n",
    "            # Add movie context features (normalized)\n",
    "            feature_vector.append(movie_info['avg'] / 5.0)  # Movie average rating\n",
    "            feature_vector.append(min(1.0, movie_info['std'] / 2.0))  # Movie rating variability \n",
    "            feature_vector.append(min(1.0, np.log1p(movie_info['count']) / 10.0))  # Movie popularity\n",
    "            \n",
    "            # Add user-movie difference feature\n",
    "            feature_vector.append((user_info['avg'] - movie_info['avg'] + 2.5) / 5.0)  # Normalized difference\n",
    "            \n",
    "            # Add category features with more sophisticated interaction\n",
    "            for feature in feature_columns:\n",
    "                user_pref = user_prefs[feature]\n",
    "                movie_feat = movie_features_row[feature]\n",
    "                \n",
    "                # Add user preference\n",
    "                feature_vector.append(user_pref)\n",
    "                \n",
    "                # Add movie feature\n",
    "                feature_vector.append(movie_feat)\n",
    "                \n",
    "                # Add interaction features\n",
    "                feature_vector.append(user_pref * movie_feat)  # Product\n",
    "                feature_vector.append(user_pref + movie_feat - 0.5)  # Sum (normalized)\n",
    "                feature_vector.append(abs(user_pref - movie_feat))  # Absolute difference\n",
    "            \n",
    "            batch_features.append(feature_vector)\n",
    "            batch_labels.append(binary_label)\n",
    "        \n",
    "        features.extend(batch_features)\n",
    "        labels.extend(batch_labels)\n",
    "        \n",
    "        processed_ratings += len(ratings_batch)\n",
    "        \n",
    "        if batch_start % (10 * batch_size) == 0:\n",
    "            elapsed = time.time() - start_time\n",
    "            progress = processed_ratings / total_ratings * 100\n",
    "            remaining = elapsed * (total_ratings - processed_ratings) / processed_ratings if processed_ratings > 0 else 0\n",
    "            logger.info(f\"Processed {processed_ratings}/{total_ratings} ratings ({progress:.1f}%) - Elapsed: {elapsed:.2f}s - Est. remaining: {remaining:.2f}s\")\n",
    "        \n",
    "        gc.collect()\n",
    "    \n",
    "    X = np.array(features, dtype=np.float32)\n",
    "    y = np.array(labels, dtype=np.float32)\n",
    "    \n",
    "    # Split the data into training and validation sets with stratification\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "    \n",
    "    logger.info(f\"Created training data: X_train shape {X_train.shape}, y_train shape {y_train.shape}\")\n",
    "    logger.info(f\"Created validation data: X_val shape {X_val.shape}, y_val shape {y_val.shape}\")\n",
    "    \n",
    "    # Check class distribution\n",
    "    train_pos = np.sum(y_train)\n",
    "    train_neg = len(y_train) - train_pos\n",
    "    val_pos = np.sum(y_val)\n",
    "    val_neg = len(y_val) - val_pos\n",
    "    \n",
    "    logger.info(f\"Training set class distribution: Positive {train_pos} ({train_pos/len(y_train)*100:.1f}%), Negative {train_neg} ({train_neg/len(y_train)*100:.1f}%)\")\n",
    "    logger.info(f\"Validation set class distribution: Positive {val_pos} ({val_pos/len(y_val)*100:.1f}%), Negative {val_neg} ({val_neg/len(y_val)*100:.1f}%)\")\n",
    "    \n",
    "    return X_train, X_val, y_train, y_val, feature_columns\n",
    "\n",
    "def f1_metric(y_true, y_pred):\n",
    "    \"\"\"Custom F1 score metric for Keras\"\"\"\n",
    "    # Calculate precision and recall\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    \n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    \n",
    "    # Calculate F1 score\n",
    "    f1 = 2 * (precision * recall) / (precision + recall + K.epsilon())\n",
    "    return f1\n",
    "\n",
    "def focal_loss(alpha=0.25, gamma=2.0):\n",
    "    \"\"\"\n",
    "    Focal loss for better handling of class imbalance\n",
    "    \n",
    "    Parameters:\n",
    "    alpha: Weighting factor for the rare class (positive)\n",
    "    gamma: Focusing parameter to down-weight easy examples\n",
    "    \"\"\"\n",
    "    def focal_loss_fixed(y_true, y_pred):\n",
    "        pt_1 = tf.where(tf.equal(y_true, 1), y_pred, tf.ones_like(y_pred))\n",
    "        pt_0 = tf.where(tf.equal(y_true, 0), y_pred, tf.zeros_like(y_pred))\n",
    "        \n",
    "        # Calculate loss with focal weighting\n",
    "        loss = -K.sum(alpha * K.pow(1. - pt_1, gamma) * K.log(pt_1 + K.epsilon())) - \\\n",
    "               K.sum((1 - alpha) * K.pow(pt_0, gamma) * K.log(1. - pt_0 + K.epsilon()))\n",
    "               \n",
    "        # Normalize by batch size\n",
    "        return loss / K.cast(K.shape(y_true)[0], 'float32')\n",
    "    \n",
    "    return focal_loss_fixed\n",
    "\n",
    "class SelfAttentionLayer(tf.keras.layers.Layer):\n",
    "    \"\"\"Properly implemented self-attention layer that handles 2D inputs\"\"\"\n",
    "    def __init__(self, hidden_units, **kwargs):\n",
    "        super(SelfAttentionLayer, self).__init__(**kwargs)\n",
    "        self.hidden_units = hidden_units\n",
    "        self.supports_masking = True\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        # Input shape validation\n",
    "        if len(input_shape) < 2:\n",
    "            raise ValueError(f\"Input shape must be at least 2D, got {input_shape}\")\n",
    "            \n",
    "        # Determine if we need to reshape 2D input\n",
    "        self.needs_reshape = len(input_shape) == 2\n",
    "        input_dim = input_shape[-1]\n",
    "        \n",
    "        # Create trainable weights\n",
    "        self.query_dense = tf.keras.layers.Dense(self.hidden_units)\n",
    "        self.key_dense = tf.keras.layers.Dense(self.hidden_units)\n",
    "        self.value_dense = tf.keras.layers.Dense(self.hidden_units)\n",
    "        self.combine_dense = tf.keras.layers.Dense(input_dim)\n",
    "        \n",
    "        self.built = True\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        # Handle 2D inputs by reshaping to 3D (batch_size, 1, features)\n",
    "        original_shape = tf.shape(inputs)\n",
    "        needs_reshape = len(inputs.shape) == 2\n",
    "        \n",
    "        if needs_reshape:\n",
    "            # Add sequence dimension of length 1\n",
    "            inputs = tf.expand_dims(inputs, axis=1)\n",
    "        \n",
    "        # Apply transformations\n",
    "        query = self.query_dense(inputs)\n",
    "        key = self.key_dense(inputs)\n",
    "        value = self.value_dense(inputs)\n",
    "        \n",
    "        # Calculate attention scores - use standard matrix multiplication\n",
    "        # (batch_size, seq_len, hidden) × (batch_size, hidden, seq_len) \n",
    "        # → (batch_size, seq_len, seq_len)\n",
    "        key_transposed = tf.transpose(key, perm=[0, 2, 1])\n",
    "        scores = tf.matmul(query, key_transposed)\n",
    "        \n",
    "        # Scale scores\n",
    "        scores = scores / tf.math.sqrt(tf.cast(self.hidden_units, dtype=tf.float32))\n",
    "        \n",
    "        # Apply softmax to get attention weights\n",
    "        weights = tf.nn.softmax(scores, axis=-1)\n",
    "        \n",
    "        # Apply attention weights to values\n",
    "        context = tf.matmul(weights, value)\n",
    "        \n",
    "        # Final transformation\n",
    "        output = self.combine_dense(context)\n",
    "        \n",
    "        # Add residual connection\n",
    "        output = output + inputs\n",
    "        \n",
    "        # Reshape back to original shape if needed\n",
    "        if needs_reshape:\n",
    "            output = tf.squeeze(output, axis=1)\n",
    "            \n",
    "        return output\n",
    "        \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        # Output shape is same as input shape\n",
    "        return input_shape\n",
    "        \n",
    "    def get_config(self):\n",
    "        config = super(SelfAttentionLayer, self).get_config()\n",
    "        config.update({\n",
    "            'hidden_units': self.hidden_units\n",
    "        })\n",
    "        return config\n",
    "\n",
    "\n",
    "def attention_block(x, hidden_units):\n",
    "    \"\"\"Wrapper function to apply the attention layer\"\"\"\n",
    "    # Create the attention layer\n",
    "    attention_layer = SelfAttentionLayer(hidden_units)\n",
    "    \n",
    "    # Apply attention directly (no need to reshape first - layer handles that)\n",
    "    x = attention_layer(x)\n",
    "    \n",
    "    # Apply layer normalization\n",
    "    x = tf.keras.layers.LayerNormalization()(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "def build_and_train_dnn_model(X_train, X_val, y_train, y_val, learning_rate=0.0005, batch_size=256, epochs=50):\n",
    "    \"\"\"\n",
    "    Build and train an enhanced DNN model with advanced architecture and training techniques\n",
    "    \"\"\"\n",
    "    logger.info(\"Building and training enhanced DNN model\")\n",
    "    \n",
    "    # Configure GPU memory growth if available\n",
    "    gpus = tf.config.list_physical_devices('GPU')\n",
    "    if gpus:\n",
    "        try:\n",
    "            for gpu in gpus:\n",
    "                tf.config.experimental.set_memory_growth(gpu, True)\n",
    "            logger.info(f\"Found {len(gpus)} GPU(s), enabled memory growth\")\n",
    "        except RuntimeError as e:\n",
    "            logger.warning(f\"GPU config error: {e}\")\n",
    "    \n",
    "    input_dim = X_train.shape[1]\n",
    "    \n",
    "    # Create model with more sophisticated architecture\n",
    "    inputs = Input(shape=(input_dim,))\n",
    "    \n",
    "    # Normalize inputs\n",
    "    x = BatchNormalization()(inputs)\n",
    "    \n",
    "    # First block - extract latent representations\n",
    "    x = Dense(dnn_hidden_layers[0], activation='relu', kernel_regularizer=l2(dnn_l2_reg))(x)\n",
    "    x_shortcut1 = x  # Save for residual connection\n",
    "    x = Dropout(dnn_dropout_rate)(x)\n",
    "    \n",
    "    # Apply attention if enabled\n",
    "    if use_attention_mechanism:\n",
    "        x = attention_block(x, dnn_hidden_layers[0] // 2)\n",
    "    \n",
    "    # Middle layers with residual connections\n",
    "    for i, units in enumerate(dnn_hidden_layers[1:], 1):\n",
    "        # Normalization before each layer\n",
    "        x = BatchNormalization()(x)\n",
    "        \n",
    "        # Dense layer with regularization\n",
    "        x = Dense(units, activation='relu', kernel_regularizer=l2(dnn_l2_reg))(x)\n",
    "        \n",
    "        # Dropout for regularization\n",
    "        x = Dropout(dnn_dropout_rate)(x)\n",
    "        \n",
    "        # Add residual connection when dimensions match or after projection\n",
    "        if i == 1 and x_shortcut1.shape[-1] >= units:\n",
    "            # Project if needed then add\n",
    "            if x_shortcut1.shape[-1] > units:\n",
    "                shortcut = Dense(units, activation='linear')(x_shortcut1)\n",
    "            else:\n",
    "                shortcut = x_shortcut1\n",
    "            x = Add()([x, shortcut])\n",
    "    \n",
    "    # Final normalization\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    # Output layer with sigmoid activation for binary classification\n",
    "    outputs = Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    # Learning rate schedule with cosine annealing\n",
    "    if use_cosine_annealing:\n",
    "        lr_schedule = tf.keras.optimizers.schedules.CosineDecayRestarts(\n",
    "            initial_learning_rate=learning_rate,\n",
    "            first_decay_steps=int(len(X_train) / batch_size) * 5,  # 5 epochs\n",
    "            t_mul=2.0,  # Double period after each restart\n",
    "            m_mul=0.9,  # Slightly reduce max LR after each restart\n",
    "            alpha=1e-6  # Minimum LR\n",
    "        )\n",
    "        optimizer = Adam(learning_rate=lr_schedule, clipnorm=1.0)\n",
    "    else:\n",
    "        # Standard Adam optimizer with gradient clipping\n",
    "        optimizer = Adam(\n",
    "            learning_rate=learning_rate,\n",
    "            clipnorm=1.0\n",
    "        )\n",
    "    \n",
    "    # Compile with appropriate loss and metrics\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='binary_crossentropy',  # Standard loss for binary classification\n",
    "        metrics=[\n",
    "            'accuracy',\n",
    "            tf.keras.metrics.AUC(name='auc'),\n",
    "            tf.keras.metrics.Precision(name='precision'),\n",
    "            tf.keras.metrics.Recall(name='recall'),\n",
    "            f1_metric\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # Calculate class weights to handle imbalance\n",
    "    neg_count = len(y_train) - np.sum(y_train)\n",
    "    pos_count = np.sum(y_train)\n",
    "    pos_weight = (1 / pos_count) * ((neg_count + pos_count) / 2.0) if pos_count > 0 else 1.0\n",
    "    neg_weight = (1 / neg_count) * ((neg_count + pos_count) / 2.0) if neg_count > 0 else 1.0\n",
    "    \n",
    "    class_weight = {0: neg_weight, 1: pos_weight}\n",
    "    \n",
    "    logger.info(f\"Class weights: {class_weight}\")\n",
    "    import keras\n",
    "    keras_version = keras.__version__\n",
    "    model_ext = '.keras' if keras_version.startswith('3.') else '.h5'\n",
    "    # Enhanced callbacks\n",
    "    callbacks = [\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=early_stopping_patience,\n",
    "            restore_best_weights=True,\n",
    "            verbose=1\n",
    "        ),\n",
    "        # ReduceLROnPlateau is removed!\n",
    "        tf.keras.callbacks.ModelCheckpoint(\n",
    "            filepath=os.path.join(output_path, 'best_model.keras'),\n",
    "            monitor='val_auc',\n",
    "            save_best_only=True,\n",
    "            mode='max',\n",
    "            verbose=1\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    # Train the model with class weights\n",
    "    logger.info(f\"Training model with {epochs} max epochs, batch size {batch_size}\")\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        verbose=1,\n",
    "        callbacks=callbacks,\n",
    "        class_weight=class_weight  # Apply class weights\n",
    "    )\n",
    "    \n",
    "    # Evaluate on validation set\n",
    "    val_metrics = model.evaluate(X_val, y_val, verbose=1)\n",
    "    \n",
    "    # Extract metrics - order matches the model.compile metrics list\n",
    "    val_loss = val_metrics[0]\n",
    "    val_acc = val_metrics[1]\n",
    "    val_auc = val_metrics[2]\n",
    "    val_precision = val_metrics[3]\n",
    "    val_recall = val_metrics[4]\n",
    "    val_f1 = val_metrics[5]\n",
    "    \n",
    "    logger.info(f\"Model validation metrics:\")\n",
    "    logger.info(f\"- Loss: {val_loss:.4f}\")\n",
    "    logger.info(f\"- Accuracy: {val_acc:.4f}\")\n",
    "    logger.info(f\"- AUC: {val_auc:.4f}\")\n",
    "    logger.info(f\"- Precision: {val_precision:.4f}\")\n",
    "    logger.info(f\"- Recall: {val_recall:.4f}\")\n",
    "    logger.info(f\"- F1 Score: {val_f1:.4f}\")\n",
    "    \n",
    "    # Plot training history with more metrics\n",
    "    plt.figure(figsize=(18, 12))\n",
    "    \n",
    "    plt.subplot(2, 3, 1)\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(2, 3, 2)\n",
    "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(2, 3, 3)\n",
    "    plt.plot(history.history['auc'], label='Training AUC')\n",
    "    plt.plot(history.history['val_auc'], label='Validation AUC')\n",
    "    plt.title('AUC')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('AUC')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(2, 3, 4)\n",
    "    plt.plot(history.history['precision'], label='Training Precision')\n",
    "    plt.plot(history.history['val_precision'], label='Validation Precision')\n",
    "    plt.title('Precision')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(2, 3, 5)\n",
    "    plt.plot(history.history['recall'], label='Training Recall')\n",
    "    plt.plot(history.history['val_recall'], label='Validation Recall')\n",
    "    plt.title('Recall')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Recall')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(2, 3, 6)\n",
    "    plt.plot(history.history['f1_metric'], label='Training F1')\n",
    "    plt.plot(history.history['val_f1_metric'], label='Validation F1')\n",
    "    plt.title('F1 Score')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('F1 Score')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_path, 'dnn_training_history.png'))\n",
    "    plt.close()\n",
    "    \n",
    "    # Create additional visualization - ROC curve\n",
    "    y_pred_prob = model.predict(X_val)\n",
    "    \n",
    "    from sklearn.metrics import roc_curve, auc\n",
    "    fpr, tpr, _ = roc_curve(y_val, y_pred_prob)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC)')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.savefig(os.path.join(output_path, 'roc_curve.png'))\n",
    "    plt.close()\n",
    "    \n",
    "    # Create precision-recall curve\n",
    "    from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "    precision, recall, _ = precision_recall_curve(y_val, y_pred_prob)\n",
    "    avg_precision = average_precision_score(y_val, y_pred_prob)\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.plot(recall, precision, color='blue', lw=2, label=f'PR curve (AP = {avg_precision:.2f})')\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title('Precision-Recall Curve')\n",
    "    plt.legend(loc=\"lower left\")\n",
    "    plt.savefig(os.path.join(output_path, 'precision_recall_curve.png'))\n",
    "    plt.close()\n",
    "    \n",
    "    return model, history\n",
    "\n",
    "def generate_user_movie_features(user_id, movie_id, user_preferences, movie_features, genre_columns, region_columns=None, user_stats=None, movie_stats=None, global_avg_rating=None):\n",
    "    \"\"\"\n",
    "    Generate enhanced feature vector for a user-movie pair\n",
    "    \"\"\"\n",
    "    if global_avg_rating is None:\n",
    "        global_avg_rating = 3.0\n",
    "    \n",
    "    if user_stats is None:\n",
    "        user_stats = {}\n",
    "    \n",
    "    if movie_stats is None:\n",
    "        movie_stats = {}\n",
    "        \n",
    "    feature_columns = genre_columns.copy()\n",
    "    if region_columns:\n",
    "        feature_columns.extend(region_columns)\n",
    "    \n",
    "    if user_id not in user_preferences['userId'].values or \\\n",
    "       movie_id not in movie_features['movieId'].values:\n",
    "        return None\n",
    "    \n",
    "    user_prefs = user_preferences[user_preferences['userId'] == user_id].iloc[0]\n",
    "    \n",
    "    movie_row = movie_features[movie_features['movieId'] == movie_id]\n",
    "    if movie_row.empty:\n",
    "        return None\n",
    "    \n",
    "    movie_features_row = movie_row.iloc[0]\n",
    "    \n",
    "    # Create enhanced feature vector with user/movie context\n",
    "    feature_vector = []\n",
    "    \n",
    "    # Get user and movie statistics\n",
    "    user_info = user_stats.get(user_id, {'avg': global_avg_rating, 'std': 0.5, 'count': 0})\n",
    "    movie_info = movie_stats.get(movie_id, {'avg': global_avg_rating, 'std': 0.5, 'count': 0})\n",
    "    \n",
    "    # Add global context features\n",
    "    feature_vector.append(global_avg_rating / 5.0)  # Normalize\n",
    "    \n",
    "    # Add user context features\n",
    "    feature_vector.append(user_info['avg'] / 5.0)  # User average rating\n",
    "    feature_vector.append(min(1.0, user_info['std'] / 2.0))  # User rating variability\n",
    "    feature_vector.append(min(1.0, np.log1p(user_info['count']) / 10.0))  # User experience\n",
    "    \n",
    "    # Add movie context features\n",
    "    feature_vector.append(movie_info['avg'] / 5.0)  # Movie average rating\n",
    "    feature_vector.append(min(1.0, movie_info['std'] / 2.0))  # Movie rating variability \n",
    "    feature_vector.append(min(1.0, np.log1p(movie_info['count']) / 10.0))  # Movie popularity\n",
    "    \n",
    "    # Add user-movie difference feature\n",
    "    feature_vector.append((user_info['avg'] - movie_info['avg'] + 2.5) / 5.0)  # Normalized difference\n",
    "    \n",
    "    # Add category features with more sophisticated interaction\n",
    "    for feature in feature_columns:\n",
    "        user_pref = user_prefs[feature]\n",
    "        movie_feat = movie_features_row[feature]\n",
    "        \n",
    "        # Add user preference\n",
    "        feature_vector.append(user_pref)\n",
    "        \n",
    "        # Add movie feature\n",
    "        feature_vector.append(movie_feat)\n",
    "        \n",
    "        # Add interaction features\n",
    "        feature_vector.append(user_pref * movie_feat)  # Product\n",
    "        feature_vector.append(user_pref + movie_feat - 0.5)  # Sum (normalized)\n",
    "        feature_vector.append(abs(user_pref - movie_feat))  # Absolute difference\n",
    "    \n",
    "    return np.array([feature_vector], dtype=np.float32)\n",
    "\n",
    "def generate_dnn_recommendations(user_id, dnn_model, user_preferences, movie_features, genre_columns, region_columns=None, train_ratings=None, user_stats=None, movie_stats=None, global_avg_rating=None, n=10):\n",
    "    \"\"\"\n",
    "    Generate movie recommendations for a user using the enhanced DNN model\n",
    "    \"\"\"\n",
    "    if global_avg_rating is None and train_ratings is not None:\n",
    "        global_avg_rating = train_ratings['rating'].mean()\n",
    "    elif global_avg_rating is None:\n",
    "        global_avg_rating = 3.0\n",
    "        \n",
    "    if user_id not in user_preferences['userId'].values:\n",
    "        logger.warning(f\"User {user_id} not found in preferences\")\n",
    "        return []\n",
    "    \n",
    "    # Get movies the user has already rated\n",
    "    rated_movies = set()\n",
    "    if train_ratings is not None:\n",
    "        rated_movies = set(train_ratings[train_ratings['userId'] == user_id]['movieId'].values)\n",
    "    \n",
    "    # Consider only unrated movies\n",
    "    unrated_movies = movie_features[~movie_features['movieId'].isin(rated_movies)]\n",
    "    \n",
    "    batch_size = 1000\n",
    "    all_predictions = []\n",
    "    \n",
    "    # Process in batches to avoid memory issues\n",
    "    for i in range(0, len(unrated_movies), batch_size):\n",
    "        batch = unrated_movies.iloc[i:i+batch_size]\n",
    "        \n",
    "        feature_vectors = []\n",
    "        movie_ids = []\n",
    "        \n",
    "        for _, movie_row in batch.iterrows():\n",
    "            movie_id = movie_row['movieId']\n",
    "            \n",
    "            # Generate features for this user-movie pair\n",
    "            feature_vector = generate_user_movie_features(\n",
    "                user_id, movie_id, \n",
    "                user_preferences, movie_features, \n",
    "                genre_columns, region_columns,\n",
    "                user_stats, movie_stats, global_avg_rating\n",
    "            )\n",
    "            \n",
    "            if feature_vector is not None:\n",
    "                feature_vectors.append(feature_vector[0])  # Flatten first dimension\n",
    "                movie_ids.append(movie_id)\n",
    "        \n",
    "        if not feature_vectors:\n",
    "            continue\n",
    "            \n",
    "        # Convert to numpy array for batch prediction\n",
    "        feature_array = np.array(feature_vectors)\n",
    "        \n",
    "        # Get probability scores (0-1)\n",
    "        like_probabilities = dnn_model.predict(feature_array, verbose=0).flatten()\n",
    "        \n",
    "        # Convert to rating scale for easier comparison\n",
    "        predicted_ratings = 0.5 + like_probabilities * 4.5\n",
    "        \n",
    "        for movie_id, pred in zip(movie_ids, predicted_ratings):\n",
    "            all_predictions.append((movie_id, float(pred)))\n",
    "    \n",
    "    # Sort by predicted rating\n",
    "    all_predictions.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    return all_predictions[:n]\n",
    "\n",
    "def generate_recommendations_for_all_users(dnn_model, user_preferences, movie_features, genre_columns, region_columns=None, train_ratings=None, n=10, batch_size=50, max_users=None):\n",
    "    \"\"\"\n",
    "    Generate recommendations for all users with improved memory management\n",
    "    \"\"\"\n",
    "    all_user_ids = user_preferences['userId'].unique()\n",
    "    \n",
    "    if max_users and max_users < len(all_user_ids):\n",
    "        user_ids = all_user_ids[:max_users]\n",
    "    else:\n",
    "        user_ids = all_user_ids\n",
    "    \n",
    "    logger.info(f\"Generating recommendations for {len(user_ids)} users\")\n",
    "    \n",
    "    all_recommendations = {}\n",
    "    total_users = len(user_ids)\n",
    "    \n",
    "    # Precompute global and user/movie statistics for faster recommendations\n",
    "    global_avg_rating = train_ratings['rating'].mean() if train_ratings is not None else 3.0\n",
    "    \n",
    "    # Precompute user statistics\n",
    "    user_stats = {}\n",
    "    if train_ratings is not None:\n",
    "        for user_id in user_ids:\n",
    "            user_ratings = train_ratings[train_ratings['userId'] == user_id]\n",
    "            if len(user_ratings) > 0:\n",
    "                user_stats[user_id] = {\n",
    "                    'avg': user_ratings['rating'].mean(),\n",
    "                    'std': user_ratings['rating'].std() if len(user_ratings) > 1 else 0.5,\n",
    "                    'count': len(user_ratings)\n",
    "                }\n",
    "    \n",
    "    # Precompute movie statistics (for most popular movies)\n",
    "    movie_stats = {}\n",
    "    if train_ratings is not None:\n",
    "        # Group by movieId and count\n",
    "        movie_counts = train_ratings['movieId'].value_counts()\n",
    "        \n",
    "        # Get popular movies (top 10%)\n",
    "        popular_threshold = np.percentile(movie_counts.values, 90) if len(movie_counts) > 10 else 0\n",
    "        popular_movies = movie_counts[movie_counts >= popular_threshold].index\n",
    "        \n",
    "        for movie_id in popular_movies:\n",
    "            movie_ratings = train_ratings[train_ratings['movieId'] == movie_id]\n",
    "            if len(movie_ratings) > 0:\n",
    "                movie_stats[movie_id] = {\n",
    "                    'avg': movie_ratings['rating'].mean(),\n",
    "                    'std': movie_ratings['rating'].std() if len(movie_ratings) > 1 else 0.5,\n",
    "                    'count': len(movie_ratings)\n",
    "                }\n",
    "    \n",
    "    # Create a dictionary of rated movies by user for faster lookups\n",
    "    user_rated_movies = {}\n",
    "    if train_ratings is not None:\n",
    "        for user_id in user_ids:\n",
    "            user_rated_movies[user_id] = set(train_ratings[train_ratings['userId'] == user_id]['movieId'].values)\n",
    "    \n",
    "    feature_columns = genre_columns.copy()\n",
    "    if region_columns:\n",
    "        feature_columns.extend(region_columns)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    for i in range(0, total_users, batch_size):\n",
    "        batch_end = min(i + batch_size, total_users)\n",
    "        batch_users = user_ids[i:batch_end]\n",
    "        \n",
    "        batch_start_time = time.time()\n",
    "        \n",
    "        for user_idx, user_id in enumerate(batch_users):\n",
    "            user_prefs = user_preferences[user_preferences['userId'] == user_id]\n",
    "            if user_prefs.empty:\n",
    "                continue\n",
    "            \n",
    "            # Get movies already rated by this user\n",
    "            rated_movies = user_rated_movies.get(user_id, set())\n",
    "            \n",
    "            # Consider only unrated movies\n",
    "            unrated_movie_ids = set(movie_features['movieId']) - rated_movies\n",
    "            \n",
    "            # For large datasets, sample a subset of candidate movies\n",
    "            # to improve efficiency while maintaining diversity\n",
    "            max_movies_per_batch = 2000\n",
    "            \n",
    "            if len(unrated_movie_ids) > max_movies_per_batch:\n",
    "                # Use a smarter sampling method:\n",
    "                # 1. Include some popular movies (higher chance of being liked)\n",
    "                # 2. Include movies with high genre match to user preferences\n",
    "                # 3. Include some random movies for diversity\n",
    "                \n",
    "                # Convert preferences to dictionary for easier access\n",
    "                pref_dict = user_prefs.iloc[0].to_dict()\n",
    "                \n",
    "                # Find top genres by preference\n",
    "                genre_prefs = [(genre, pref_dict.get(genre, 0)) \n",
    "                              for genre in genre_columns if genre in pref_dict]\n",
    "                top_genres = sorted(genre_prefs, key=lambda x: x[1], reverse=True)[:5]\n",
    "                top_genre_names = [g[0] for g in top_genres if g[1] > 0]\n",
    "                \n",
    "                # Get movies from top genres (if any positive preferences)\n",
    "                top_genre_movies = set()\n",
    "                if top_genre_names:\n",
    "                    for genre in top_genre_names:\n",
    "                        genre_movies = set(movie_features[movie_features[genre] == 1]['movieId'])\n",
    "                        top_genre_movies.update(genre_movies)\n",
    "                    \n",
    "                    # Filter to unrated movies only\n",
    "                    top_genre_movies = top_genre_movies.intersection(unrated_movie_ids)\n",
    "                    \n",
    "                    # Limit to a reasonable number\n",
    "                    if len(top_genre_movies) > max_movies_per_batch // 2:\n",
    "                        top_genre_movies = set(list(top_genre_movies)[:max_movies_per_batch // 2])\n",
    "                \n",
    "                # Get popular movies based on movie_stats\n",
    "                popular_movies = set([m for m, stats in movie_stats.items() \n",
    "                                    if stats['count'] > 5 and stats['avg'] >= 3])\n",
    "                popular_unrated = popular_movies.intersection(unrated_movie_ids) - top_genre_movies\n",
    "                \n",
    "                # Limit number of popular movies\n",
    "                if len(popular_unrated) > max_movies_per_batch // 4:\n",
    "                    popular_unrated = set(list(popular_unrated)[:max_movies_per_batch // 4])\n",
    "                \n",
    "                # Random sampling for remaining slots\n",
    "                remaining_count = max_movies_per_batch - len(top_genre_movies) - len(popular_unrated)\n",
    "                remaining_movies = unrated_movie_ids - top_genre_movies - popular_unrated\n",
    "                \n",
    "                if len(remaining_movies) > remaining_count:\n",
    "                    remaining_sample = np.random.choice(list(remaining_movies), \n",
    "                                                       size=remaining_count, \n",
    "                                                       replace=False)\n",
    "                    remaining_movies = set(remaining_sample)\n",
    "                \n",
    "                # Combine all selected movies\n",
    "                unrated_movie_ids = top_genre_movies.union(popular_unrated).union(remaining_movies)\n",
    "            \n",
    "            candidate_movies = movie_features[movie_features['movieId'].isin(unrated_movie_ids)]\n",
    "            \n",
    "            if len(candidate_movies) == 0:\n",
    "                continue\n",
    "            \n",
    "            # Process movies in batches to avoid memory issues\n",
    "            movie_batch_size = 200\n",
    "            predictions = []\n",
    "            \n",
    "            for j in range(0, len(candidate_movies), movie_batch_size):\n",
    "                movie_batch_end = min(j + movie_batch_size, len(candidate_movies))\n",
    "                movie_batch = candidate_movies.iloc[j:movie_batch_end]\n",
    "                \n",
    "                batch_features = []\n",
    "                batch_movie_ids = []\n",
    "                \n",
    "                for _, movie_row in movie_batch.iterrows():\n",
    "                    movie_id = movie_row['movieId']\n",
    "                    \n",
    "                    # Get or compute movie stats on-demand for non-cached movies\n",
    "                    if movie_id not in movie_stats and train_ratings is not None:\n",
    "                        movie_ratings = train_ratings[train_ratings['movieId'] == movie_id]\n",
    "                        if len(movie_ratings) > 0:\n",
    "                            movie_stats[movie_id] = {\n",
    "                                'avg': movie_ratings['rating'].mean(),\n",
    "                                'std': movie_ratings['rating'].std() if len(movie_ratings) > 1 else 0.5,\n",
    "                                'count': len(movie_ratings)\n",
    "                            }\n",
    "                    \n",
    "                    # Generate features\n",
    "                    feature_vector = []\n",
    "                    \n",
    "                    # Get user and movie stats\n",
    "                    user_info = user_stats.get(user_id, {'avg': global_avg_rating, 'std': 0.5, 'count': 0})\n",
    "                    movie_info = movie_stats.get(movie_id, {'avg': global_avg_rating, 'std': 0.5, 'count': 0})\n",
    "                    \n",
    "                    # Add global context features\n",
    "                    feature_vector.append(global_avg_rating / 5.0)  # Normalize\n",
    "                    \n",
    "                    # Add user context features\n",
    "                    feature_vector.append(user_info['avg'] / 5.0)  # User average rating\n",
    "                    feature_vector.append(min(1.0, user_info['std'] / 2.0))  # User rating variability\n",
    "                    feature_vector.append(min(1.0, np.log1p(user_info['count']) / 10.0))  # User experience\n",
    "                    \n",
    "                    # Add movie context features\n",
    "                    feature_vector.append(movie_info['avg'] / 5.0)  # Movie average rating\n",
    "                    feature_vector.append(min(1.0, movie_info['std'] / 2.0))  # Movie rating variability \n",
    "                    feature_vector.append(min(1.0, np.log1p(movie_info['count']) / 10.0))  # Movie popularity\n",
    "                    \n",
    "                    # Add user-movie difference feature\n",
    "                    feature_vector.append((user_info['avg'] - movie_info['avg'] + 2.5) / 5.0)  # Normalized difference\n",
    "                    \n",
    "                    # Add features with interactions\n",
    "                    for feature in feature_columns:\n",
    "                        user_pref = user_prefs.iloc[0][feature]\n",
    "                        movie_feat = movie_row[feature]\n",
    "                        \n",
    "                        # Add user preference\n",
    "                        feature_vector.append(user_pref)\n",
    "                        \n",
    "                        # Add movie feature\n",
    "                        feature_vector.append(movie_feat)\n",
    "                        \n",
    "                        # Add interaction features\n",
    "                        feature_vector.append(user_pref * movie_feat)  # Product\n",
    "                        feature_vector.append(user_pref + movie_feat - 0.5)  # Sum (normalized)\n",
    "                        feature_vector.append(abs(user_pref - movie_feat))  # Absolute difference\n",
    "                    \n",
    "                    batch_features.append(feature_vector)\n",
    "                    batch_movie_ids.append(movie_id)\n",
    "                \n",
    "                batch_features = np.array(batch_features, dtype=np.float32)\n",
    "                \n",
    "                if len(batch_features) == 0:\n",
    "                    continue\n",
    "                \n",
    "                try:\n",
    "                    # Get probability scores\n",
    "                    batch_predictions = dnn_model.predict(batch_features, verbose=0).flatten()\n",
    "                    \n",
    "                    # Convert to rating-like scale\n",
    "                    batch_ratings = 0.5 + (batch_predictions * 4.5)\n",
    "                    \n",
    "                    for movie_id, pred in zip(batch_movie_ids, batch_ratings):\n",
    "                        predictions.append((movie_id, float(pred)))\n",
    "                except Exception as e:\n",
    "                    logger.error(f\"Error predicting for user {user_id}: {e}\")\n",
    "            \n",
    "            if predictions:\n",
    "                predictions.sort(key=lambda x: x[1], reverse=True)\n",
    "                all_recommendations[user_id] = predictions[:n]\n",
    "        \n",
    "        elapsed = time.time() - start_time\n",
    "        progress = batch_end / total_users * 100\n",
    "        remaining = elapsed / batch_end * (total_users - batch_end) if batch_end > 0 else 0\n",
    "        \n",
    "        logger.info(f\"Processed {batch_end}/{total_users} users ({progress:.1f}%) - Elapsed: {elapsed:.2f}s - Est. remaining: {remaining:.2f}s\")\n",
    "        \n",
    "        gc.collect()\n",
    "    \n",
    "    logger.info(f\"Generated recommendations for {len(all_recommendations)}/{total_users} users\")\n",
    "    \n",
    "    return all_recommendations\n",
    "\n",
    "def evaluate_recommendations(recommendations, test_ratings, dnn_model, user_preferences, movie_features, genre_columns, region_columns=None, threshold=3):\n",
    "    \"\"\"\n",
    "    Evaluate recommendation model using enhanced metrics\n",
    "    \"\"\"\n",
    "    logger.info(\"Evaluating recommendations with comprehensive metrics\")\n",
    "    \n",
    "    # Find common users between test set and recommendations\n",
    "    test_users = set(test_ratings['userId'].unique())\n",
    "    recommendation_users = set(recommendations.keys())\n",
    "    common_users = test_users.intersection(recommendation_users)\n",
    "    \n",
    "    logger.info(f\"Test users: {len(test_users)}, Users with recommendations: {len(recommendation_users)}\")\n",
    "    logger.info(f\"Common users for evaluation: {len(common_users)}\")\n",
    "    \n",
    "    if len(common_users) == 0:\n",
    "        logger.warning(\"No common users between test set and recommendations\")\n",
    "        \n",
    "        # Calculate baseline metrics for all test data\n",
    "        # Use global average rating as prediction\n",
    "        global_avg_rating = test_ratings['rating'].mean()\n",
    "        predictions = np.full(len(test_ratings), global_avg_rating)\n",
    "        actuals = test_ratings['rating'].values\n",
    "        \n",
    "        # Calculate RMSE and MAE\n",
    "        mse = np.mean((predictions - actuals) ** 2)\n",
    "        rmse = np.sqrt(mse)\n",
    "        mae = np.mean(np.abs(predictions - actuals))\n",
    "        \n",
    "        # Convert to binary for classification metrics\n",
    "        binary_preds = (predictions > threshold).astype(int)\n",
    "        binary_actuals = (actuals > threshold).astype(int)\n",
    "        \n",
    "        # Classification metrics\n",
    "        accuracy = np.mean(binary_preds == binary_actuals)\n",
    "        \n",
    "        # Calculate confusion matrix elements\n",
    "        true_positives = np.sum((binary_preds == 1) & (binary_actuals == 1))\n",
    "        false_positives = np.sum((binary_preds == 1) & (binary_actuals == 0))\n",
    "        true_negatives = np.sum((binary_preds == 0) & (binary_actuals == 0))\n",
    "        false_negatives = np.sum((binary_preds == 0) & (binary_actuals == 1))\n",
    "        \n",
    "        precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0\n",
    "        recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0\n",
    "        f1_score = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "        \n",
    "        logger.info(f\"Baseline evaluation results:\")\n",
    "        logger.info(f\"RMSE: {rmse:.4f}\")\n",
    "        logger.info(f\"MAE: {mae:.4f}\")\n",
    "        logger.info(f\"Accuracy: {accuracy:.4f}\")\n",
    "        logger.info(f\"Precision: {precision:.4f}\")\n",
    "        logger.info(f\"Recall: {recall:.4f}\")\n",
    "        logger.info(f\"F1 Score: {f1_score:.4f}\")\n",
    "        \n",
    "        metrics = {\n",
    "            'rmse': rmse,\n",
    "            'mae': mae,\n",
    "            'accuracy': accuracy,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1_score': f1_score,\n",
    "            'num_predictions': len(test_ratings),\n",
    "            'method': 'baseline_average'\n",
    "        }\n",
    "        \n",
    "        return metrics, {}\n",
    "    \n",
    "    # Prepare data for evaluation\n",
    "    predictions = []\n",
    "    actuals = []\n",
    "    binary_predictions = []\n",
    "    binary_actuals = []\n",
    "    \n",
    "    # Tracking for rank-based metrics\n",
    "    rank_metrics = defaultdict(list)\n",
    "    \n",
    "    # Track metrics per user\n",
    "    user_metrics = {}\n",
    "    \n",
    "    # Precompute global stats\n",
    "    global_avg_rating = test_ratings['rating'].mean()\n",
    "    \n",
    "    # Calculate user stats once\n",
    "    user_stats = {}\n",
    "    for user_id in common_users:\n",
    "        user_test = test_ratings[test_ratings['userId'] == user_id]\n",
    "        if len(user_test) > 0:\n",
    "            user_stats[user_id] = {\n",
    "                'avg': user_test['rating'].mean(),\n",
    "                'std': user_test['rating'].std() if len(user_test) > 1 else 0.5,\n",
    "                'count': len(user_test)\n",
    "            }\n",
    "    \n",
    "    # Process each user\n",
    "    for user_id in common_users:\n",
    "        if user_id not in user_preferences['userId'].values:\n",
    "            continue\n",
    "        \n",
    "        user_test_ratings = test_ratings[test_ratings['userId'] == user_id]\n",
    "        \n",
    "        # Get this user's recommendations\n",
    "        user_recs = {}\n",
    "        if user_id in recommendations:\n",
    "            user_recs = dict(recommendations[user_id])\n",
    "        \n",
    "        user_preds = []\n",
    "        user_actuals = []\n",
    "        user_binary_preds = []\n",
    "        user_binary_actuals = []\n",
    "        \n",
    "        # For each test rating, compare with recommendation\n",
    "        for _, row in user_test_ratings.iterrows():\n",
    "            movie_id = row['movieId']\n",
    "            actual_rating = row['rating']\n",
    "            binary_actual = 1 if actual_rating > threshold else 0\n",
    "            \n",
    "            if movie_id in user_recs:\n",
    "                # Use pre-computed recommendation score\n",
    "                predicted_rating = user_recs[movie_id]\n",
    "                binary_prediction = 1 if predicted_rating > (threshold * 4.5 / 5.0 + 0.5) else 0\n",
    "                \n",
    "                user_preds.append(predicted_rating)\n",
    "                user_actuals.append(actual_rating)\n",
    "                user_binary_preds.append(binary_prediction)\n",
    "                user_binary_actuals.append(binary_actual)\n",
    "                \n",
    "                # Store for rank calculations\n",
    "                rank_metrics['movie_ids'].append(movie_id)\n",
    "                rank_metrics['users'].append(user_id)\n",
    "                rank_metrics['actuals'].append(actual_rating)\n",
    "                rank_metrics['predictions'].append(predicted_rating)\n",
    "                \n",
    "                # Find the rank of this movie in the user's recommendations\n",
    "                rec_items = [item[0] for item in recommendations[user_id]]\n",
    "                rank = rec_items.index(movie_id) + 1 if movie_id in rec_items else len(rec_items) + 1\n",
    "                rank_metrics['ranks'].append(rank)\n",
    "                \n",
    "            elif movie_id in movie_features['movieId'].values:\n",
    "                # Generate prediction for this movie\n",
    "                feature_vector = generate_user_movie_features(\n",
    "                    user_id, \n",
    "                    movie_id, \n",
    "                    user_preferences, \n",
    "                    movie_features, \n",
    "                    genre_columns,\n",
    "                    region_columns,\n",
    "                    user_stats=user_stats,\n",
    "                    global_avg_rating=global_avg_rating\n",
    "                )\n",
    "                \n",
    "                if feature_vector is not None:\n",
    "                    # Get probability from model\n",
    "                    like_probability = dnn_model.predict(feature_vector, verbose=0)[0][0]\n",
    "                    \n",
    "                    # Convert to rating-like scale\n",
    "                    predicted_rating = 0.5 + like_probability * 4.5\n",
    "                    \n",
    "                    # Binary prediction\n",
    "                    binary_prediction = 1 if like_probability > 0.5 else 0\n",
    "                    \n",
    "                    user_preds.append(predicted_rating)\n",
    "                    user_actuals.append(actual_rating)\n",
    "                    user_binary_preds.append(binary_prediction)\n",
    "                    user_binary_actuals.append(binary_actual)\n",
    "        \n",
    "        if user_preds:\n",
    "            # Add user predictions to global list\n",
    "            predictions.extend(user_preds)\n",
    "            actuals.extend(user_actuals)\n",
    "            binary_predictions.extend(user_binary_preds)\n",
    "            binary_actuals.extend(user_binary_actuals)\n",
    "            \n",
    "            # Calculate per-user metrics\n",
    "            user_binary_preds_np = np.array(user_binary_preds)\n",
    "            user_binary_actuals_np = np.array(user_binary_actuals)\n",
    "            \n",
    "            # Accuracy\n",
    "            user_accuracy = np.mean(user_binary_preds_np == user_binary_actuals_np)\n",
    "            \n",
    "            # Classification metrics\n",
    "            user_tp = np.sum((user_binary_preds_np == 1) & (user_binary_actuals_np == 1))\n",
    "            user_fp = np.sum((user_binary_preds_np == 1) & (user_binary_actuals_np == 0))\n",
    "            user_tn = np.sum((user_binary_preds_np == 0) & (user_binary_actuals_np == 0))\n",
    "            user_fn = np.sum((user_binary_preds_np == 0) & (user_binary_actuals_np == 1))\n",
    "            \n",
    "            user_precision = user_tp / (user_tp + user_fp) if (user_tp + user_fp) > 0 else 0\n",
    "            user_recall = user_tp / (user_tp + user_fn) if (user_tp + user_fn) > 0 else 0\n",
    "            user_f1 = 2 * user_precision * user_recall / (user_precision + user_recall) if (user_precision + user_recall) > 0 else 0\n",
    "            \n",
    "            # RMSE (on original rating scale)\n",
    "            user_preds_np = np.array(user_preds)\n",
    "            user_actuals_np = np.array(user_actuals)\n",
    "            user_rmse = np.sqrt(np.mean((user_preds_np - user_actuals_np) ** 2))\n",
    "            user_mae = np.mean(np.abs(user_preds_np - user_actuals_np))\n",
    "            \n",
    "            # Store user metrics\n",
    "            user_metrics[user_id] = {\n",
    "                'accuracy': user_accuracy,\n",
    "                'precision': user_precision,\n",
    "                'recall': user_recall,\n",
    "                'f1_score': user_f1,\n",
    "                'rmse': user_rmse,\n",
    "                'mae': user_mae,\n",
    "                'num_predictions': len(user_preds),\n",
    "                'tp': int(user_tp),\n",
    "                'fp': int(user_fp),\n",
    "                'tn': int(user_tn),\n",
    "                'fn': int(user_fn)\n",
    "            }\n",
    "    \n",
    "    if not predictions:\n",
    "        logger.warning(\"No predictions available for evaluation\")\n",
    "        return {\n",
    "            'rmse': 0.0,\n",
    "            'mae': 0.0,\n",
    "            'accuracy': 0.0,\n",
    "            'precision': 0.0,\n",
    "            'recall': 0.0,\n",
    "            'f1_score': 0.0,\n",
    "            'num_predictions': 0\n",
    "        }, {}\n",
    "    \n",
    "    # Convert to numpy arrays for calculations\n",
    "    predictions = np.array(predictions)\n",
    "    actuals = np.array(actuals)\n",
    "    binary_predictions = np.array(binary_predictions)\n",
    "    binary_actuals = np.array(binary_actuals)\n",
    "    \n",
    "    # Calculate binary classification metrics\n",
    "    accuracy = np.mean(binary_predictions == binary_actuals)\n",
    "    \n",
    "    # Calculate confusion matrix elements\n",
    "    true_positives = np.sum((binary_predictions == 1) & (binary_actuals == 1))\n",
    "    false_positives = np.sum((binary_predictions == 1) & (binary_actuals == 0))\n",
    "    true_negatives = np.sum((binary_predictions == 0) & (binary_actuals == 0))\n",
    "    false_negatives = np.sum((binary_predictions == 0) & (binary_actuals == 1))\n",
    "    \n",
    "    # Calculate precision, recall, and F1 score\n",
    "    precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0\n",
    "    recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0\n",
    "    f1_score = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    # Calculate RMSE and MAE\n",
    "    rmse = np.sqrt(np.mean((predictions - actuals) ** 2))\n",
    "    mae = np.mean(np.abs(predictions - actuals))\n",
    "    \n",
    "    # Calculate rank-based metrics if available\n",
    "    ndcg = 0.0\n",
    "    map_score = 0.0\n",
    "    mrr = 0.0\n",
    "    \n",
    "    if rank_metrics['ranks']:\n",
    "        # Normalized Discounted Cumulative Gain (NDCG)\n",
    "        # Calculate DCG: sum of (2^relevance - 1) / log2(rank + 1)\n",
    "        # For NDCG, we normalize by the ideal DCG (items sorted by relevance)\n",
    "        relevance = np.array(rank_metrics['actuals']) > threshold  # Convert ratings to binary relevance\n",
    "        ranks = np.array(rank_metrics['ranks'])\n",
    "        \n",
    "        # DCG calculation\n",
    "        dcg = np.sum((2**relevance - 1) / np.log2(ranks + 1))\n",
    "        \n",
    "        # IDCG calculation (sort by relevance)\n",
    "        ideal_ranks = np.argsort(relevance)[::-1] + 1  # Descending order\n",
    "        idcg = np.sum((2**relevance - 1) / np.log2(ideal_ranks + 1))\n",
    "        \n",
    "        ndcg = dcg / idcg if idcg > 0 else 0\n",
    "        \n",
    "        # Mean Average Precision (MAP)\n",
    "        # For each user, calculate average precision\n",
    "        users = np.array(rank_metrics['users'])\n",
    "        unique_users = np.unique(users)\n",
    "        \n",
    "        avg_precisions = []\n",
    "        reciprocal_ranks = []\n",
    "        \n",
    "        for user in unique_users:\n",
    "            user_indices = np.where(users == user)[0]\n",
    "            user_relevance = relevance[user_indices]\n",
    "            user_ranks = ranks[user_indices]\n",
    "            \n",
    "            # Sort by rank\n",
    "            sort_idx = np.argsort(user_ranks)\n",
    "            user_relevance = user_relevance[sort_idx]\n",
    "            user_ranks = user_ranks[sort_idx]\n",
    "            \n",
    "            # Calculate precision at each relevant position\n",
    "            relevant_positions = np.where(user_relevance == 1)[0]\n",
    "            \n",
    "            if len(relevant_positions) > 0:\n",
    "                # Mean Reciprocal Rank - 1/rank of first relevant item\n",
    "                reciprocal_ranks.append(1.0 / user_ranks[relevant_positions[0]])\n",
    "                \n",
    "                # Average Precision\n",
    "                precision_at_k = []\n",
    "                for k in relevant_positions:\n",
    "                    precision_at_k.append(np.sum(user_relevance[:k+1]) / (k+1))\n",
    "                \n",
    "                avg_precisions.append(np.mean(precision_at_k))\n",
    "        \n",
    "        map_score = np.mean(avg_precisions) if avg_precisions else 0\n",
    "        mrr = np.mean(reciprocal_ranks) if reciprocal_ranks else 0\n",
    "    \n",
    "    metrics = {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1_score,\n",
    "        'true_positives': int(true_positives),\n",
    "        'false_positives': int(false_positives),\n",
    "        'true_negatives': int(true_negatives),\n",
    "        'false_negatives': int(false_negatives),\n",
    "        'rmse': rmse,\n",
    "        'mae': mae,\n",
    "        'ndcg': ndcg,\n",
    "        'map': map_score,\n",
    "        'mrr': mrr,\n",
    "        'num_predictions': len(predictions),\n",
    "        'method': 'enhanced_evaluation'\n",
    "    }\n",
    "    \n",
    "    logger.info(f\"Evaluation completed:\")\n",
    "    logger.info(f\"Accuracy: {accuracy:.4f}\")\n",
    "    logger.info(f\"Precision: {precision:.4f}\")\n",
    "    logger.info(f\"Recall: {recall:.4f}\")\n",
    "    logger.info(f\"F1 Score: {f1_score:.4f}\")\n",
    "    logger.info(f\"RMSE: {rmse:.4f}\")\n",
    "    logger.info(f\"MAE: {mae:.4f}\")\n",
    "    logger.info(f\"NDCG: {ndcg:.4f}\")\n",
    "    logger.info(f\"MAP: {map_score:.4f}\")\n",
    "    logger.info(f\"MRR: {mrr:.4f}\")\n",
    "    logger.info(f\"Predictions: {len(predictions)}\")\n",
    "    \n",
    "    # Create visualization for confusion matrix\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    cm = np.array([\n",
    "        [true_negatives, false_positives],\n",
    "        [false_negatives, true_positives]\n",
    "    ])\n",
    "    \n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "               xticklabels=['Predicted Negative', 'Predicted Positive'],\n",
    "               yticklabels=['Actual Negative', 'Actual Positive'])\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.savefig(os.path.join(output_path, 'dnn_confusion_matrix.png'))\n",
    "    plt.close()\n",
    "    \n",
    "    # Create bar chart of metrics\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    metric_names = ['Accuracy', 'Precision', 'Recall', 'F1 Score', 'NDCG', 'MAP', 'MRR']\n",
    "    metric_values = [accuracy, precision, recall, f1_score, ndcg, map_score, mrr]\n",
    "    \n",
    "    colors = plt.cm.viridis(np.linspace(0, 0.8, len(metric_names)))\n",
    "    bars = plt.bar(metric_names, metric_values, color=colors)\n",
    "    \n",
    "    # Add value labels on top of bars\n",
    "    for bar, value in zip(bars, metric_values):\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, \n",
    "                bar.get_height() + 0.02, \n",
    "                f'{value:.3f}', \n",
    "                ha='center', va='bottom', \n",
    "                fontweight='bold')\n",
    "    \n",
    "    plt.ylim(0, 1.0)\n",
    "    plt.title('Evaluation Metrics')\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    plt.savefig(os.path.join(output_path, 'dnn_evaluation_metrics.png'))\n",
    "    plt.close()\n",
    "    \n",
    "    # Create scatter plot of actual vs predicted ratings\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.scatter(actuals, predictions, alpha=0.5)\n",
    "    plt.plot([0.5, 5], [0.5, 5], 'r--')  # Perfect prediction line\n",
    "    plt.xlim(0.5, 5)\n",
    "    plt.ylim(0.5, 5)\n",
    "    plt.xlabel('Actual Ratings')\n",
    "    plt.ylabel('Predicted Ratings')\n",
    "    plt.title(f'Actual vs Predicted Ratings (RMSE={rmse:.3f})')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.savefig(os.path.join(output_path, 'actual_vs_predicted.png'))\n",
    "    plt.close()\n",
    "    \n",
    "    return metrics, user_metrics\n",
    "\n",
    "def recommend_for_user(user_id, recommendations, movie_features=None, n=10):\n",
    "    \"\"\"\n",
    "    Display improved recommendations for a user\n",
    "    \"\"\"\n",
    "    if user_id not in recommendations:\n",
    "        logger.warning(f\"No recommendations found for user {user_id}\")\n",
    "        return\n",
    "    \n",
    "    user_recs = recommendations[user_id][:n]\n",
    "    \n",
    "    if not user_recs:\n",
    "        logger.warning(f\"No recommendations found for user {user_id}\")\n",
    "        return\n",
    "    \n",
    "    logger.info(f\"\\nTop {len(user_recs)} recommendations for user {user_id}:\")\n",
    "    \n",
    "    recs_info = []\n",
    "    \n",
    "    for i, (movie_id, predicted_rating) in enumerate(user_recs, 1):\n",
    "        movie_info = f\"Movie ID: {movie_id}\"\n",
    "        genres = []\n",
    "        \n",
    "        if movie_features is not None:\n",
    "            movie_row = movie_features[movie_features['movieId'] == movie_id]\n",
    "            if not movie_row.empty:\n",
    "                if 'title' in movie_row.columns:\n",
    "                    movie_info = movie_row.iloc[0]['title']\n",
    "                \n",
    "                # Extract genres\n",
    "                genre_columns = [col for col in movie_row.columns if col not in \n",
    "                                ['movieId', 'title', 'tokens', 'token_count', 'top_keywords'] and\n",
    "                                col not in ['North America', 'Europe', 'East Asia', 'South Asia', \n",
    "                                           'Southeast Asia', 'Oceania', 'Middle East', 'Africa', \n",
    "                                           'Latin America', 'Other']]\n",
    "                \n",
    "                genres = [genre for genre in genre_columns if movie_row.iloc[0][genre] == 1]\n",
    "        \n",
    "        genre_str = \", \".join(genres[:3]) + (\", ...\" if len(genres) > 3 else \"\")\n",
    "        logger.info(f\"{i}. {movie_info} - Rating: {predicted_rating:.2f} - Genres: {genre_str}\")\n",
    "        \n",
    "        recs_info.append({\n",
    "            'rank': i,\n",
    "            'movie_id': movie_id,\n",
    "            'title': movie_info,\n",
    "            'predicted_rating': predicted_rating,\n",
    "            'genres': genres\n",
    "        })\n",
    "    \n",
    "    return recs_info\n",
    "\n",
    "# Main execution flow\n",
    "logger.info(\"Starting enhanced DNN-based recommendation pipeline\")\n",
    "log_memory_usage(\"Initial memory usage\")\n",
    "\n",
    "# Load data\n",
    "data = load_data()\n",
    "if data is None:\n",
    "    logger.error(\"Failed to load data\")\n",
    "    exit(1)\n",
    "\n",
    "log_memory_usage(\"After loading data\")\n",
    "\n",
    "# Extract genre and region features\n",
    "movie_features_with_regions, genre_columns, region_columns = extract_genre_and_region_features(data['movie_features'])\n",
    "\n",
    "if movie_features_with_regions is None:\n",
    "    logger.error(\"Failed to extract movie features\")\n",
    "    exit(1)\n",
    "\n",
    "log_memory_usage(\"After feature extraction\")\n",
    "\n",
    "# Calculate user preferences\n",
    "user_preferences = calculate_user_preferences(\n",
    "    data['train_ratings'], \n",
    "    movie_features_with_regions,\n",
    "    genre_columns + region_columns,\n",
    "    threshold_rating\n",
    ")\n",
    "\n",
    "# Save user preferences\n",
    "user_preferences.to_csv(os.path.join(output_path, 'user_genre_preferences.csv'), index=False)\n",
    "logger.info(f\"Saved user preferences for {len(user_preferences)} users\")\n",
    "\n",
    "# Save movie genre features\n",
    "movie_features_with_regions.to_csv(os.path.join(output_path, 'movie_genre_features.csv'), index=False)\n",
    "logger.info(f\"Saved movie genre features for {len(movie_features_with_regions)} movies\")\n",
    "\n",
    "log_memory_usage(\"After user preferences calculation\")\n",
    "\n",
    "# Prepare training data\n",
    "X_train, X_val, y_train, y_val, feature_columns = prepare_dnn_training_data(\n",
    "    data['train_ratings'],\n",
    "    user_preferences,\n",
    "    movie_features_with_regions,\n",
    "    genre_columns,\n",
    "    region_columns,\n",
    "    threshold=threshold_rating\n",
    ")\n",
    "\n",
    "log_memory_usage(\"After training data preparation\")\n",
    "\n",
    "# Build and train the model\n",
    "dnn_model, training_history = build_and_train_dnn_model(\n",
    "    X_train, \n",
    "    X_val, \n",
    "    y_train, \n",
    "    y_val,\n",
    "    learning_rate=dnn_learning_rate,\n",
    "    batch_size=dnn_batch_size,\n",
    "    epochs=dnn_epochs\n",
    ")\n",
    "\n",
    "log_memory_usage(\"After model training\")\n",
    "\n",
    "# Save the trained model\n",
    "dnn_model.save(os.path.join(output_path, 'dnn_model.h5'))\n",
    "logger.info(\"Saved trained DNN model\")\n",
    "\n",
    "# Generate recommendations for users with adaptive batch size\n",
    "dnn_recommendations = generate_recommendations_for_all_users(\n",
    "    dnn_model,\n",
    "    user_preferences,\n",
    "    movie_features_with_regions,\n",
    "    genre_columns,\n",
    "    region_columns,\n",
    "    data['train_ratings'],\n",
    "    top_n,\n",
    "    batch_size=50\n",
    ")\n",
    "\n",
    "log_memory_usage(\"After generating recommendations\")\n",
    "\n",
    "# Save recommendations\n",
    "with open(os.path.join(output_path, 'dnn_recommendations.pkl'), 'wb') as f:\n",
    "    pickle.dump(dnn_recommendations, f)\n",
    "logger.info(f\"Saved recommendations for {len(dnn_recommendations)} users\")\n",
    "\n",
    "# Also save in CSV format for easier inspection\n",
    "recommendations_list = []\n",
    "for user_id, recs in dnn_recommendations.items():\n",
    "    for rank, (movie_id, score) in enumerate(recs, 1):\n",
    "        movie_title = \"Unknown\"\n",
    "        genres = []\n",
    "        \n",
    "        if 'movie_features' in data:\n",
    "            movie_row = data['movie_features'][data['movie_features']['movieId'] == movie_id]\n",
    "            if not movie_row.empty and 'title' in movie_row.columns:\n",
    "                movie_title = movie_row.iloc[0]['title']\n",
    "                \n",
    "                # Extract genres\n",
    "                genre_cols = [col for col in movie_row.columns if col not in \n",
    "                            ['movieId', 'title', 'tokens', 'token_count', 'top_keywords'] and\n",
    "                            col not in ['North America', 'Europe', 'East Asia', 'South Asia', \n",
    "                                       'Southeast Asia', 'Oceania', 'Middle East', 'Africa', \n",
    "                                       'Latin America', 'Other']]\n",
    "                \n",
    "                genres = [genre for genre in genre_cols if movie_row.iloc[0][genre] == 1]\n",
    "        \n",
    "        recommendations_list.append({\n",
    "            'userId': user_id,\n",
    "            'movieId': movie_id,\n",
    "            'title': movie_title,\n",
    "            'rank': rank,\n",
    "            'predicted_rating': score,\n",
    "            'genres': '|'.join(genres)\n",
    "        })\n",
    "\n",
    "# Save recommendations to CSV in chunks\n",
    "if recommendations_list:\n",
    "    chunk_size = 10000\n",
    "    recommendations_df = pd.DataFrame(recommendations_list)\n",
    "    \n",
    "    # Save in chunks to avoid memory issues with large datasets\n",
    "    for i in range(0, len(recommendations_df), chunk_size):\n",
    "        chunk = recommendations_df.iloc[i:i+chunk_size]\n",
    "        \n",
    "        if i == 0:\n",
    "            chunk.to_csv(os.path.join(output_path, 'dnn_recommendations.csv'), index=False, mode='w')\n",
    "        else:\n",
    "            chunk.to_csv(os.path.join(output_path, 'dnn_recommendations.csv'), index=False, mode='a', header=False)\n",
    "            \n",
    "    logger.info(f\"Saved {len(recommendations_df)} recommendations to CSV\")\n",
    "\n",
    "log_memory_usage(\"After saving recommendations\")\n",
    "\n",
    "# Evaluate the recommendations\n",
    "logger.info(\"Evaluating DNN recommendations with enhanced metrics\")\n",
    "evaluation_metrics, user_metrics = evaluate_recommendations(\n",
    "    dnn_recommendations,\n",
    "    data['test_ratings'],\n",
    "    dnn_model,\n",
    "    user_preferences,\n",
    "    movie_features_with_regions,\n",
    "    genre_columns,\n",
    "    region_columns,\n",
    "    threshold=threshold_rating\n",
    ")\n",
    "\n",
    "log_memory_usage(\"After evaluation\")\n",
    "\n",
    "# Save evaluation results\n",
    "if evaluation_metrics:\n",
    "    evaluation_results = pd.DataFrame([evaluation_metrics])\n",
    "    evaluation_results.to_csv(os.path.join(output_path, 'dnn_evaluation.csv'), index=False)\n",
    "    logger.info(\"Saved evaluation metrics\")\n",
    "    \n",
    "    # Save per-user metrics\n",
    "    user_metrics_df = pd.DataFrame.from_dict(user_metrics, orient='index')\n",
    "    user_metrics_df.reset_index(inplace=True)\n",
    "    user_metrics_df.rename(columns={'index': 'userId'}, inplace=True)\n",
    "    user_metrics_df.to_csv(os.path.join(output_path, 'dnn_user_metrics.csv'), index=False)\n",
    "    logger.info(f\"Saved per-user metrics for {len(user_metrics)} users\")\n",
    "    \n",
    "    # Analyze user metrics by user rating count\n",
    "    if 'train_ratings' in data and len(user_metrics_df) > 0:\n",
    "        # Get rating counts for each user\n",
    "        user_rating_counts = data['train_ratings'].groupby('userId').size().reset_index(name='rating_count')\n",
    "        \n",
    "        # Merge with user metrics\n",
    "        user_analysis = pd.merge(user_metrics_df, user_rating_counts, on='userId', how='left')\n",
    "        \n",
    "        # Create rating count bins\n",
    "        user_analysis['rating_count_bin'] = pd.cut(\n",
    "            user_analysis['rating_count'], \n",
    "            bins=[0, 10, 25, 50, 100, float('inf')],\n",
    "            labels=['1-10', '11-25', '26-50', '51-100', '100+']\n",
    "        )\n",
    "        \n",
    "        # Group by rating count bin and calculate average metrics\n",
    "        metrics_by_count = user_analysis.groupby('rating_count_bin').agg({\n",
    "            'rmse': 'mean',\n",
    "            'mae': 'mean',\n",
    "            'accuracy': 'mean',\n",
    "            'precision': 'mean',\n",
    "            'recall': 'mean',\n",
    "            'f1_score': 'mean',\n",
    "            'userId': 'count'\n",
    "        }).reset_index()\n",
    "        \n",
    "        metrics_by_count.rename(columns={'userId': 'num_users'}, inplace=True)\n",
    "        \n",
    "        # Save to CSV\n",
    "        metrics_by_count.to_csv(os.path.join(output_path, 'metrics_by_rating_count.csv'), index=False)\n",
    "        \n",
    "        # Create visualization\n",
    "        plt.figure(figsize=(14, 10))\n",
    "        \n",
    "        metrics = ['rmse', 'accuracy', 'precision', 'recall', 'f1_score']\n",
    "        colors = plt.cm.tab10(np.linspace(0, 1, len(metrics)))\n",
    "        \n",
    "        for i, metric in enumerate(metrics):\n",
    "            plt.subplot(len(metrics), 1, i+1)\n",
    "            plt.bar(metrics_by_count['rating_count_bin'], \n",
    "                   metrics_by_count[metric], \n",
    "                   color=colors[i],\n",
    "                   alpha=0.7)\n",
    "            \n",
    "            # Add value labels\n",
    "            for j, v in enumerate(metrics_by_count[metric]):\n",
    "                plt.text(j, v + 0.02, f'{v:.3f}', ha='center', fontweight='bold')\n",
    "                \n",
    "            # Add user counts as text\n",
    "            if i == 0:\n",
    "                for j, count in enumerate(metrics_by_count['num_users']):\n",
    "                    plt.text(j, metrics_by_count[metric].max() * 0.8, \n",
    "                            f'n={count}', ha='center', \n",
    "                            bbox=dict(facecolor='white', alpha=0.5))\n",
    "            \n",
    "            plt.title(f'{metric.upper()} by User Rating Count')\n",
    "            plt.grid(axis='y', alpha=0.3)\n",
    "            \n",
    "            # For RMSE, lower is better\n",
    "            if metric == 'rmse':\n",
    "                plt.ylim(0, min(2.0, metrics_by_count[metric].max() * 1.2))\n",
    "            else:\n",
    "                plt.ylim(0, 1.0)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(output_path, 'metrics_by_rating_count.png'))\n",
    "        plt.close()\n",
    "        \n",
    "        logger.info(\"Created metrics analysis by user rating count\")\n",
    "\n",
    "# Show sample recommendations\n",
    "logger.info(\"\\nSample recommendation for exploration:\")\n",
    "if dnn_recommendations:\n",
    "    # Pick a random user with recommendations\n",
    "    sample_user_id = np.random.choice(list(dnn_recommendations.keys()))\n",
    "    \n",
    "    if sample_user_id in user_preferences['userId'].values:\n",
    "        user_prefs = user_preferences[user_preferences['userId'] == sample_user_id].iloc[0]\n",
    "        genre_pref_columns = [col for col in user_preferences.columns if col in genre_columns]\n",
    "        \n",
    "        logger.info(f\"\\nUser {sample_user_id} Preferences:\")\n",
    "        user_prefs_list = [(genre, user_prefs[genre]) for genre in genre_pref_columns if user_prefs[genre] != 0]\n",
    "        liked_genres = sorted(user_prefs_list, key=lambda x: x[1], reverse=True)[:3]\n",
    "        disliked_genres = sorted(user_prefs_list, key=lambda x: x[1])[:3]\n",
    "        \n",
    "        logger.info(f\"- Most liked genres: {', '.join([f'{g} ({v:.2f})' for g, v in liked_genres if v > 0])}\")\n",
    "        logger.info(f\"- Most disliked genres: {', '.join([f'{g} ({v:.2f})' for g, v in disliked_genres if v < 0])}\")\n",
    "        \n",
    "        # Show region preferences if available\n",
    "        if region_columns:\n",
    "            region_pref_columns = [col for col in user_preferences.columns if col in region_columns]\n",
    "            region_prefs_list = [(region, user_prefs[region]) for region in region_pref_columns if user_prefs[region] != 0]\n",
    "            liked_regions = sorted(region_prefs_list, key=lambda x: x[1], reverse=True)[:3]\n",
    "            \n",
    "            if liked_regions and liked_regions[0][1] > 0:\n",
    "                logger.info(f\"- Preferred regions: {', '.join([f'{r} ({v:.2f})' for r, v in liked_regions if v > 0])}\")\n",
    "    \n",
    "    # Show the recommendations\n",
    "    recommend_for_user(sample_user_id, dnn_recommendations, data['movie_features'])\n",
    "\n",
    "    # Look up this user in the metrics to see how we did\n",
    "    if user_metrics and sample_user_id in user_metrics:\n",
    "        user_metric = user_metrics[sample_user_id]\n",
    "        logger.info(f\"\\nEvaluation metrics for user {sample_user_id}:\")\n",
    "        logger.info(f\"- RMSE: {user_metric['rmse']:.4f}\")\n",
    "        logger.info(f\"- Accuracy: {user_metric['accuracy']:.4f}\")\n",
    "        logger.info(f\"- F1 Score: {user_metric['f1_score']:.4f}\")\n",
    "        logger.info(f\"- Number of predictions: {user_metric['num_predictions']}\")\n",
    "\n",
    "log_memory_usage(\"Final memory usage\")\n",
    "logger.info(\"Enhanced DNN-based recommendation pipeline completed successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
