{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.corpus import wordnet\n",
    "from collections import Counter\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Download necessary NLTK resources\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('wordnet', quiet=True)\n",
    "nltk.download('averaged_perceptron_tagger', quiet=True)\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "STEP 1: MOVIE TEXT FEATURE EXTRACTION\n",
      "================================================================================\n",
      "Loaded 27278 movies from MovieLens dataset\n",
      "   movieId                    title  \\\n",
      "0        1         Toy Story (1995)   \n",
      "1        2           Jumanji (1995)   \n",
      "2        3  Grumpier Old Men (1995)   \n",
      "\n",
      "                                        genres  \n",
      "0  Adventure|Animation|Children|Comedy|Fantasy  \n",
      "1                   Adventure|Children|Fantasy  \n",
      "2                               Comedy|Romance  \n",
      "\n",
      "Loaded 1069382 movies from TMDB dataset\n",
      "   id           tmdb_title                                           overview\n",
      "0   2                Ariel  A Finnish man goes to the city to find a job a...\n",
      "1   3  Shadows in Paradise  Nikander, a rubbish collector and would-be ent...\n",
      "2   5           Four Rooms  It's Ted the Bellhop's first night on the job....\n",
      "\n",
      "Loaded 27278 movie links\n",
      "   movieId  imdbId   tmdbId\n",
      "0        1  114709    862.0\n",
      "1        2  113497   8844.0\n",
      "2        3  113228  15602.0\n",
      "\n",
      "Loaded 465564 movie tags\n",
      "   userId  movieId          tag            timestamp\n",
      "0      18     4141  Mark Waters  2009-04-24 18:19:40\n",
      "1      65      208    dark hero  2013-05-10 01:41:18\n",
      "2      65      353    dark hero  2013-05-10 01:41:19\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Movie Text Feature Extraction\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 1: MOVIE TEXT FEATURE EXTRACTION\")\n",
    "print(\"=\"*80)\n",
    "# Load MovieLens movie data\n",
    "movies_df = pd.read_csv('data/20M/movie.csv')\n",
    "print(f\"Loaded {len(movies_df)} movies from MovieLens dataset\")\n",
    "print(movies_df.head(3))\n",
    "\n",
    "# Load TMDB data (containing movie overviews, cast, director)\n",
    "tmdb_df = pd.read_csv('data/20M/tmdb.csv')\n",
    "print(f\"\\nLoaded {len(tmdb_df)} movies from TMDB dataset\")\n",
    "print(tmdb_df.head(3)[['id', 'tmdb_title', 'overview']])\n",
    "\n",
    "# Load links data to connect MovieLens IDs with TMDB IDs\n",
    "links_df = pd.read_csv('data/20M/link.csv')\n",
    "print(f\"\\nLoaded {len(links_df)} movie links\")\n",
    "print(links_df.head(3))\n",
    "\n",
    "# Load tags data for additional text information\n",
    "tags_df = pd.read_csv('data/20M/tag.csv')\n",
    "print(f\"\\nLoaded {len(tags_df)} movie tags\")\n",
    "print(tags_df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample movie text corpus:\n",
      "Movie: Toy Story (1995)\n",
      "Text corpus: Toy Story (1995) Led by Woody, Andy's toys live happily in his room until Andy's birthday brings Buzz Lightyear onto the scene. Afraid of losing his place in Andy's heart, Woody plots against Buzz. But when circumstances separate Buzz and Woody from their owner, the duo eventually learns to put asid...\n",
      "\n",
      "Created text corpus for 27278 movies\n",
      "   movieId                    title  \\\n",
      "0        1         Toy Story (1995)   \n",
      "1        2           Jumanji (1995)   \n",
      "2        3  Grumpier Old Men (1995)   \n",
      "\n",
      "                                         text_corpus  \n",
      "0  Toy Story (1995) Led by Woody, Andy's toys liv...  \n",
      "1  Jumanji (1995) When siblings Judy and Peter di...  \n",
      "2  Grumpier Old Men (1995) A family wedding reign...  \n"
     ]
    }
   ],
   "source": [
    "# Merge movie data with TMDB data via links_df\n",
    "movie_data = pd.merge(movies_df, links_df, on='movieId', how='left')\n",
    "movie_data = pd.merge(movie_data, tmdb_df, left_on='tmdbId', right_on='id', how='left')\n",
    "# Create text corpus for each movie\n",
    "movie_data['text_corpus'] = \"\"\n",
    "\n",
    "# Add title to corpus\n",
    "movie_data['text_corpus'] += movie_data['title'].fillna(\"\")\n",
    "\n",
    "# Add TMDB overview to corpus\n",
    "movie_data['text_corpus'] += \" \" + movie_data['overview'].fillna(\"\")\n",
    "\n",
    "# Add TMDB cast to corpus\n",
    "movie_data['text_corpus'] += \" \" + movie_data['cast'].fillna(\"\")\n",
    "\n",
    "# Add TMDB director to corpus\n",
    "movie_data['text_corpus'] += \" \" + movie_data['director'].fillna(\"\")\n",
    "\n",
    "# Aggregate tags by movieId\n",
    "tags_by_movie = tags_df.groupby('movieId')['tag'].apply(lambda x: ' '.join(x.fillna(''))).reset_index()\n",
    "\n",
    "# Merge tags with movies\n",
    "movie_data = pd.merge(movie_data, tags_by_movie, on='movieId', how='left')\n",
    "\n",
    "# Add tags to corpus\n",
    "movie_data['text_corpus'] += \" \" + movie_data['tag'].fillna(\"\")\n",
    "\n",
    "# Display a sample text corpus\n",
    "print(\"\\nSample movie text corpus:\")\n",
    "sample_movie = movie_data.iloc[0]\n",
    "print(f\"Movie: {sample_movie['title']}\")\n",
    "print(f\"Text corpus: {sample_movie['text_corpus'][:300]}...\")\n",
    "\n",
    "# Output: Movie text corpus data\n",
    "print(f\"\\nCreated text corpus for {len(movie_data)} movies\")\n",
    "movie_corpus_df = movie_data[['movieId', 'title', 'text_corpus']]\n",
    "print(movie_corpus_df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "STEP 2: TEXT PREPROCESSING\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Text Preprocessing\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 2: TEXT PREPROCESSING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Define helper functions for text preprocessing\n",
    "def get_wordnet_pos(tag):\n",
    "    \"\"\"Map POS tag to WordNet POS tag\"\"\"\n",
    "    tag_dict = {\n",
    "        \"J\": wordnet.ADJ,\n",
    "        \"N\": wordnet.NOUN,\n",
    "        \"V\": wordnet.VERB,\n",
    "        \"R\": wordnet.ADV\n",
    "    }\n",
    "    return tag_dict.get(tag[0].upper(), wordnet.NOUN)\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"Clean and normalize text\"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    \n",
    "    # Remove HTML tags\n",
    "    text = re.sub(r'<.*?>', ' ', text)\n",
    "    \n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove special characters and digits\n",
    "    text = re.sub(r'[^\\w\\s]', ' ', text)\n",
    "    text = re.sub(r'\\d+', ' ', text)\n",
    "    \n",
    "    # Remove extra spaces\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    \n",
    "    return text.strip()\n",
    "\n",
    "def preprocess_text(text, stop_words, lemmatizer):\n",
    "    \"\"\"Tokenize, remove stopwords, and lemmatize text\"\"\"\n",
    "    if not isinstance(text, str) or text == \"\":\n",
    "        return []\n",
    "    \n",
    "    # Clean the text\n",
    "    cleaned_text = clean_text(text)\n",
    "    \n",
    "    # Tokenize text\n",
    "    tokens = word_tokenize(cleaned_text)\n",
    "    \n",
    "    # Remove stopwords and short words\n",
    "    tokens = [word for word in tokens if word not in stop_words and len(word) > 1]\n",
    "    \n",
    "    try:\n",
    "        # Try lemmatizing tokens with POS tagging\n",
    "        tagged_tokens = pos_tag(tokens)\n",
    "        lemmatized_tokens = [lemmatizer.lemmatize(word, get_wordnet_pos(tag)) \n",
    "                           for word, tag in tagged_tokens]\n",
    "    except LookupError:\n",
    "        # Fallback to simple lemmatization without POS tagging\n",
    "        lemmatized_tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    \n",
    "    return lemmatized_tokens\n",
    "# Initialize NLTK tools\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning and tokenizing text corpus...\n",
      "\n",
      "Sample of preprocessed text:\n",
      "Movie: Toy Story (1995)\n",
      "Original text: Toy Story (1995) Led by Woody, Andy's toys live happily in his room until Andy's birthday brings Buz...\n",
      "Cleaned text: toy story led by woody andy s toys live happily in his room until andy s birthday brings buzz lighty...\n",
      "Tokens: ['toy', 'story', 'led', 'woody', 'andy', 'toy', 'live', 'happily', 'room', 'andy', 'birthday', 'brings', 'buzz', 'lightyear', 'onto', 'scene', 'afraid', 'losing', 'place', 'andy']...\n"
     ]
    }
   ],
   "source": [
    "# Apply preprocessing to movie text corpus\n",
    "print(\"Cleaning and tokenizing text corpus...\")\n",
    "movie_data['cleaned_text'] = movie_data['text_corpus'].apply(clean_text)\n",
    "movie_data['tokens'] = movie_data['cleaned_text'].apply(lambda x: preprocess_text(x, stop_words, lemmatizer))\n",
    "\n",
    "# Display sample of preprocessed text\n",
    "print(\"\\nSample of preprocessed text:\")\n",
    "sample_idx = 0\n",
    "print(f\"Movie: {movie_data.iloc[sample_idx]['title']}\")\n",
    "print(f\"Original text: {movie_data.iloc[sample_idx]['text_corpus'][:100]}...\")\n",
    "print(f\"Cleaned text: {movie_data.iloc[sample_idx]['cleaned_text'][:100]}...\")\n",
    "print(f\"Tokens: {movie_data.iloc[sample_idx]['tokens'][:20]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Vocabulary size: 176297 unique words\n",
      "Top 20 most common words: [('john', 17204), ('michael', 12303), ('robert', 11611), ('david', 10285), ('james', 9209), ('comedy', 8358), ('paul', 7471), ('life', 7082), ('richard', 6865), ('george', 6785), ('peter', 6759), ('based', 6471), ('book', 6466), ('story', 6392), ('nudity', 6012), ('tom', 5800), ('war', 5767), ('william', 5343), ('jack', 5307), ('film', 5305)]\n"
     ]
    }
   ],
   "source": [
    "# Count corpus words\n",
    "all_words = []\n",
    "for tokens in movie_data['tokens']:\n",
    "    all_words.extend(tokens)\n",
    "\n",
    "corpus_word_counts = Counter(all_words)\n",
    "print(f\"\\nVocabulary size: {len(corpus_word_counts)} unique words\")\n",
    "print(f\"Top 20 most common words: {corpus_word_counts.most_common(20)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Document frequency of top words:\n",
      "'john' appears in 9220 documents\n",
      "'michael' appears in 7213 documents\n",
      "'robert' appears in 6859 documents\n",
      "'david' appears in 6583 documents\n",
      "'james' appears in 5900 documents\n",
      "'life' appears in 5451 documents\n",
      "'paul' appears in 5279 documents\n",
      "'richard' appears in 5041 documents\n",
      "'peter' appears in 4719 documents\n",
      "'young' appears in 4607 documents\n",
      "\n",
      "Preprocessed movie text data:\n",
      "   movieId                    title  \\\n",
      "0        1         Toy Story (1995)   \n",
      "1        2           Jumanji (1995)   \n",
      "2        3  Grumpier Old Men (1995)   \n",
      "\n",
      "                                              tokens  \n",
      "0  [toy, story, led, woody, andy, toy, live, happ...  \n",
      "1  [jumanji, sibling, judy, peter, discover, ench...  \n",
      "2  [grumpier, old, men, family, wedding, reignite...  \n",
      "\n",
      "Token distribution plot saved as 'token_distribution.png'\n"
     ]
    }
   ],
   "source": [
    "# Calculate document frequency (number of documents containing each word)\n",
    "doc_freq = {}\n",
    "for tokens in movie_data['tokens']:\n",
    "    for word in set(tokens):  # Count each word only once per document\n",
    "        doc_freq[word] = doc_freq.get(word, 0) + 1\n",
    "\n",
    "print(f\"\\nDocument frequency of top words:\")\n",
    "for word, count in sorted(doc_freq.items(), key=lambda x: x[1], reverse=True)[:10]:\n",
    "    print(f\"'{word}' appears in {count} documents\")\n",
    "\n",
    "# Output: Preprocessed text data\n",
    "preprocessed_df = movie_data[['movieId', 'title', 'tokens']]\n",
    "print(\"\\nPreprocessed movie text data:\")\n",
    "print(preprocessed_df.head(3))\n",
    "# Plot token length distribution\n",
    "token_lengths = [len(tokens) for tokens in movie_data['tokens']]\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(token_lengths, bins=30, color='skyblue', edgecolor='black')\n",
    "plt.title('Distribution of Token Count per Movie')\n",
    "plt.xlabel('Number of Tokens')\n",
    "plt.ylabel('Number of Movies')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.savefig('token_distribution.png')\n",
    "print(\"\\nToken distribution plot saved as 'token_distribution.png'\")\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "STEP 3: DATA NORMALIZATION\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Data Normalization\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 3: DATA NORMALIZATION\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 20000263 ratings from 138493 users\n",
      "   userId  movieId  rating            timestamp\n",
      "0       1        2     3.5  2005-04-02 23:53:47\n",
      "1       1       29     3.5  2005-04-02 23:31:16\n",
      "2       1       32     3.5  2005-04-02 23:33:39\n",
      "3       1       47     3.5  2005-04-02 23:32:07\n",
      "4       1       50     3.5  2005-04-02 23:29:40\n",
      "\n",
      "User rating statistics:\n",
      "   userId  rating_count  rating_mean  rating_std\n",
      "0       1           175     3.742857    0.382284\n",
      "1       2            61     4.000000    1.064581\n",
      "2       3           187     4.122995    0.910427\n",
      "3       4            28     3.571429    0.790151\n",
      "4       5            66     4.272727    0.969464\n"
     ]
    }
   ],
   "source": [
    "# Load user ratings data\n",
    "ratings_df = pd.read_csv('data/20M/rating.csv')\n",
    "print(f\"Loaded {len(ratings_df)} ratings from {len(ratings_df['userId'].unique())} users\")\n",
    "print(ratings_df.head())\n",
    "\n",
    "# Calculate rating statistics by user\n",
    "user_stats = ratings_df.groupby('userId').agg({\n",
    "    'rating': ['count', 'mean', 'std']\n",
    "}).reset_index()\n",
    "user_stats.columns = ['userId', 'rating_count', 'rating_mean', 'rating_std']\n",
    "\n",
    "# Fill NA values in std with 0 (for users with only one rating)\n",
    "user_stats['rating_std'] = user_stats['rating_std'].fillna(0)\n",
    "\n",
    "print(\"\\nUser rating statistics:\")\n",
    "print(user_stats.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "User rating statistics plot saved as 'user_rating_stats.png'\n"
     ]
    }
   ],
   "source": [
    "# Plot user rating distributions\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.hist(user_stats['rating_mean'], bins=20, color='skyblue', edgecolor='black')\n",
    "plt.title('Distribution of Mean Ratings per User')\n",
    "plt.xlabel('Mean Rating')\n",
    "plt.ylabel('Number of Users')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.hist(user_stats['rating_std'], bins=20, color='lightgreen', edgecolor='black')\n",
    "plt.title('Distribution of Rating Standard Deviation per User')\n",
    "plt.xlabel('Rating Standard Deviation')\n",
    "plt.ylabel('Number of Users')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.hist(user_stats['rating_count'], bins=20, color='salmon', edgecolor='black')\n",
    "plt.title('Distribution of Rating Count per User')\n",
    "plt.xlabel('Number of Ratings')\n",
    "plt.ylabel('Number of Users')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('user_rating_stats.png')\n",
    "print(\"\\nUser rating statistics plot saved as 'user_rating_stats.png'\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Normalizing ratings...\n",
      "\n",
      "Original vs. Normalized ratings:\n",
      "   userId  movieId  rating  normalized_rating\n",
      "0       1        2     3.5           0.394120\n",
      "1       1       29     3.5           0.394120\n",
      "2       1       32     3.5           0.394120\n",
      "3       1       47     3.5           0.394120\n",
      "4       1       50     3.5           0.394120\n",
      "5       1      112     3.5           0.394120\n",
      "6       1      151     4.0           0.612108\n",
      "7       1      223     4.0           0.612108\n",
      "8       1      253     4.0           0.612108\n",
      "9       1      260     4.0           0.612108\n"
     ]
    }
   ],
   "source": [
    "# Normalize ratings using z-score and min-max scaling\n",
    "def normalize_ratings(ratings, user_stats):\n",
    "    normalized_ratings = ratings.copy()\n",
    "    \n",
    "    for index, row in normalized_ratings.iterrows():\n",
    "        user_id = row['userId']\n",
    "        user_data = user_stats[user_stats['userId'] == user_id]\n",
    "        \n",
    "        if user_data.empty:\n",
    "            # Skip if user not found in stats\n",
    "            normalized_ratings.at[index, 'normalized_rating'] = 0.5  # Default mid-value\n",
    "            continue\n",
    "            \n",
    "        user_data = user_data.iloc[0]\n",
    "        mean_rating = user_data['rating_mean']\n",
    "        std_rating = user_data['rating_std']\n",
    "        \n",
    "        if std_rating > 0:\n",
    "            # Z-score normalization\n",
    "            normalized_rating = (row['rating'] - mean_rating) / std_rating\n",
    "            # Scale to [0, 1]\n",
    "            normalized_rating = (normalized_rating + 3) / 6  # Assuming range is [-3, 3] after z-score\n",
    "            normalized_rating = min(max(normalized_rating, 0), 1)  # Clip to [0, 1]\n",
    "        else:\n",
    "            # If std is 0, just use min-max scaling from [0.5, 5] to [0, 1]\n",
    "            normalized_rating = (row['rating'] - 0.5) / 4.5\n",
    "        \n",
    "        normalized_ratings.at[index, 'normalized_rating'] = normalized_rating\n",
    "    \n",
    "    return normalized_ratings\n",
    "\n",
    "# Apply normalization\n",
    "print(\"\\nNormalizing ratings...\")\n",
    "normalized_ratings = normalize_ratings(ratings_df, user_stats)\n",
    "\n",
    "print(\"\\nOriginal vs. Normalized ratings:\")\n",
    "print(normalized_ratings[['userId', 'movieId', 'rating', 'normalized_rating']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Rating normalization plot saved as 'rating_normalization.png'\n",
      "\n",
      "Normalized ratings data:\n",
      "   userId  movieId  rating            timestamp  normalized_rating\n",
      "0       1        2     3.5  2005-04-02 23:53:47            0.39412\n",
      "1       1       29     3.5  2005-04-02 23:31:16            0.39412\n",
      "2       1       32     3.5  2005-04-02 23:33:39            0.39412\n",
      "3       1       47     3.5  2005-04-02 23:32:07            0.39412\n",
      "4       1       50     3.5  2005-04-02 23:29:40            0.39412\n"
     ]
    }
   ],
   "source": [
    "# Plot original vs normalized ratings\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(ratings_df['rating'], bins=9, color='skyblue', edgecolor='black', alpha=0.7)\n",
    "plt.title('Distribution of Original Ratings')\n",
    "plt.xlabel('Rating')\n",
    "plt.ylabel('Count')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(normalized_ratings['normalized_rating'], bins=20, color='salmon', edgecolor='black', alpha=0.7)\n",
    "plt.title('Distribution of Normalized Ratings')\n",
    "plt.xlabel('Normalized Rating')\n",
    "plt.ylabel('Count')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('rating_normalization.png')\n",
    "print(\"\\nRating normalization plot saved as 'rating_normalization.png'\")\n",
    "plt.close()\n",
    "\n",
    "# Output: Normalized ratings data\n",
    "print(\"\\nNormalized ratings data:\")\n",
    "print(normalized_ratings.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "STEP 4: GENRE ENCODING\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Genre Encoding (Binary Representation)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 4: GENRE ENCODING\")\n",
    "print(\"=\"*80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Example of raw genres format:\n",
      "   movieId                               title  \\\n",
      "0        1                    Toy Story (1995)   \n",
      "1        2                      Jumanji (1995)   \n",
      "2        3             Grumpier Old Men (1995)   \n",
      "3        4            Waiting to Exhale (1995)   \n",
      "4        5  Father of the Bride Part II (1995)   \n",
      "\n",
      "                                        genres  \n",
      "0  Adventure|Animation|Children|Comedy|Fantasy  \n",
      "1                   Adventure|Children|Fantasy  \n",
      "2                               Comedy|Romance  \n",
      "3                         Comedy|Drama|Romance  \n",
      "4                                       Comedy  \n"
     ]
    }
   ],
   "source": [
    "# Extract genres from movies dataframe\n",
    "print(\"\\nExample of raw genres format:\")\n",
    "print(movies_df[['movieId', 'title', 'genres']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found 20 unique genres: ['(no genres listed)', 'Action', 'Adventure', 'Animation', 'Children', 'Comedy', 'Crime', 'Documentary', 'Drama', 'Fantasy', 'Film-Noir', 'Horror', 'IMAX', 'Musical', 'Mystery', 'Romance', 'Sci-Fi', 'Thriller', 'War', 'Western']\n"
     ]
    }
   ],
   "source": [
    "# Count total unique genres\n",
    "all_genres = set()\n",
    "for genres in movies_df['genres'].str.split('|'):\n",
    "    if isinstance(genres, list):\n",
    "        all_genres.update(genres)\n",
    "\n",
    "print(f\"\\nFound {len(all_genres)} unique genres: {sorted(all_genres)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "One-hot encoded genres (sample):\n",
      "   movieId  (no genres listed)  Action  Adventure  Animation  Children  \\\n",
      "0        1                   0       0          1          1         1   \n",
      "1        2                   0       0          1          0         1   \n",
      "2        3                   0       0          0          0         0   \n",
      "3        4                   0       0          0          0         0   \n",
      "4        5                   0       0          0          0         0   \n",
      "\n",
      "   Comedy  Crime  Documentary  Drama  ...  Film-Noir  Horror  IMAX  Musical  \\\n",
      "0       1      0            0      0  ...          0       0     0        0   \n",
      "1       0      0            0      0  ...          0       0     0        0   \n",
      "2       1      0            0      0  ...          0       0     0        0   \n",
      "3       1      0            0      1  ...          0       0     0        0   \n",
      "4       1      0            0      0  ...          0       0     0        0   \n",
      "\n",
      "   Mystery  Romance  Sci-Fi  Thriller  War  Western  \n",
      "0        0        0       0         0    0        0  \n",
      "1        0        0       0         0    0        0  \n",
      "2        0        1       0         0    0        0  \n",
      "3        0        1       0         0    0        0  \n",
      "4        0        0       0         0    0        0  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "# One-hot encode genres\n",
    "# First, create a DataFrame with movieId and genre columns\n",
    "genre_data = []\n",
    "for _, movie in movies_df.iterrows():\n",
    "    movie_id = movie['movieId']\n",
    "    genres = movie['genres'].split('|') if isinstance(movie['genres'], str) else []\n",
    "    \n",
    "    for genre in genres:\n",
    "        genre_data.append({'movieId': movie_id, 'genre': genre})\n",
    "\n",
    "# Convert to DataFrame\n",
    "genre_df = pd.DataFrame(genre_data)\n",
    "\n",
    "# Create pivot table for one-hot encoding\n",
    "genre_one_hot = pd.pivot_table(\n",
    "    genre_df, \n",
    "    index='movieId', \n",
    "    columns='genre', \n",
    "    aggfunc=lambda x: 1, \n",
    "    fill_value=0\n",
    ").reset_index()\n",
    "\n",
    "# Flatten the column names\n",
    "genre_one_hot.columns.name = None\n",
    "\n",
    "print(\"\\nOne-hot encoded genres (sample):\")\n",
    "print(genre_one_hot.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Movies with genre encodings (sample):\n",
      "   movieId                               title  (no genres listed)  Action  \\\n",
      "0        1                    Toy Story (1995)                   0       0   \n",
      "1        2                      Jumanji (1995)                   0       0   \n",
      "2        3             Grumpier Old Men (1995)                   0       0   \n",
      "3        4            Waiting to Exhale (1995)                   0       0   \n",
      "4        5  Father of the Bride Part II (1995)                   0       0   \n",
      "\n",
      "   Adventure  Animation  Children  Comedy  Crime  Documentary  ...  Film-Noir  \\\n",
      "0          1          1         1       1      0            0  ...          0   \n",
      "1          1          0         1       0      0            0  ...          0   \n",
      "2          0          0         0       1      0            0  ...          0   \n",
      "3          0          0         0       1      0            0  ...          0   \n",
      "4          0          0         0       1      0            0  ...          0   \n",
      "\n",
      "   Horror  IMAX  Musical  Mystery  Romance  Sci-Fi  Thriller  War  Western  \n",
      "0       0     0        0        0        0       0         0    0        0  \n",
      "1       0     0        0        0        0       0         0    0        0  \n",
      "2       0     0        0        0        1       0         0    0        0  \n",
      "3       0     0        0        0        1       0         0    0        0  \n",
      "4       0     0        0        0        0       0         0    0        0  \n",
      "\n",
      "[5 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "# Merge with original movie data\n",
    "movie_genres = pd.merge(\n",
    "    movies_df[['movieId', 'title']], \n",
    "    genre_one_hot, \n",
    "    on='movieId', \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Fill NaN values with 0\n",
    "for genre in all_genres:\n",
    "    if genre in movie_genres.columns:\n",
    "        movie_genres[genre] = movie_genres[genre].fillna(0).astype(int)\n",
    "\n",
    "print(\"\\nMovies with genre encodings (sample):\")\n",
    "print(movie_genres.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Genre distribution plot saved as 'genre_distribution.png'\n",
      "\n",
      "Final genre-encoded data:\n",
      "   movieId                               title  (no genres listed)  Action  \\\n",
      "0        1                    Toy Story (1995)                   0       0   \n",
      "1        2                      Jumanji (1995)                   0       0   \n",
      "2        3             Grumpier Old Men (1995)                   0       0   \n",
      "3        4            Waiting to Exhale (1995)                   0       0   \n",
      "4        5  Father of the Bride Part II (1995)                   0       0   \n",
      "\n",
      "   Adventure  Animation  Children  Comedy  Crime  Documentary  ...  Film-Noir  \\\n",
      "0          1          1         1       1      0            0  ...          0   \n",
      "1          1          0         1       0      0            0  ...          0   \n",
      "2          0          0         0       1      0            0  ...          0   \n",
      "3          0          0         0       1      0            0  ...          0   \n",
      "4          0          0         0       1      0            0  ...          0   \n",
      "\n",
      "   Horror  IMAX  Musical  Mystery  Romance  Sci-Fi  Thriller  War  Western  \n",
      "0       0     0        0        0        0       0         0    0        0  \n",
      "1       0     0        0        0        0       0         0    0        0  \n",
      "2       0     0        0        0        1       0         0    0        0  \n",
      "3       0     0        0        0        1       0         0    0        0  \n",
      "4       0     0        0        0        0       0         0    0        0  \n",
      "\n",
      "[5 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "# Plot genre distribution\n",
    "genre_counts = {}\n",
    "for genre in all_genres:\n",
    "    if genre in movie_genres.columns:\n",
    "        genre_counts[genre] = movie_genres[genre].sum()\n",
    "\n",
    "# Sort genres by count\n",
    "sorted_genres = sorted(genre_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.bar([x[0] for x in sorted_genres], [x[1] for x in sorted_genres], color='skyblue', edgecolor='black')\n",
    "plt.title('Distribution of Movies by Genre')\n",
    "plt.xlabel('Genre')\n",
    "plt.ylabel('Number of Movies')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.grid(True, axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('genre_distribution.png')\n",
    "print(\"\\nGenre distribution plot saved as 'genre_distribution.png'\")\n",
    "plt.close()\n",
    "\n",
    "# Output: Genre-encoded data\n",
    "print(\"\\nFinal genre-encoded data:\")\n",
    "print(movie_genres.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "FINAL OUTPUT: COMBINED MOVIE FEATURES\n",
      "================================================================================\n",
      "\n",
      "Final movie features (sample):\n",
      "   movieId                               title  (no genres listed)  Action  \\\n",
      "0        1                    Toy Story (1995)                   0       0   \n",
      "1        2                      Jumanji (1995)                   0       0   \n",
      "2        3             Grumpier Old Men (1995)                   0       0   \n",
      "3        4            Waiting to Exhale (1995)                   0       0   \n",
      "4        5  Father of the Bride Part II (1995)                   0       0   \n",
      "\n",
      "   Adventure  Animation  Children  Comedy  Crime  Documentary  ...  IMAX  \\\n",
      "0          1          1         1       1      0            0  ...     0   \n",
      "1          1          0         1       0      0            0  ...     0   \n",
      "2          0          0         0       1      0            0  ...     0   \n",
      "3          0          0         0       1      0            0  ...     0   \n",
      "4          0          0         0       1      0            0  ...     0   \n",
      "\n",
      "   Musical  Mystery  Romance  Sci-Fi  Thriller  War  Western  token_count  \\\n",
      "0        0        0        0       0         0    0        0          659   \n",
      "1        0        0        0       0         0    0        0          324   \n",
      "2        0        0        1       0         0    0        0          103   \n",
      "3        0        0        1       0         0    0        0          137   \n",
      "4        0        0        0       0         0    0        0          180   \n",
      "\n",
      "                                top_keywords  \n",
      "0      [pixar, animation, disney, tom, hank]  \n",
      "1     [robin, williams, game, time, fantasy]  \n",
      "2            [old, max, sequel, local, jack]  \n",
      "3       [waiting, lee, brown, angela, chick]  \n",
      "4  [martin, steve, george, wedding, colwell]  \n",
      "\n",
      "[5 rows x 24 columns]\n",
      "\n",
      "Processed data saved to 'processed_movie_features.csv' and 'normalized_ratings.csv'\n",
      "\n",
      "================================================================================\n",
      "SUMMARY OF STAGE 1 DATA PROCESSING\n",
      "================================================================================\n",
      "1. Extracted text features for 27278 movies\n",
      "2. Preprocessed text resulting in a vocabulary of 176297 unique words\n",
      "3. Normalized 20000263 ratings from 138493 users\n",
      "4. Created one-hot encodings for 20 genres\n",
      "5. Final dataset contains 27278 movies with complete feature sets\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Final Output: Combined Movie Features\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FINAL OUTPUT: COMBINED MOVIE FEATURES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Combine all features into one DataFrame\n",
    "movie_features = pd.merge(\n",
    "    movie_genres,  # Contains movieId, title, and genre encodings\n",
    "    preprocessed_df[['movieId', 'tokens']],  # Contains preprocessed text tokens\n",
    "    on='movieId',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Add a column for text corpus length (token count)\n",
    "movie_features['token_count'] = movie_features['tokens'].apply(lambda x: len(x) if isinstance(x, list) else 0)\n",
    "\n",
    "# Add a column for the top 5 keywords for each movie (based on frequency)\n",
    "def get_top_keywords(tokens, n=5):\n",
    "    if not isinstance(tokens, list) or len(tokens) == 0:\n",
    "        return []\n",
    "    \n",
    "    word_counts = Counter(tokens)\n",
    "    return [word for word, _ in word_counts.most_common(n)]\n",
    "\n",
    "movie_features['top_keywords'] = movie_features['tokens'].apply(get_top_keywords)\n",
    "\n",
    "# Drop the tokens column to make the DataFrame more readable for display\n",
    "display_features = movie_features.drop(columns=['tokens'])\n",
    "\n",
    "print(\"\\nFinal movie features (sample):\")\n",
    "print(display_features.head())\n",
    "\n",
    "# Save the processed data for later use\n",
    "movie_features.to_csv('processed_movie_features.csv', index=False)\n",
    "normalized_ratings.to_csv('normalized_ratings.csv', index=False)\n",
    "\n",
    "print(\"\\nProcessed data saved to 'processed_movie_features.csv' and 'normalized_ratings.csv'\")\n",
    "\n",
    "# Summary of the data processing pipeline\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SUMMARY OF STAGE 1 DATA PROCESSING\")\n",
    "print(\"=\"*80)\n",
    "print(f\"1. Extracted text features for {len(movie_data)} movies\")\n",
    "print(f\"2. Preprocessed text resulting in a vocabulary of {len(corpus_word_counts)} unique words\")\n",
    "print(f\"3. Normalized {len(normalized_ratings)} ratings from {len(user_stats)} users\")\n",
    "print(f\"4. Created one-hot encodings for {len(all_genres)} genres\")\n",
    "print(f\"5. Final dataset contains {len(movie_features)} movies with complete feature sets\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
