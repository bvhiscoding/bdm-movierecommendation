{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "CONTENT-BASED MOVIE RECOMMENDATION SYSTEM WITH LOG-LIKELIHOOD AND WORD2VEC\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "STEP 1: DATA LOADING\n",
      "================================================================================\n",
      "Loading processed data from stage1.py...\n",
      "Loaded features for 15597 movies\n",
      "\n",
      "Sample of movie features data:\n",
      "   movieId                    title  \\\n",
      "0        1         Toy Story (1995)   \n",
      "1        2           Jumanji (1995)   \n",
      "2        3  Grumpier Old Men (1995)   \n",
      "\n",
      "                                      top_keywords  \n",
      "0            [woody, andy, animation, pixar, buzz]  \n",
      "1                [game, time, board, travel, alan]  \n",
      "2  [max, local, grumpier old men, family, wedding]  \n",
      "\n",
      "Average token count per movie: 31.77\n",
      "Min token count: 1, Max token count: 273\n",
      "\n",
      "Loaded 1476401 normalized ratings\n",
      "\n",
      "Sample of normalized ratings data:\n",
      "   userId  movieId  rating  normalized_rating\n",
      "0       1        2     3.5           0.666667\n",
      "1       1       29     3.5           0.666667\n",
      "2       1       32     3.5           0.666667\n",
      "\n",
      "Number of unique users: 10000\n",
      "Number of unique movies: 15597\n",
      "Rating sparsity: 99.0534%\n",
      "\n",
      "Split ratings into 1175202 training and 301199 testing samples\n",
      "Training set covers 8000 users and 14995 movies\n",
      "Testing set covers 2000 users and 11109 movies\n",
      "\n",
      "================================================================================\n",
      "STEP 2: CORPUS ANALYSIS\n",
      "================================================================================\n",
      "Building vocabulary and word frequency counts...\n",
      "Processed 1000/15597 movies (6.4%)\n",
      "Processed 2000/15597 movies (12.8%)\n",
      "Processed 3000/15597 movies (19.2%)\n",
      "Processed 4000/15597 movies (25.6%)\n",
      "Processed 5000/15597 movies (32.1%)\n",
      "Processed 6000/15597 movies (38.5%)\n",
      "Processed 7000/15597 movies (44.9%)\n",
      "Processed 8000/15597 movies (51.3%)\n",
      "Processed 9000/15597 movies (57.7%)\n",
      "Processed 10000/15597 movies (64.1%)\n",
      "Processed 11000/15597 movies (70.5%)\n",
      "Processed 12000/15597 movies (76.9%)\n",
      "Processed 13000/15597 movies (83.3%)\n",
      "Processed 14000/15597 movies (89.8%)\n",
      "Processed 15000/15597 movies (96.2%)\n",
      "Processed 15597/15597 movies (100.0%)\n",
      "Built vocabulary with 56636 unique words\n",
      "Total words in corpus: 495561\n",
      "\n",
      "Top 20 most common words in the corpus:\n",
      "'life': 3552\n",
      "'find': 2317\n",
      "'one': 2158\n",
      "'young': 2116\n",
      "'year': 1952\n",
      "'man': 1919\n",
      "'family': 1790\n",
      "'woman': 1765\n",
      "'love': 1747\n",
      "'two': 1674\n",
      "'friend': 1660\n",
      "'story': 1598\n",
      "'get': 1457\n",
      "'time': 1438\n",
      "'take': 1412\n",
      "'world': 1350\n",
      "'new': 1254\n",
      "'film': 1234\n",
      "'old': 1221\n",
      "'father': 1207\n",
      "\n",
      "================================================================================\n",
      "STEP 3: LOG-LIKELIHOOD CALCULATION\n",
      "================================================================================\n",
      "Calculating Log-Likelihood values for all movies in batches...\n",
      "Total corpus size: 495561 words\n",
      "Processing batch 1: movies 1-100 of 15597\n",
      "Progress: 0.6% - Elapsed: 0.01s - Est. remaining: 1.15s\n",
      "Processing batch 2: movies 101-200 of 15597\n",
      "Progress: 1.3% - Elapsed: 0.11s - Est. remaining: 16.85s\n",
      "Processing batch 3: movies 201-300 of 15597\n",
      "Progress: 1.9% - Elapsed: 0.21s - Est. remaining: 32.63s\n",
      "Processing batch 4: movies 301-400 of 15597\n",
      "Progress: 2.6% - Elapsed: 0.31s - Est. remaining: 46.54s\n",
      "Processing batch 5: movies 401-500 of 15597\n",
      "Progress: 3.2% - Elapsed: 0.43s - Est. remaining: 65.16s\n",
      "Processing batch 6: movies 501-600 of 15597\n",
      "Progress: 3.8% - Elapsed: 0.54s - Est. remaining: 80.45s\n",
      "Processing batch 7: movies 601-700 of 15597\n",
      "Progress: 4.5% - Elapsed: 0.64s - Est. remaining: 94.82s\n",
      "Processing batch 8: movies 701-800 of 15597\n",
      "Progress: 5.1% - Elapsed: 0.74s - Est. remaining: 110.06s\n",
      "Processing batch 9: movies 801-900 of 15597\n",
      "Progress: 5.8% - Elapsed: 0.87s - Est. remaining: 128.17s\n",
      "Processing batch 10: movies 901-1000 of 15597\n",
      "Progress: 6.4% - Elapsed: 0.98s - Est. remaining: 143.02s\n",
      "Processing batch 11: movies 1001-1100 of 15597\n",
      "Progress: 7.1% - Elapsed: 1.11s - Est. remaining: 160.41s\n",
      "Processing batch 12: movies 1101-1200 of 15597\n",
      "Progress: 7.7% - Elapsed: 1.21s - Est. remaining: 174.41s\n",
      "Processing batch 13: movies 1201-1300 of 15597\n",
      "Progress: 8.3% - Elapsed: 1.31s - Est. remaining: 187.18s\n",
      "Processing batch 14: movies 1301-1400 of 15597\n",
      "Progress: 9.0% - Elapsed: 1.40s - Est. remaining: 199.16s\n",
      "Processing batch 15: movies 1401-1500 of 15597\n",
      "Progress: 9.6% - Elapsed: 1.53s - Est. remaining: 215.33s\n",
      "Processing batch 16: movies 1501-1600 of 15597\n",
      "Progress: 10.3% - Elapsed: 1.63s - Est. remaining: 227.60s\n",
      "Processing batch 17: movies 1601-1700 of 15597\n",
      "Progress: 10.9% - Elapsed: 1.71s - Est. remaining: 237.32s\n",
      "Processing batch 18: movies 1701-1800 of 15597\n",
      "Progress: 11.5% - Elapsed: 1.83s - Est. remaining: 252.28s\n",
      "Processing batch 19: movies 1801-1900 of 15597\n",
      "Progress: 12.2% - Elapsed: 1.91s - Est. remaining: 260.99s\n",
      "Processing batch 20: movies 1901-2000 of 15597\n",
      "Progress: 12.8% - Elapsed: 2.01s - Est. remaining: 273.52s\n",
      "Processing batch 21: movies 2001-2100 of 15597\n",
      "Progress: 13.5% - Elapsed: 2.14s - Est. remaining: 288.66s\n",
      "Processing batch 22: movies 2101-2200 of 15597\n",
      "Progress: 14.1% - Elapsed: 2.21s - Est. remaining: 295.92s\n",
      "Processing batch 23: movies 2201-2300 of 15597\n",
      "Progress: 14.7% - Elapsed: 2.27s - Est. remaining: 301.51s\n",
      "Processing batch 24: movies 2301-2400 of 15597\n",
      "Progress: 15.4% - Elapsed: 2.35s - Est. remaining: 309.97s\n",
      "Processing batch 25: movies 2401-2500 of 15597\n",
      "Progress: 16.0% - Elapsed: 2.41s - Est. remaining: 316.03s\n",
      "Processing batch 26: movies 2501-2600 of 15597\n",
      "Progress: 16.7% - Elapsed: 2.48s - Est. remaining: 322.42s\n",
      "Processing batch 27: movies 2601-2700 of 15597\n",
      "Progress: 17.3% - Elapsed: 2.55s - Est. remaining: 328.42s\n",
      "Processing batch 28: movies 2701-2800 of 15597\n",
      "Progress: 18.0% - Elapsed: 2.61s - Est. remaining: 333.54s\n",
      "Processing batch 29: movies 2801-2900 of 15597\n",
      "Progress: 18.6% - Elapsed: 2.67s - Est. remaining: 338.85s\n",
      "Processing batch 30: movies 2901-3000 of 15597\n",
      "Progress: 19.2% - Elapsed: 2.75s - Est. remaining: 346.01s\n",
      "Processing batch 31: movies 3001-3100 of 15597\n",
      "Progress: 19.9% - Elapsed: 2.81s - Est. remaining: 351.04s\n",
      "Processing batch 32: movies 3101-3200 of 15597\n",
      "Progress: 20.5% - Elapsed: 2.86s - Est. remaining: 355.05s\n",
      "Processing batch 33: movies 3201-3300 of 15597\n",
      "Progress: 21.2% - Elapsed: 2.93s - Est. remaining: 359.75s\n",
      "Processing batch 34: movies 3301-3400 of 15597\n",
      "Progress: 21.8% - Elapsed: 2.99s - Est. remaining: 365.27s\n",
      "Processing batch 35: movies 3401-3500 of 15597\n",
      "Progress: 22.4% - Elapsed: 3.07s - Est. remaining: 371.98s\n",
      "Processing batch 36: movies 3501-3600 of 15597\n",
      "Progress: 23.1% - Elapsed: 3.12s - Est. remaining: 374.53s\n",
      "Processing batch 37: movies 3601-3700 of 15597\n",
      "Progress: 23.7% - Elapsed: 3.19s - Est. remaining: 379.66s\n",
      "Processing batch 38: movies 3701-3800 of 15597\n",
      "Progress: 24.4% - Elapsed: 3.25s - Est. remaining: 383.84s\n",
      "Processing batch 39: movies 3801-3900 of 15597\n",
      "Progress: 25.0% - Elapsed: 3.33s - Est. remaining: 389.21s\n",
      "Processing batch 40: movies 3901-4000 of 15597\n",
      "Progress: 25.6% - Elapsed: 3.39s - Est. remaining: 393.27s\n",
      "Processing batch 41: movies 4001-4100 of 15597\n",
      "Progress: 26.3% - Elapsed: 3.47s - Est. remaining: 398.67s\n",
      "Processing batch 42: movies 4101-4200 of 15597\n",
      "Progress: 26.9% - Elapsed: 3.55s - Est. remaining: 404.53s\n",
      "Processing batch 43: movies 4201-4300 of 15597\n",
      "Progress: 27.6% - Elapsed: 3.63s - Est. remaining: 410.02s\n",
      "Processing batch 44: movies 4301-4400 of 15597\n",
      "Progress: 28.2% - Elapsed: 3.75s - Est. remaining: 419.63s\n",
      "Processing batch 45: movies 4401-4500 of 15597\n",
      "Progress: 28.9% - Elapsed: 3.83s - Est. remaining: 424.58s\n",
      "Processing batch 46: movies 4501-4600 of 15597\n",
      "Progress: 29.5% - Elapsed: 3.94s - Est. remaining: 433.79s\n",
      "Processing batch 47: movies 4601-4700 of 15597\n",
      "Progress: 30.1% - Elapsed: 4.04s - Est. remaining: 440.30s\n",
      "Processing batch 48: movies 4701-4800 of 15597\n",
      "Progress: 30.8% - Elapsed: 4.10s - Est. remaining: 442.71s\n",
      "Processing batch 49: movies 4801-4900 of 15597\n",
      "Progress: 31.4% - Elapsed: 4.20s - Est. remaining: 448.75s\n",
      "Processing batch 50: movies 4901-5000 of 15597\n",
      "Progress: 32.1% - Elapsed: 4.28s - Est. remaining: 453.62s\n",
      "Processing batch 51: movies 5001-5100 of 15597\n",
      "Progress: 32.7% - Elapsed: 4.40s - Est. remaining: 461.80s\n",
      "Processing batch 52: movies 5101-5200 of 15597\n",
      "Progress: 33.3% - Elapsed: 4.47s - Est. remaining: 464.77s\n",
      "Processing batch 53: movies 5201-5300 of 15597\n",
      "Progress: 34.0% - Elapsed: 4.55s - Est. remaining: 468.90s\n",
      "Processing batch 54: movies 5301-5400 of 15597\n",
      "Progress: 34.6% - Elapsed: 4.66s - Est. remaining: 475.36s\n",
      "Processing batch 55: movies 5401-5500 of 15597\n",
      "Progress: 35.3% - Elapsed: 4.76s - Est. remaining: 480.16s\n",
      "Processing batch 56: movies 5501-5600 of 15597\n",
      "Progress: 35.9% - Elapsed: 4.85s - Est. remaining: 485.28s\n",
      "Processing batch 57: movies 5601-5700 of 15597\n",
      "Progress: 36.5% - Elapsed: 4.97s - Est. remaining: 492.27s\n",
      "Processing batch 58: movies 5701-5800 of 15597\n",
      "Progress: 37.2% - Elapsed: 5.07s - Est. remaining: 497.19s\n",
      "Processing batch 59: movies 5801-5900 of 15597\n",
      "Progress: 37.8% - Elapsed: 5.16s - Est. remaining: 500.02s\n",
      "Processing batch 60: movies 5901-6000 of 15597\n",
      "Progress: 38.5% - Elapsed: 5.24s - Est. remaining: 503.03s\n",
      "Processing batch 61: movies 6001-6100 of 15597\n",
      "Progress: 39.1% - Elapsed: 5.37s - Est. remaining: 509.76s\n",
      "Processing batch 62: movies 6101-6200 of 15597\n",
      "Progress: 39.8% - Elapsed: 5.48s - Est. remaining: 514.80s\n",
      "Processing batch 63: movies 6201-6300 of 15597\n",
      "Progress: 40.4% - Elapsed: 5.57s - Est. remaining: 518.30s\n",
      "Processing batch 64: movies 6301-6400 of 15597\n",
      "Progress: 41.0% - Elapsed: 5.67s - Est. remaining: 521.24s\n",
      "Processing batch 65: movies 6401-6500 of 15597\n",
      "Progress: 41.7% - Elapsed: 5.78s - Est. remaining: 526.02s\n",
      "Processing batch 66: movies 6501-6600 of 15597\n",
      "Progress: 42.3% - Elapsed: 5.89s - Est. remaining: 529.84s\n",
      "Processing batch 67: movies 6601-6700 of 15597\n",
      "Progress: 43.0% - Elapsed: 5.97s - Est. remaining: 531.40s\n",
      "Processing batch 68: movies 6701-6800 of 15597\n",
      "Progress: 43.6% - Elapsed: 6.07s - Est. remaining: 533.60s\n",
      "Processing batch 69: movies 6801-6900 of 15597\n",
      "Progress: 44.2% - Elapsed: 6.21s - Est. remaining: 540.13s\n",
      "Processing batch 70: movies 6901-7000 of 15597\n",
      "Progress: 44.9% - Elapsed: 6.40s - Est. remaining: 550.42s\n",
      "Processing batch 71: movies 7001-7100 of 15597\n",
      "Progress: 45.5% - Elapsed: 6.57s - Est. remaining: 557.87s\n",
      "Processing batch 72: movies 7101-7200 of 15597\n",
      "Progress: 46.2% - Elapsed: 6.73s - Est. remaining: 565.33s\n",
      "Processing batch 73: movies 7201-7300 of 15597\n",
      "Progress: 46.8% - Elapsed: 6.87s - Est. remaining: 570.21s\n",
      "Processing batch 74: movies 7301-7400 of 15597\n",
      "Progress: 47.4% - Elapsed: 7.03s - Est. remaining: 576.47s\n",
      "Processing batch 75: movies 7401-7500 of 15597\n",
      "Progress: 48.1% - Elapsed: 7.16s - Est. remaining: 579.63s\n",
      "Processing batch 76: movies 7501-7600 of 15597\n",
      "Progress: 48.7% - Elapsed: 7.28s - Est. remaining: 582.28s\n",
      "Processing batch 77: movies 7601-7700 of 15597\n",
      "Progress: 49.4% - Elapsed: 7.42s - Est. remaining: 585.96s\n",
      "Processing batch 78: movies 7701-7800 of 15597\n",
      "Progress: 50.0% - Elapsed: 7.52s - Est. remaining: 586.12s\n",
      "Processing batch 79: movies 7801-7900 of 15597\n",
      "Progress: 50.7% - Elapsed: 7.60s - Est. remaining: 585.26s\n",
      "Processing batch 80: movies 7901-8000 of 15597\n",
      "Progress: 51.3% - Elapsed: 7.73s - Est. remaining: 586.94s\n",
      "Processing batch 81: movies 8001-8100 of 15597\n",
      "Progress: 51.9% - Elapsed: 7.83s - Est. remaining: 586.97s\n",
      "Processing batch 82: movies 8101-8200 of 15597\n",
      "Progress: 52.6% - Elapsed: 7.96s - Est. remaining: 588.98s\n",
      "Processing batch 83: movies 8201-8300 of 15597\n",
      "Progress: 53.2% - Elapsed: 8.07s - Est. remaining: 588.89s\n",
      "Processing batch 84: movies 8301-8400 of 15597\n",
      "Progress: 53.9% - Elapsed: 8.16s - Est. remaining: 587.47s\n",
      "Processing batch 85: movies 8401-8500 of 15597\n",
      "Progress: 54.5% - Elapsed: 8.25s - Est. remaining: 585.47s\n",
      "Processing batch 86: movies 8501-8600 of 15597\n",
      "Progress: 55.1% - Elapsed: 8.33s - Est. remaining: 582.86s\n",
      "Processing batch 87: movies 8601-8700 of 15597\n",
      "Progress: 55.8% - Elapsed: 8.41s - Est. remaining: 579.85s\n",
      "Processing batch 88: movies 8701-8800 of 15597\n",
      "Progress: 56.4% - Elapsed: 8.50s - Est. remaining: 577.84s\n",
      "Processing batch 89: movies 8801-8900 of 15597\n",
      "Progress: 57.1% - Elapsed: 8.58s - Est. remaining: 574.65s\n",
      "Processing batch 90: movies 8901-9000 of 15597\n",
      "Progress: 57.7% - Elapsed: 8.69s - Est. remaining: 573.07s\n",
      "Processing batch 91: movies 9001-9100 of 15597\n",
      "Progress: 58.3% - Elapsed: 8.79s - Est. remaining: 571.02s\n",
      "Processing batch 92: movies 9101-9200 of 15597\n",
      "Progress: 59.0% - Elapsed: 8.91s - Est. remaining: 570.11s\n",
      "Processing batch 93: movies 9201-9300 of 15597\n",
      "Progress: 59.6% - Elapsed: 9.00s - Est. remaining: 566.57s\n",
      "Processing batch 94: movies 9301-9400 of 15597\n",
      "Progress: 60.3% - Elapsed: 9.08s - Est. remaining: 562.68s\n",
      "Processing batch 95: movies 9401-9500 of 15597\n",
      "Progress: 60.9% - Elapsed: 9.17s - Est. remaining: 558.82s\n",
      "Processing batch 96: movies 9501-9600 of 15597\n",
      "Progress: 61.6% - Elapsed: 9.27s - Est. remaining: 555.66s\n",
      "Processing batch 97: movies 9601-9700 of 15597\n",
      "Progress: 62.2% - Elapsed: 9.36s - Est. remaining: 552.00s\n",
      "Processing batch 98: movies 9701-9800 of 15597\n",
      "Progress: 62.8% - Elapsed: 9.44s - Est. remaining: 547.24s\n",
      "Processing batch 99: movies 9801-9900 of 15597\n",
      "Progress: 63.5% - Elapsed: 9.53s - Est. remaining: 543.04s\n",
      "Processing batch 100: movies 9901-10000 of 15597\n",
      "Progress: 64.1% - Elapsed: 9.66s - Est. remaining: 540.47s\n",
      "Processing batch 101: movies 10001-10100 of 15597\n",
      "Progress: 64.8% - Elapsed: 9.74s - Est. remaining: 535.32s\n",
      "Processing batch 102: movies 10101-10200 of 15597\n",
      "Progress: 65.4% - Elapsed: 9.83s - Est. remaining: 530.37s\n",
      "Processing batch 103: movies 10201-10300 of 15597\n",
      "Progress: 66.0% - Elapsed: 9.95s - Est. remaining: 527.13s\n",
      "Processing batch 104: movies 10301-10400 of 15597\n",
      "Progress: 66.7% - Elapsed: 10.05s - Est. remaining: 522.32s\n",
      "Processing batch 105: movies 10401-10500 of 15597\n",
      "Progress: 67.3% - Elapsed: 10.13s - Est. remaining: 516.43s\n",
      "Processing batch 106: movies 10501-10600 of 15597\n",
      "Progress: 68.0% - Elapsed: 10.25s - Est. remaining: 512.36s\n",
      "Processing batch 107: movies 10601-10700 of 15597\n",
      "Progress: 68.6% - Elapsed: 10.34s - Est. remaining: 506.42s\n",
      "Processing batch 108: movies 10701-10800 of 15597\n",
      "Progress: 69.2% - Elapsed: 10.43s - Est. remaining: 500.20s\n",
      "Processing batch 109: movies 10801-10900 of 15597\n",
      "Progress: 69.9% - Elapsed: 10.51s - Est. remaining: 493.50s\n",
      "Processing batch 110: movies 10901-11000 of 15597\n",
      "Progress: 70.5% - Elapsed: 10.62s - Est. remaining: 488.37s\n",
      "Processing batch 111: movies 11001-11100 of 15597\n",
      "Progress: 71.2% - Elapsed: 10.70s - Est. remaining: 481.21s\n",
      "Processing batch 112: movies 11101-11200 of 15597\n",
      "Progress: 71.8% - Elapsed: 10.79s - Est. remaining: 474.58s\n",
      "Processing batch 113: movies 11201-11300 of 15597\n",
      "Progress: 72.4% - Elapsed: 10.91s - Est. remaining: 468.99s\n",
      "Processing batch 114: movies 11301-11400 of 15597\n",
      "Progress: 73.1% - Elapsed: 11.02s - Est. remaining: 462.39s\n",
      "Processing batch 115: movies 11401-11500 of 15597\n",
      "Progress: 73.7% - Elapsed: 11.10s - Est. remaining: 454.90s\n",
      "Processing batch 116: movies 11501-11600 of 15597\n",
      "Progress: 74.4% - Elapsed: 11.18s - Est. remaining: 446.84s\n",
      "Processing batch 117: movies 11601-11700 of 15597\n",
      "Progress: 75.0% - Elapsed: 11.30s - Est. remaining: 440.36s\n",
      "Processing batch 118: movies 11701-11800 of 15597\n",
      "Progress: 75.7% - Elapsed: 11.38s - Est. remaining: 432.06s\n",
      "Processing batch 119: movies 11801-11900 of 15597\n",
      "Progress: 76.3% - Elapsed: 11.46s - Est. remaining: 423.82s\n",
      "Processing batch 120: movies 11901-12000 of 15597\n",
      "Progress: 76.9% - Elapsed: 11.58s - Est. remaining: 416.55s\n",
      "Processing batch 121: movies 12001-12100 of 15597\n",
      "Progress: 77.6% - Elapsed: 11.66s - Est. remaining: 407.77s\n",
      "Processing batch 122: movies 12101-12200 of 15597\n",
      "Progress: 78.2% - Elapsed: 11.74s - Est. remaining: 398.68s\n",
      "Processing batch 123: movies 12201-12300 of 15597\n",
      "Progress: 78.9% - Elapsed: 11.87s - Est. remaining: 391.20s\n",
      "Processing batch 124: movies 12301-12400 of 15597\n",
      "Progress: 79.5% - Elapsed: 11.96s - Est. remaining: 382.35s\n",
      "Processing batch 125: movies 12401-12500 of 15597\n",
      "Progress: 80.1% - Elapsed: 12.07s - Est. remaining: 373.77s\n",
      "Processing batch 126: movies 12501-12600 of 15597\n",
      "Progress: 80.8% - Elapsed: 12.17s - Est. remaining: 364.73s\n",
      "Processing batch 127: movies 12601-12700 of 15597\n",
      "Progress: 81.4% - Elapsed: 12.23s - Est. remaining: 354.40s\n",
      "Processing batch 128: movies 12701-12800 of 15597\n",
      "Progress: 82.1% - Elapsed: 12.36s - Est. remaining: 345.69s\n",
      "Processing batch 129: movies 12801-12900 of 15597\n",
      "Progress: 82.7% - Elapsed: 12.47s - Est. remaining: 336.30s\n",
      "Processing batch 130: movies 12901-13000 of 15597\n",
      "Progress: 83.3% - Elapsed: 12.55s - Est. remaining: 326.03s\n",
      "Processing batch 131: movies 13001-13100 of 15597\n",
      "Progress: 84.0% - Elapsed: 12.64s - Est. remaining: 315.56s\n",
      "Processing batch 132: movies 13101-13200 of 15597\n",
      "Progress: 84.6% - Elapsed: 12.76s - Est. remaining: 305.88s\n",
      "Processing batch 133: movies 13201-13300 of 15597\n",
      "Progress: 85.3% - Elapsed: 12.85s - Est. remaining: 295.19s\n",
      "Processing batch 134: movies 13301-13400 of 15597\n",
      "Progress: 85.9% - Elapsed: 12.93s - Est. remaining: 284.04s\n",
      "Processing batch 135: movies 13401-13500 of 15597\n",
      "Progress: 86.6% - Elapsed: 13.01s - Est. remaining: 272.83s\n",
      "Processing batch 136: movies 13501-13600 of 15597\n",
      "Progress: 87.2% - Elapsed: 13.11s - Est. remaining: 261.84s\n",
      "Processing batch 137: movies 13601-13700 of 15597\n",
      "Progress: 87.8% - Elapsed: 13.21s - Est. remaining: 250.56s\n",
      "Processing batch 138: movies 13701-13800 of 15597\n",
      "Progress: 88.5% - Elapsed: 13.30s - Est. remaining: 238.99s\n",
      "Processing batch 139: movies 13801-13900 of 15597\n",
      "Progress: 89.1% - Elapsed: 13.38s - Est. remaining: 227.06s\n",
      "Processing batch 140: movies 13901-14000 of 15597\n",
      "Progress: 89.8% - Elapsed: 13.53s - Est. remaining: 216.06s\n",
      "Processing batch 141: movies 14001-14100 of 15597\n",
      "Progress: 90.4% - Elapsed: 13.63s - Est. remaining: 204.07s\n",
      "Processing batch 142: movies 14101-14200 of 15597\n",
      "Progress: 91.0% - Elapsed: 13.74s - Est. remaining: 191.88s\n",
      "Processing batch 143: movies 14201-14300 of 15597\n",
      "Progress: 91.7% - Elapsed: 13.85s - Est. remaining: 179.66s\n",
      "Processing batch 144: movies 14301-14400 of 15597\n",
      "Progress: 92.3% - Elapsed: 13.94s - Est. remaining: 166.88s\n",
      "Processing batch 145: movies 14401-14500 of 15597\n",
      "Progress: 93.0% - Elapsed: 14.05s - Est. remaining: 154.12s\n",
      "Processing batch 146: movies 14501-14600 of 15597\n",
      "Progress: 93.6% - Elapsed: 14.14s - Est. remaining: 141.01s\n",
      "Processing batch 147: movies 14601-14700 of 15597\n",
      "Progress: 94.2% - Elapsed: 14.25s - Est. remaining: 127.86s\n",
      "Processing batch 148: movies 14701-14800 of 15597\n",
      "Progress: 94.9% - Elapsed: 14.34s - Est. remaining: 114.32s\n",
      "Processing batch 149: movies 14801-14900 of 15597\n",
      "Progress: 95.5% - Elapsed: 14.47s - Est. remaining: 100.85s\n",
      "Processing batch 150: movies 14901-15000 of 15597\n",
      "Progress: 96.2% - Elapsed: 14.56s - Est. remaining: 86.95s\n",
      "Processing batch 151: movies 15001-15100 of 15597\n",
      "Progress: 96.8% - Elapsed: 14.69s - Est. remaining: 73.00s\n",
      "Processing batch 152: movies 15101-15200 of 15597\n",
      "Progress: 97.5% - Elapsed: 14.81s - Est. remaining: 58.82s\n",
      "Processing batch 153: movies 15201-15300 of 15597\n",
      "Progress: 98.1% - Elapsed: 14.93s - Est. remaining: 44.35s\n",
      "Processing batch 154: movies 15301-15400 of 15597\n",
      "Progress: 98.7% - Elapsed: 15.04s - Est. remaining: 29.64s\n",
      "Processing batch 155: movies 15401-15500 of 15597\n",
      "Progress: 99.4% - Elapsed: 15.16s - Est. remaining: 14.70s\n",
      "Processing batch 156: movies 15501-15597 of 15597\n",
      "Progress: 100.0% - Elapsed: 15.26s - Est. remaining: 0.00s\n",
      "\n",
      "Sample Log-Likelihood values for movie 'Toy Story (1995)' (ID: 1):\n",
      "Word: 'woody', LL Value: 42.87\n",
      "Word: 'andy', LL Value: 36.03\n",
      "Word: 'pixar', LL Value: 33.48\n",
      "Word: 'buzz', LL Value: 26.72\n",
      "Word: 'animation', LL Value: 25.43\n",
      "Word: 'tom hanks pixar', LL Value: 18.36\n",
      "Word: 'buzz lightyear', LL Value: 15.59\n",
      "Word: 'tÃ£', LL Value: 13.36\n",
      "Word: 'toy story', LL Value: 12.62\n",
      "Word: 'aside', LL Value: 10.53\n",
      "Calculated Log-Likelihood values for 15597 movies\n",
      "Average number of words with LL > 10 per movie: 11.03\n",
      "Min: 0, Max: 53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-17 19:00:23,926 : INFO : collecting all words and their counts\n",
      "2025-04-17 19:00:23,926 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2025-04-17 19:00:23,973 : INFO : PROGRESS: at sentence #10000, processed 320514 words, keeping 42077 word types\n",
      "2025-04-17 19:00:24,002 : INFO : collected 56636 word types from a corpus of 495561 raw words and 15597 sentences\n",
      "2025-04-17 19:00:24,003 : INFO : Creating a fresh vocabulary\n",
      "2025-04-17 19:00:24,037 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 10526 unique words (18.59% of original 56636, drops 46110)', 'datetime': '2025-04-17T19:00:24.037823', 'gensim': '4.3.3', 'python': '3.10.1 (tags/v3.10.1:2cd268a, Dec  6 2021, 19:10:37) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22000-SP0', 'event': 'prepare_vocab'}\n",
      "2025-04-17 19:00:24,038 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 429945 word corpus (86.76% of original 495561, drops 65616)', 'datetime': '2025-04-17T19:00:24.038823', 'gensim': '4.3.3', 'python': '3.10.1 (tags/v3.10.1:2cd268a, Dec  6 2021, 19:10:37) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22000-SP0', 'event': 'prepare_vocab'}\n",
      "2025-04-17 19:00:24,095 : INFO : deleting the raw counts dictionary of 56636 items\n",
      "2025-04-17 19:00:24,097 : INFO : sample=0.001 downsamples 20 most-common words\n",
      "2025-04-17 19:00:24,098 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 420861.7488359756 word corpus (97.9%% of prior 429945)', 'datetime': '2025-04-17T19:00:24.098487', 'gensim': '4.3.3', 'python': '3.10.1 (tags/v3.10.1:2cd268a, Dec  6 2021, 19:10:37) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22000-SP0', 'event': 'prepare_vocab'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "STEP 4: WORD2VEC MODEL TRAINING\n",
      "================================================================================\n",
      "Training Word2Vec model with 100 dimensions...\n",
      "Loaded tokens from 1000/15597 movies (6.4%)\n",
      "Loaded tokens from 2000/15597 movies (12.8%)\n",
      "Loaded tokens from 3000/15597 movies (19.2%)\n",
      "Loaded tokens from 4000/15597 movies (25.6%)\n",
      "Loaded tokens from 5000/15597 movies (32.1%)\n",
      "Loaded tokens from 6000/15597 movies (38.5%)\n",
      "Loaded tokens from 7000/15597 movies (44.9%)\n",
      "Loaded tokens from 8000/15597 movies (51.3%)\n",
      "Loaded tokens from 9000/15597 movies (57.7%)\n",
      "Loaded tokens from 10000/15597 movies (64.1%)\n",
      "Loaded tokens from 11000/15597 movies (70.5%)\n",
      "Loaded tokens from 12000/15597 movies (76.9%)\n",
      "Loaded tokens from 13000/15597 movies (83.3%)\n",
      "Loaded tokens from 14000/15597 movies (89.8%)\n",
      "Loaded tokens from 15000/15597 movies (96.2%)\n",
      "Loaded tokens from 15597/15597 movies (100.0%)\n",
      "Training corpus size: 495561 tokens from 15597 documents\n",
      "Starting Word2Vec training (this may take a few minutes)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-17 19:00:24,163 : INFO : estimated required memory for 10526 words and 100 dimensions: 13683800 bytes\n",
      "2025-04-17 19:00:24,164 : INFO : resetting layer weights\n",
      "2025-04-17 19:00:24,169 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2025-04-17T19:00:24.169434', 'gensim': '4.3.3', 'python': '3.10.1 (tags/v3.10.1:2cd268a, Dec  6 2021, 19:10:37) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22000-SP0', 'event': 'build_vocab'}\n",
      "2025-04-17 19:00:24,170 : INFO : Word2Vec lifecycle event {'msg': 'training model with 4 workers on 10526 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2025-04-17T19:00:24.170432', 'gensim': '4.3.3', 'python': '3.10.1 (tags/v3.10.1:2cd268a, Dec  6 2021, 19:10:37) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22000-SP0', 'event': 'train'}\n",
      "2025-04-17 19:00:24,778 : INFO : EPOCH 0: training on 495561 raw words (420779 effective words) took 0.6s, 696994 effective words/s\n",
      "2025-04-17 19:00:25,353 : INFO : EPOCH 1: training on 495561 raw words (420885 effective words) took 0.6s, 738379 effective words/s\n",
      "2025-04-17 19:00:25,881 : INFO : EPOCH 2: training on 495561 raw words (420879 effective words) took 0.5s, 803588 effective words/s\n",
      "2025-04-17 19:00:26,440 : INFO : EPOCH 3: training on 495561 raw words (420986 effective words) took 0.6s, 757216 effective words/s\n",
      "2025-04-17 19:00:26,934 : INFO : EPOCH 4: training on 495561 raw words (420933 effective words) took 0.5s, 859752 effective words/s\n",
      "2025-04-17 19:00:27,473 : INFO : EPOCH 5: training on 495561 raw words (420931 effective words) took 0.5s, 785090 effective words/s\n",
      "2025-04-17 19:00:28,181 : INFO : EPOCH 6: training on 495561 raw words (420887 effective words) took 0.7s, 597668 effective words/s\n",
      "2025-04-17 19:00:28,828 : INFO : EPOCH 7: training on 495561 raw words (420795 effective words) took 0.6s, 654134 effective words/s\n",
      "2025-04-17 19:00:29,539 : INFO : EPOCH 8: training on 495561 raw words (420858 effective words) took 0.7s, 596623 effective words/s\n",
      "2025-04-17 19:00:30,264 : INFO : EPOCH 9: training on 495561 raw words (420945 effective words) took 0.7s, 584229 effective words/s\n",
      "2025-04-17 19:00:30,980 : INFO : EPOCH 10: training on 495561 raw words (420979 effective words) took 0.7s, 591960 effective words/s\n",
      "2025-04-17 19:00:31,636 : INFO : EPOCH 11: training on 495561 raw words (420892 effective words) took 0.6s, 648703 effective words/s\n",
      "2025-04-17 19:00:32,321 : INFO : EPOCH 12: training on 495561 raw words (420879 effective words) took 0.7s, 619197 effective words/s\n",
      "2025-04-17 19:00:33,363 : INFO : EPOCH 13 - PROGRESS: at 97.81% examples, 396852 words/s, in_qsize 1, out_qsize 1\n",
      "2025-04-17 19:00:33,382 : INFO : EPOCH 13: training on 495561 raw words (420860 effective words) took 1.1s, 397883 effective words/s\n",
      "2025-04-17 19:00:34,427 : INFO : EPOCH 14 - PROGRESS: at 73.90% examples, 311284 words/s, in_qsize 7, out_qsize 0\n",
      "2025-04-17 19:00:34,642 : INFO : EPOCH 14: training on 495561 raw words (420764 effective words) took 1.2s, 343678 effective words/s\n",
      "2025-04-17 19:00:35,267 : INFO : EPOCH 15: training on 495561 raw words (420763 effective words) took 0.6s, 679806 effective words/s\n",
      "2025-04-17 19:00:35,799 : INFO : EPOCH 16: training on 495561 raw words (420760 effective words) took 0.5s, 794637 effective words/s\n",
      "2025-04-17 19:00:36,393 : INFO : EPOCH 17: training on 495561 raw words (420785 effective words) took 0.6s, 713574 effective words/s\n",
      "2025-04-17 19:00:36,978 : INFO : EPOCH 18: training on 495561 raw words (420942 effective words) took 0.6s, 724036 effective words/s\n",
      "2025-04-17 19:00:37,532 : INFO : EPOCH 19: training on 495561 raw words (420910 effective words) took 0.5s, 768625 effective words/s\n",
      "2025-04-17 19:00:38,134 : INFO : EPOCH 20: training on 495561 raw words (420980 effective words) took 0.6s, 706407 effective words/s\n",
      "2025-04-17 19:00:38,645 : INFO : EPOCH 21: training on 495561 raw words (420771 effective words) took 0.5s, 828214 effective words/s\n",
      "2025-04-17 19:00:39,203 : INFO : EPOCH 22: training on 495561 raw words (420992 effective words) took 0.6s, 761747 effective words/s\n",
      "2025-04-17 19:00:39,727 : INFO : EPOCH 23: training on 495561 raw words (420834 effective words) took 0.5s, 798092 effective words/s\n",
      "2025-04-17 19:00:40,321 : INFO : EPOCH 24: training on 495561 raw words (420894 effective words) took 0.6s, 705580 effective words/s\n",
      "2025-04-17 19:00:40,337 : INFO : Word2Vec lifecycle event {'msg': 'training on 12389025 raw words (10521883 effective words) took 16.2s, 650834 effective words/s', 'datetime': '2025-04-17T19:00:40.337591', 'gensim': '4.3.3', 'python': '3.10.1 (tags/v3.10.1:2cd268a, Dec  6 2021, 19:10:37) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22000-SP0', 'event': 'train'}\n",
      "2025-04-17 19:00:40,337 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=10526, vector_size=100, alpha=0.025>', 'datetime': '2025-04-17T19:00:40.337591', 'gensim': '4.3.3', 'python': '3.10.1 (tags/v3.10.1:2cd268a, Dec  6 2021, 19:10:37) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22000-SP0', 'event': 'created'}\n",
      "2025-04-17 19:00:40,493 : INFO : Word2Vec lifecycle event {'fname_or_handle': './rec/content-recommendations\\\\word2vec_model', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2025-04-17T19:00:40.477766', 'gensim': '4.3.3', 'python': '3.10.1 (tags/v3.10.1:2cd268a, Dec  6 2021, 19:10:37) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22000-SP0', 'event': 'saving'}\n",
      "2025-04-17 19:00:40,493 : INFO : not storing attribute cum_table\n",
      "2025-04-17 19:00:40,493 : INFO : saved ./rec/content-recommendations\\word2vec_model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec training completed in 16.55 seconds\n",
      "Word2Vec model vocabulary size: 10526 words\n",
      "\n",
      "Example word vectors from the trained model:\n",
      "'life': [-0.1331653   0.1447169  -0.1565991   0.16734359 -0.13623318]...\n",
      "'find': [-0.06630741  0.07161452  0.2895959  -0.13645025  0.01124258]...\n",
      "'one': [-0.00383072  0.01343242 -0.01334147  0.13722739 -0.02237568]...\n",
      "'young': [-0.00285587  0.04664513  0.39584547  0.22857559 -0.02308213]...\n",
      "'year': [-0.10162728  0.11932383 -0.2685828   0.09097381  0.34784853]...\n",
      "'man': [-0.05770181 -0.00540611  0.1960616   0.13434081 -0.21820319]...\n",
      "'family': [ 0.03941261  0.09690348  0.37980968 -0.07581328 -0.12075664]...\n",
      "'woman': [-0.02292731  0.09135665  0.31914535  0.40973133 -0.15492617]...\n",
      "'love': [0.11889771 0.11612496 0.05649545 0.12811585 0.33568144]...\n",
      "'two': [-0.21881759 -0.32106325  0.2607771   0.4193083  -0.20562954]...\n",
      "\n",
      "Example word similarities:\n",
      "Words similar to 'action': [('packed', 0.6525827646255493), ('keira knightley', 0.5913197994232178), ('damon', 0.5702375173568726), ('angelina jolie', 0.5591294169425964), ('carrie fisher', 0.5568510293960571)]\n",
      "Words similar to 'love': [('madly', 0.6849327683448792), ('intimacy', 0.6411151885986328), ('altar', 0.6205316781997681), ('liliom', 0.5945253372192383), ('unrequited', 0.587310254573822)]\n",
      "Words similar to 'hero': [('tempted', 0.5413933992385864), ('alan moore', 0.5386875867843628), ('vigilantism', 0.5368308424949646), ('swashbuckling', 0.526409387588501), ('super', 0.5263887643814087)]\n",
      "Words similar to 'villain': [('superheroes', 0.6071042418479919), ('fantastic four', 0.572883665561676), ('alan moore', 0.5481836199760437), ('jaw', 0.544040322303772), ('vanquish', 0.5424493551254272)]\n",
      "Trained and saved Word2Vec model with 10526 words\n",
      "\n",
      "================================================================================\n",
      "STEP 5: MOVIE VECTOR GENERATION\n",
      "================================================================================\n",
      "Generating movie feature vectors using Log-Likelihood + Word2Vec in batches...\n",
      "Processing batch 1: movies 1-100 of 15597\n",
      "Progress: 0.6% - Elapsed: 0.01s - Est. remaining: 1.39s\n",
      "Successfully created vectors: 100/100\n",
      "Processing batch 2: movies 101-200 of 15597\n",
      "Progress: 1.3% - Elapsed: 0.10s - Est. remaining: 15.14s\n",
      "Successfully created vectors: 200/200\n",
      "Processing batch 3: movies 201-300 of 15597\n",
      "Progress: 1.9% - Elapsed: 0.21s - Est. remaining: 31.88s\n",
      "Successfully created vectors: 300/300\n",
      "Processing batch 4: movies 301-400 of 15597\n",
      "Progress: 2.6% - Elapsed: 0.36s - Est. remaining: 54.01s\n",
      "Successfully created vectors: 400/400\n",
      "Processing batch 5: movies 401-500 of 15597\n",
      "Progress: 3.2% - Elapsed: 0.46s - Est. remaining: 68.75s\n",
      "Successfully created vectors: 500/500\n",
      "Processing batch 6: movies 501-600 of 15597\n",
      "Progress: 3.8% - Elapsed: 0.61s - Est. remaining: 91.93s\n",
      "Successfully created vectors: 600/600\n",
      "Processing batch 7: movies 601-700 of 15597\n",
      "Progress: 4.5% - Elapsed: 0.76s - Est. remaining: 113.09s\n",
      "Successfully created vectors: 700/700\n",
      "Processing batch 8: movies 701-800 of 15597\n",
      "Progress: 5.1% - Elapsed: 0.86s - Est. remaining: 126.94s\n",
      "Successfully created vectors: 794/800\n",
      "Processing batch 9: movies 801-900 of 15597\n",
      "Progress: 5.8% - Elapsed: 1.03s - Est. remaining: 150.96s\n",
      "Successfully created vectors: 893/900\n",
      "Processing batch 10: movies 901-1000 of 15597\n",
      "Progress: 6.4% - Elapsed: 1.13s - Est. remaining: 164.88s\n",
      "Successfully created vectors: 993/1000\n",
      "Processing batch 11: movies 1001-1100 of 15597\n",
      "Progress: 7.1% - Elapsed: 1.26s - Est. remaining: 182.40s\n",
      "Successfully created vectors: 1091/1100\n",
      "Processing batch 12: movies 1101-1200 of 15597\n",
      "Progress: 7.7% - Elapsed: 1.40s - Est. remaining: 200.90s\n",
      "Successfully created vectors: 1190/1200\n",
      "Processing batch 13: movies 1201-1300 of 15597\n",
      "Progress: 8.3% - Elapsed: 1.56s - Est. remaining: 222.86s\n",
      "Successfully created vectors: 1290/1300\n",
      "Processing batch 14: movies 1301-1400 of 15597\n",
      "Progress: 9.0% - Elapsed: 1.67s - Est. remaining: 237.69s\n",
      "Successfully created vectors: 1389/1400\n",
      "Processing batch 15: movies 1401-1500 of 15597\n",
      "Progress: 9.6% - Elapsed: 1.81s - Est. remaining: 254.49s\n",
      "Successfully created vectors: 1489/1500\n",
      "Processing batch 16: movies 1501-1600 of 15597\n",
      "Progress: 10.3% - Elapsed: 1.94s - Est. remaining: 271.72s\n",
      "Successfully created vectors: 1589/1600\n",
      "Processing batch 17: movies 1601-1700 of 15597\n",
      "Progress: 10.9% - Elapsed: 2.06s - Est. remaining: 286.97s\n",
      "Successfully created vectors: 1687/1700\n",
      "Processing batch 18: movies 1701-1800 of 15597\n",
      "Progress: 11.5% - Elapsed: 2.18s - Est. remaining: 300.49s\n",
      "Successfully created vectors: 1787/1800\n",
      "Processing batch 19: movies 1801-1900 of 15597\n",
      "Progress: 12.2% - Elapsed: 2.34s - Est. remaining: 320.37s\n",
      "Successfully created vectors: 1887/1900\n",
      "Processing batch 20: movies 1901-2000 of 15597\n",
      "Progress: 12.8% - Elapsed: 2.47s - Est. remaining: 335.74s\n",
      "Successfully created vectors: 1987/2000\n",
      "Processing batch 21: movies 2001-2100 of 15597\n",
      "Progress: 13.5% - Elapsed: 2.61s - Est. remaining: 352.07s\n",
      "Successfully created vectors: 2087/2100\n",
      "Processing batch 22: movies 2101-2200 of 15597\n",
      "Progress: 14.1% - Elapsed: 2.73s - Est. remaining: 365.95s\n",
      "Successfully created vectors: 2186/2200\n",
      "Processing batch 23: movies 2201-2300 of 15597\n",
      "Progress: 14.7% - Elapsed: 2.84s - Est. remaining: 378.25s\n",
      "Successfully created vectors: 2286/2300\n",
      "Processing batch 24: movies 2301-2400 of 15597\n",
      "Progress: 15.4% - Elapsed: 2.99s - Est. remaining: 395.05s\n",
      "Successfully created vectors: 2386/2400\n",
      "Processing batch 25: movies 2401-2500 of 15597\n",
      "Progress: 16.0% - Elapsed: 3.10s - Est. remaining: 406.04s\n",
      "Successfully created vectors: 2485/2500\n",
      "Processing batch 26: movies 2501-2600 of 15597\n",
      "Progress: 16.7% - Elapsed: 3.20s - Est. remaining: 416.04s\n",
      "Successfully created vectors: 2585/2600\n",
      "Processing batch 27: movies 2601-2700 of 15597\n",
      "Progress: 17.3% - Elapsed: 3.35s - Est. remaining: 431.64s\n",
      "Successfully created vectors: 2685/2700\n",
      "Processing batch 28: movies 2701-2800 of 15597\n",
      "Progress: 18.0% - Elapsed: 3.47s - Est. remaining: 444.30s\n",
      "Successfully created vectors: 2784/2800\n",
      "Processing batch 29: movies 2801-2900 of 15597\n",
      "Progress: 18.6% - Elapsed: 3.60s - Est. remaining: 457.26s\n",
      "Successfully created vectors: 2884/2900\n",
      "Processing batch 30: movies 2901-3000 of 15597\n",
      "Progress: 19.2% - Elapsed: 3.73s - Est. remaining: 469.56s\n",
      "Successfully created vectors: 2984/3000\n",
      "Processing batch 31: movies 3001-3100 of 15597\n",
      "Progress: 19.9% - Elapsed: 3.83s - Est. remaining: 478.45s\n",
      "Successfully created vectors: 3084/3100\n",
      "Processing batch 32: movies 3101-3200 of 15597\n",
      "Progress: 20.5% - Elapsed: 3.96s - Est. remaining: 491.02s\n",
      "Successfully created vectors: 3184/3200\n",
      "Processing batch 33: movies 3201-3300 of 15597\n",
      "Progress: 21.2% - Elapsed: 4.08s - Est. remaining: 501.34s\n",
      "Successfully created vectors: 3284/3300\n",
      "Processing batch 34: movies 3301-3400 of 15597\n",
      "Progress: 21.8% - Elapsed: 4.19s - Est. remaining: 510.89s\n",
      "Successfully created vectors: 3384/3400\n",
      "Processing batch 35: movies 3401-3500 of 15597\n",
      "Progress: 22.4% - Elapsed: 4.33s - Est. remaining: 524.13s\n",
      "Successfully created vectors: 3484/3500\n",
      "Processing batch 36: movies 3501-3600 of 15597\n",
      "Progress: 23.1% - Elapsed: 4.45s - Est. remaining: 534.07s\n",
      "Successfully created vectors: 3584/3600\n",
      "Processing batch 37: movies 3601-3700 of 15597\n",
      "Progress: 23.7% - Elapsed: 4.59s - Est. remaining: 546.31s\n",
      "Successfully created vectors: 3684/3700\n",
      "Processing batch 38: movies 3701-3800 of 15597\n",
      "Progress: 24.4% - Elapsed: 4.69s - Est. remaining: 553.35s\n",
      "Successfully created vectors: 3784/3800\n",
      "Processing batch 39: movies 3801-3900 of 15597\n",
      "Progress: 25.0% - Elapsed: 4.81s - Est. remaining: 562.18s\n",
      "Successfully created vectors: 3884/3900\n",
      "Processing batch 40: movies 3901-4000 of 15597\n",
      "Progress: 25.6% - Elapsed: 4.96s - Est. remaining: 574.68s\n",
      "Successfully created vectors: 3984/4000\n",
      "Processing batch 41: movies 4001-4100 of 15597\n",
      "Progress: 26.3% - Elapsed: 5.09s - Est. remaining: 585.45s\n",
      "Successfully created vectors: 4083/4100\n",
      "Processing batch 42: movies 4101-4200 of 15597\n",
      "Progress: 26.9% - Elapsed: 5.20s - Est. remaining: 592.33s\n",
      "Successfully created vectors: 4183/4200\n",
      "Processing batch 43: movies 4201-4300 of 15597\n",
      "Progress: 27.6% - Elapsed: 5.34s - Est. remaining: 603.31s\n",
      "Successfully created vectors: 4283/4300\n",
      "Processing batch 44: movies 4301-4400 of 15597\n",
      "Progress: 28.2% - Elapsed: 5.43s - Est. remaining: 607.93s\n",
      "Successfully created vectors: 4383/4400\n",
      "Processing batch 45: movies 4401-4500 of 15597\n",
      "Progress: 28.9% - Elapsed: 5.50s - Est. remaining: 610.88s\n",
      "Successfully created vectors: 4483/4500\n",
      "Processing batch 46: movies 4501-4600 of 15597\n",
      "Progress: 29.5% - Elapsed: 5.60s - Est. remaining: 616.06s\n",
      "Successfully created vectors: 4583/4600\n",
      "Processing batch 47: movies 4601-4700 of 15597\n",
      "Progress: 30.1% - Elapsed: 5.68s - Est. remaining: 619.49s\n",
      "Successfully created vectors: 4683/4700\n",
      "Processing batch 48: movies 4701-4800 of 15597\n",
      "Progress: 30.8% - Elapsed: 5.77s - Est. remaining: 623.07s\n",
      "Successfully created vectors: 4783/4800\n",
      "Processing batch 49: movies 4801-4900 of 15597\n",
      "Progress: 31.4% - Elapsed: 5.87s - Est. remaining: 627.67s\n",
      "Successfully created vectors: 4883/4900\n",
      "Processing batch 50: movies 4901-5000 of 15597\n",
      "Progress: 32.1% - Elapsed: 6.02s - Est. remaining: 637.65s\n",
      "Successfully created vectors: 4983/5000\n",
      "Processing batch 51: movies 5001-5100 of 15597\n",
      "Progress: 32.7% - Elapsed: 6.11s - Est. remaining: 641.25s\n",
      "Successfully created vectors: 5081/5100\n",
      "Processing batch 52: movies 5101-5200 of 15597\n",
      "Progress: 33.3% - Elapsed: 6.19s - Est. remaining: 643.22s\n",
      "Successfully created vectors: 5181/5200\n",
      "Processing batch 53: movies 5201-5300 of 15597\n",
      "Progress: 34.0% - Elapsed: 6.27s - Est. remaining: 645.74s\n",
      "Successfully created vectors: 5281/5300\n",
      "Processing batch 54: movies 5301-5400 of 15597\n",
      "Progress: 34.6% - Elapsed: 6.37s - Est. remaining: 649.85s\n",
      "Successfully created vectors: 5381/5400\n",
      "Processing batch 55: movies 5401-5500 of 15597\n",
      "Progress: 35.3% - Elapsed: 6.48s - Est. remaining: 654.54s\n",
      "Successfully created vectors: 5481/5500\n",
      "Processing batch 56: movies 5501-5600 of 15597\n",
      "Progress: 35.9% - Elapsed: 6.59s - Est. remaining: 658.80s\n",
      "Successfully created vectors: 5581/5600\n",
      "Processing batch 57: movies 5601-5700 of 15597\n",
      "Progress: 36.5% - Elapsed: 6.69s - Est. remaining: 662.43s\n",
      "Successfully created vectors: 5681/5700\n",
      "Processing batch 58: movies 5701-5800 of 15597\n",
      "Progress: 37.2% - Elapsed: 6.79s - Est. remaining: 665.66s\n",
      "Successfully created vectors: 5781/5800\n",
      "Processing batch 59: movies 5801-5900 of 15597\n",
      "Progress: 37.8% - Elapsed: 6.92s - Est. remaining: 671.10s\n",
      "Successfully created vectors: 5881/5900\n",
      "Processing batch 60: movies 5901-6000 of 15597\n",
      "Progress: 38.5% - Elapsed: 7.05s - Est. remaining: 676.64s\n",
      "Successfully created vectors: 5981/6000\n",
      "Processing batch 61: movies 6001-6100 of 15597\n",
      "Progress: 39.1% - Elapsed: 7.15s - Est. remaining: 679.00s\n",
      "Successfully created vectors: 6081/6100\n",
      "Processing batch 62: movies 6101-6200 of 15597\n",
      "Progress: 39.8% - Elapsed: 7.23s - Est. remaining: 679.00s\n",
      "Successfully created vectors: 6181/6200\n",
      "Processing batch 63: movies 6201-6300 of 15597\n",
      "Progress: 40.4% - Elapsed: 7.32s - Est. remaining: 680.20s\n",
      "Successfully created vectors: 6281/6300\n",
      "Processing batch 64: movies 6301-6400 of 15597\n",
      "Progress: 41.0% - Elapsed: 7.40s - Est. remaining: 680.53s\n",
      "Successfully created vectors: 6381/6400\n",
      "Processing batch 65: movies 6401-6500 of 15597\n",
      "Progress: 41.7% - Elapsed: 7.47s - Est. remaining: 679.38s\n",
      "Successfully created vectors: 6481/6500\n",
      "Processing batch 66: movies 6501-6600 of 15597\n",
      "Progress: 42.3% - Elapsed: 7.56s - Est. remaining: 680.48s\n",
      "Successfully created vectors: 6581/6600\n",
      "Processing batch 67: movies 6601-6700 of 15597\n",
      "Progress: 43.0% - Elapsed: 7.65s - Est. remaining: 680.93s\n",
      "Successfully created vectors: 6681/6700\n",
      "Processing batch 68: movies 6701-6800 of 15597\n",
      "Progress: 43.6% - Elapsed: 7.74s - Est. remaining: 680.49s\n",
      "Successfully created vectors: 6781/6800\n",
      "Processing batch 69: movies 6801-6900 of 15597\n",
      "Progress: 44.2% - Elapsed: 7.81s - Est. remaining: 678.81s\n",
      "Successfully created vectors: 6881/6900\n",
      "Processing batch 70: movies 6901-7000 of 15597\n",
      "Progress: 44.9% - Elapsed: 7.90s - Est. remaining: 679.02s\n",
      "Successfully created vectors: 6981/7000\n",
      "Processing batch 71: movies 7001-7100 of 15597\n",
      "Progress: 45.5% - Elapsed: 7.98s - Est. remaining: 678.21s\n",
      "Successfully created vectors: 7081/7100\n",
      "Processing batch 72: movies 7101-7200 of 15597\n",
      "Progress: 46.2% - Elapsed: 8.06s - Est. remaining: 676.89s\n",
      "Successfully created vectors: 7181/7200\n",
      "Processing batch 73: movies 7201-7300 of 15597\n",
      "Progress: 46.8% - Elapsed: 8.14s - Est. remaining: 675.63s\n",
      "Successfully created vectors: 7280/7300\n",
      "Processing batch 74: movies 7301-7400 of 15597\n",
      "Progress: 47.4% - Elapsed: 8.22s - Est. remaining: 674.16s\n",
      "Successfully created vectors: 7380/7400\n",
      "Processing batch 75: movies 7401-7500 of 15597\n",
      "Progress: 48.1% - Elapsed: 8.30s - Est. remaining: 671.84s\n",
      "Successfully created vectors: 7480/7500\n",
      "Processing batch 76: movies 7501-7600 of 15597\n",
      "Progress: 48.7% - Elapsed: 8.40s - Est. remaining: 671.53s\n",
      "Successfully created vectors: 7580/7600\n",
      "Processing batch 77: movies 7601-7700 of 15597\n",
      "Progress: 49.4% - Elapsed: 8.47s - Est. remaining: 669.25s\n",
      "Successfully created vectors: 7680/7700\n",
      "Processing batch 78: movies 7701-7800 of 15597\n",
      "Progress: 50.0% - Elapsed: 8.55s - Est. remaining: 666.70s\n",
      "Successfully created vectors: 7780/7800\n",
      "Processing batch 79: movies 7801-7900 of 15597\n",
      "Progress: 50.7% - Elapsed: 8.63s - Est. remaining: 664.23s\n",
      "Successfully created vectors: 7880/7900\n",
      "Processing batch 80: movies 7901-8000 of 15597\n",
      "Progress: 51.3% - Elapsed: 8.72s - Est. remaining: 662.51s\n",
      "Successfully created vectors: 7980/8000\n",
      "Processing batch 81: movies 8001-8100 of 15597\n",
      "Progress: 51.9% - Elapsed: 8.81s - Est. remaining: 660.39s\n",
      "Successfully created vectors: 8080/8100\n",
      "Processing batch 82: movies 8101-8200 of 15597\n",
      "Progress: 52.6% - Elapsed: 8.93s - Est. remaining: 660.91s\n",
      "Successfully created vectors: 8180/8200\n",
      "Processing batch 83: movies 8201-8300 of 15597\n",
      "Progress: 53.2% - Elapsed: 9.01s - Est. remaining: 657.81s\n",
      "Successfully created vectors: 8280/8300\n",
      "Processing batch 84: movies 8301-8400 of 15597\n",
      "Progress: 53.9% - Elapsed: 9.11s - Est. remaining: 656.00s\n",
      "Successfully created vectors: 8380/8400\n",
      "Processing batch 85: movies 8401-8500 of 15597\n",
      "Progress: 54.5% - Elapsed: 9.19s - Est. remaining: 652.44s\n",
      "Successfully created vectors: 8480/8500\n",
      "Processing batch 86: movies 8501-8600 of 15597\n",
      "Progress: 55.1% - Elapsed: 9.28s - Est. remaining: 649.40s\n",
      "Successfully created vectors: 8579/8600\n",
      "Processing batch 87: movies 8601-8700 of 15597\n",
      "Progress: 55.8% - Elapsed: 9.37s - Est. remaining: 646.39s\n",
      "Successfully created vectors: 8679/8700\n",
      "Processing batch 88: movies 8701-8800 of 15597\n",
      "Progress: 56.4% - Elapsed: 9.46s - Est. remaining: 642.99s\n",
      "Successfully created vectors: 8779/8800\n",
      "Processing batch 89: movies 8801-8900 of 15597\n",
      "Progress: 57.1% - Elapsed: 9.54s - Est. remaining: 638.86s\n",
      "Successfully created vectors: 8879/8900\n",
      "Processing batch 90: movies 8901-9000 of 15597\n",
      "Progress: 57.7% - Elapsed: 9.62s - Est. remaining: 634.91s\n",
      "Successfully created vectors: 8978/9000\n",
      "Processing batch 91: movies 9001-9100 of 15597\n",
      "Progress: 58.3% - Elapsed: 9.69s - Est. remaining: 629.68s\n",
      "Successfully created vectors: 9078/9100\n",
      "Processing batch 92: movies 9101-9200 of 15597\n",
      "Progress: 59.0% - Elapsed: 9.79s - Est. remaining: 626.22s\n",
      "Successfully created vectors: 9178/9200\n",
      "Processing batch 93: movies 9201-9300 of 15597\n",
      "Progress: 59.6% - Elapsed: 9.88s - Est. remaining: 621.98s\n",
      "Successfully created vectors: 9278/9300\n",
      "Processing batch 94: movies 9301-9400 of 15597\n",
      "Progress: 60.3% - Elapsed: 9.96s - Est. remaining: 617.18s\n",
      "Successfully created vectors: 9378/9400\n",
      "Processing batch 95: movies 9401-9500 of 15597\n",
      "Progress: 60.9% - Elapsed: 10.05s - Est. remaining: 612.86s\n",
      "Successfully created vectors: 9478/9500\n",
      "Processing batch 96: movies 9501-9600 of 15597\n",
      "Progress: 61.6% - Elapsed: 10.13s - Est. remaining: 607.58s\n",
      "Successfully created vectors: 9578/9600\n",
      "Processing batch 97: movies 9601-9700 of 15597\n",
      "Progress: 62.2% - Elapsed: 10.22s - Est. remaining: 602.85s\n",
      "Successfully created vectors: 9678/9700\n",
      "Processing batch 98: movies 9701-9800 of 15597\n",
      "Progress: 62.8% - Elapsed: 10.34s - Est. remaining: 599.31s\n",
      "Successfully created vectors: 9778/9800\n",
      "Processing batch 99: movies 9801-9900 of 15597\n",
      "Progress: 63.5% - Elapsed: 10.49s - Est. remaining: 597.34s\n",
      "Successfully created vectors: 9877/9900\n",
      "Processing batch 100: movies 9901-10000 of 15597\n",
      "Progress: 64.1% - Elapsed: 10.59s - Est. remaining: 592.62s\n",
      "Successfully created vectors: 9977/10000\n",
      "Processing batch 101: movies 10001-10100 of 15597\n",
      "Progress: 64.8% - Elapsed: 10.69s - Est. remaining: 587.50s\n",
      "Successfully created vectors: 10077/10100\n",
      "Processing batch 102: movies 10101-10200 of 15597\n",
      "Progress: 65.4% - Elapsed: 10.83s - Est. remaining: 584.72s\n",
      "Successfully created vectors: 10177/10200\n",
      "Processing batch 103: movies 10201-10300 of 15597\n",
      "Progress: 66.0% - Elapsed: 10.98s - Est. remaining: 581.59s\n",
      "Successfully created vectors: 10276/10300\n",
      "Processing batch 104: movies 10301-10400 of 15597\n",
      "Progress: 66.7% - Elapsed: 11.11s - Est. remaining: 577.46s\n",
      "Successfully created vectors: 10376/10400\n",
      "Processing batch 105: movies 10401-10500 of 15597\n",
      "Progress: 67.3% - Elapsed: 11.21s - Est. remaining: 571.61s\n",
      "Successfully created vectors: 10476/10500\n",
      "Processing batch 106: movies 10501-10600 of 15597\n",
      "Progress: 68.0% - Elapsed: 11.31s - Est. remaining: 564.97s\n",
      "Successfully created vectors: 10576/10600\n",
      "Processing batch 107: movies 10601-10700 of 15597\n",
      "Progress: 68.6% - Elapsed: 11.45s - Est. remaining: 560.66s\n",
      "Successfully created vectors: 10676/10700\n",
      "Processing batch 108: movies 10701-10800 of 15597\n",
      "Progress: 69.2% - Elapsed: 11.56s - Est. remaining: 554.38s\n",
      "Successfully created vectors: 10775/10800\n",
      "Processing batch 109: movies 10801-10900 of 15597\n",
      "Progress: 69.9% - Elapsed: 11.67s - Est. remaining: 548.20s\n",
      "Successfully created vectors: 10875/10900\n",
      "Processing batch 110: movies 10901-11000 of 15597\n",
      "Progress: 70.5% - Elapsed: 11.81s - Est. remaining: 543.04s\n",
      "Successfully created vectors: 10975/11000\n",
      "Processing batch 111: movies 11001-11100 of 15597\n",
      "Progress: 71.2% - Elapsed: 11.92s - Est. remaining: 536.17s\n",
      "Successfully created vectors: 11075/11100\n",
      "Processing batch 112: movies 11101-11200 of 15597\n",
      "Progress: 71.8% - Elapsed: 12.03s - Est. remaining: 529.18s\n",
      "Successfully created vectors: 11175/11200\n",
      "Processing batch 113: movies 11201-11300 of 15597\n",
      "Progress: 72.4% - Elapsed: 12.17s - Est. remaining: 523.16s\n",
      "Successfully created vectors: 11275/11300\n",
      "Processing batch 114: movies 11301-11400 of 15597\n",
      "Progress: 73.1% - Elapsed: 12.27s - Est. remaining: 515.11s\n",
      "Successfully created vectors: 11374/11400\n",
      "Processing batch 115: movies 11401-11500 of 15597\n",
      "Progress: 73.7% - Elapsed: 12.39s - Est. remaining: 507.72s\n",
      "Successfully created vectors: 11472/11500\n",
      "Processing batch 116: movies 11501-11600 of 15597\n",
      "Progress: 74.4% - Elapsed: 12.52s - Est. remaining: 500.59s\n",
      "Successfully created vectors: 11572/11600\n",
      "Processing batch 117: movies 11601-11700 of 15597\n",
      "Progress: 75.0% - Elapsed: 12.62s - Est. remaining: 491.92s\n",
      "Successfully created vectors: 11671/11700\n",
      "Processing batch 118: movies 11701-11800 of 15597\n",
      "Progress: 75.7% - Elapsed: 12.73s - Est. remaining: 483.17s\n",
      "Successfully created vectors: 11770/11800\n",
      "Processing batch 119: movies 11801-11900 of 15597\n",
      "Progress: 76.3% - Elapsed: 12.87s - Est. remaining: 475.62s\n",
      "Successfully created vectors: 11869/11900\n",
      "Processing batch 120: movies 11901-12000 of 15597\n",
      "Progress: 76.9% - Elapsed: 12.96s - Est. remaining: 466.31s\n",
      "Successfully created vectors: 11968/12000\n",
      "Processing batch 121: movies 12001-12100 of 15597\n",
      "Progress: 77.6% - Elapsed: 13.06s - Est. remaining: 456.86s\n",
      "Successfully created vectors: 12068/12100\n",
      "Processing batch 122: movies 12101-12200 of 15597\n",
      "Progress: 78.2% - Elapsed: 13.21s - Est. remaining: 448.70s\n",
      "Successfully created vectors: 12168/12200\n",
      "Processing batch 123: movies 12201-12300 of 15597\n",
      "Progress: 78.9% - Elapsed: 13.31s - Est. remaining: 438.70s\n",
      "Successfully created vectors: 12268/12300\n",
      "Processing batch 124: movies 12301-12400 of 15597\n",
      "Progress: 79.5% - Elapsed: 13.39s - Est. remaining: 428.12s\n",
      "Successfully created vectors: 12368/12400\n",
      "Processing batch 125: movies 12401-12500 of 15597\n",
      "Progress: 80.1% - Elapsed: 13.53s - Est. remaining: 419.02s\n",
      "Successfully created vectors: 12466/12500\n",
      "Processing batch 126: movies 12501-12600 of 15597\n",
      "Progress: 80.8% - Elapsed: 13.63s - Est. remaining: 408.43s\n",
      "Successfully created vectors: 12564/12600\n",
      "Processing batch 127: movies 12601-12700 of 15597\n",
      "Progress: 81.4% - Elapsed: 13.72s - Est. remaining: 397.44s\n",
      "Successfully created vectors: 12664/12700\n",
      "Processing batch 128: movies 12701-12800 of 15597\n",
      "Progress: 82.1% - Elapsed: 13.85s - Est. remaining: 387.33s\n",
      "Successfully created vectors: 12764/12800\n",
      "Processing batch 129: movies 12801-12900 of 15597\n",
      "Progress: 82.7% - Elapsed: 13.95s - Est. remaining: 376.26s\n",
      "Successfully created vectors: 12864/12900\n",
      "Processing batch 130: movies 12901-13000 of 15597\n",
      "Progress: 83.3% - Elapsed: 14.05s - Est. remaining: 364.88s\n",
      "Successfully created vectors: 12964/13000\n",
      "Processing batch 131: movies 13001-13100 of 15597\n",
      "Progress: 84.0% - Elapsed: 14.19s - Est. remaining: 354.26s\n",
      "Successfully created vectors: 13064/13100\n",
      "Processing batch 132: movies 13101-13200 of 15597\n",
      "Progress: 84.6% - Elapsed: 14.27s - Est. remaining: 342.16s\n",
      "Successfully created vectors: 13164/13200\n",
      "Processing batch 133: movies 13201-13300 of 15597\n",
      "Progress: 85.3% - Elapsed: 14.37s - Est. remaining: 330.07s\n",
      "Successfully created vectors: 13264/13300\n",
      "Processing batch 134: movies 13301-13400 of 15597\n",
      "Progress: 85.9% - Elapsed: 14.51s - Est. remaining: 318.69s\n",
      "Successfully created vectors: 13364/13400\n",
      "Processing batch 135: movies 13401-13500 of 15597\n",
      "Progress: 86.6% - Elapsed: 14.60s - Est. remaining: 306.26s\n",
      "Successfully created vectors: 13464/13500\n",
      "Processing batch 136: movies 13501-13600 of 15597\n",
      "Progress: 87.2% - Elapsed: 14.68s - Est. remaining: 293.23s\n",
      "Successfully created vectors: 13564/13600\n",
      "Processing batch 137: movies 13601-13700 of 15597\n",
      "Progress: 87.8% - Elapsed: 14.77s - Est. remaining: 280.20s\n",
      "Successfully created vectors: 13664/13700\n",
      "Processing batch 138: movies 13701-13800 of 15597\n",
      "Progress: 88.5% - Elapsed: 14.86s - Est. remaining: 267.01s\n",
      "Successfully created vectors: 13764/13800\n",
      "Processing batch 139: movies 13801-13900 of 15597\n",
      "Progress: 89.1% - Elapsed: 14.93s - Est. remaining: 253.37s\n",
      "Successfully created vectors: 13863/13900\n",
      "Processing batch 140: movies 13901-14000 of 15597\n",
      "Progress: 89.8% - Elapsed: 15.01s - Est. remaining: 239.75s\n",
      "Successfully created vectors: 13962/14000\n",
      "Processing batch 141: movies 14001-14100 of 15597\n",
      "Progress: 90.4% - Elapsed: 15.08s - Est. remaining: 225.75s\n",
      "Successfully created vectors: 14061/14100\n",
      "Processing batch 142: movies 14101-14200 of 15597\n",
      "Progress: 91.0% - Elapsed: 15.17s - Est. remaining: 211.87s\n",
      "Successfully created vectors: 14160/14200\n",
      "Processing batch 143: movies 14201-14300 of 15597\n",
      "Progress: 91.7% - Elapsed: 15.24s - Est. remaining: 197.64s\n",
      "Successfully created vectors: 14259/14300\n",
      "Processing batch 144: movies 14301-14400 of 15597\n",
      "Progress: 92.3% - Elapsed: 15.33s - Est. remaining: 183.52s\n",
      "Successfully created vectors: 14358/14400\n",
      "Processing batch 145: movies 14401-14500 of 15597\n",
      "Progress: 93.0% - Elapsed: 15.42s - Est. remaining: 169.13s\n",
      "Successfully created vectors: 14457/14500\n",
      "Processing batch 146: movies 14501-14600 of 15597\n",
      "Progress: 93.6% - Elapsed: 15.52s - Est. remaining: 154.76s\n",
      "Successfully created vectors: 14557/14600\n",
      "Processing batch 147: movies 14601-14700 of 15597\n",
      "Progress: 94.2% - Elapsed: 15.64s - Est. remaining: 140.30s\n",
      "Successfully created vectors: 14655/14700\n",
      "Processing batch 148: movies 14701-14800 of 15597\n",
      "Progress: 94.9% - Elapsed: 15.71s - Est. remaining: 125.19s\n",
      "Successfully created vectors: 14754/14800\n",
      "Processing batch 149: movies 14801-14900 of 15597\n",
      "Progress: 95.5% - Elapsed: 15.79s - Est. remaining: 110.05s\n",
      "Successfully created vectors: 14854/14900\n",
      "Processing batch 150: movies 14901-15000 of 15597\n",
      "Progress: 96.2% - Elapsed: 15.88s - Est. remaining: 94.80s\n",
      "Successfully created vectors: 14952/15000\n",
      "Processing batch 151: movies 15001-15100 of 15597\n",
      "Progress: 96.8% - Elapsed: 15.96s - Est. remaining: 79.35s\n",
      "Successfully created vectors: 15046/15100\n",
      "Processing batch 152: movies 15101-15200 of 15597\n",
      "Progress: 97.5% - Elapsed: 16.03s - Est. remaining: 63.65s\n",
      "Successfully created vectors: 15145/15200\n",
      "Processing batch 153: movies 15201-15300 of 15597\n",
      "Progress: 98.1% - Elapsed: 16.11s - Est. remaining: 47.84s\n",
      "Successfully created vectors: 15245/15300\n",
      "Processing batch 154: movies 15301-15400 of 15597\n",
      "Progress: 98.7% - Elapsed: 16.19s - Est. remaining: 31.90s\n",
      "Successfully created vectors: 15342/15400\n",
      "Processing batch 155: movies 15401-15500 of 15597\n",
      "Progress: 99.4% - Elapsed: 16.26s - Est. remaining: 15.77s\n",
      "Successfully created vectors: 15441/15500\n",
      "Processing batch 156: movies 15501-15597 of 15597\n",
      "Progress: 100.0% - Elapsed: 16.34s - Est. remaining: 0.00s\n",
      "Successfully created vectors: 15538/15597\n",
      "\n",
      "Vector generation complete:\n",
      "Successfully created vectors: 15538/15597 (99.6%)\n",
      "Movies with no words found: 0\n",
      "Movies with too low LL sum: 59\n",
      "\n",
      "Sample movie vectors:\n",
      "Movie: 'Toy Story (1995)' (ID: 1)\n",
      "Vector shape: (100,)\n",
      "Vector norm: 1.0000\n",
      "First 5 dimensions: [ 0.04217758 -0.03516068  0.13233231 -0.08002583  0.10884047]\n",
      "---\n",
      "Movie: 'Jumanji (1995)' (ID: 2)\n",
      "Vector shape: (100,)\n",
      "Vector norm: 1.0000\n",
      "First 5 dimensions: [-0.03694503  0.00220638  0.13819443  0.04305124 -0.01646295]\n",
      "---\n",
      "Movie: 'Grumpier Old Men (1995)' (ID: 3)\n",
      "Vector shape: (100,)\n",
      "Vector norm: 1.0000\n",
      "First 5 dimensions: [ 0.05916069 -0.03452557  0.18870564 -0.04411813  0.07115461]\n",
      "---\n",
      "Generated and saved feature vectors for 15538 movies\n",
      "\n",
      "Vector statistics:\n",
      "Average vector norm: 1.0000\n",
      "Vector dimensionality: 100\n",
      "\n",
      "================================================================================\n",
      "STEP 6: USER VECTOR GENERATION\n",
      "================================================================================\n",
      "Generating user feature vectors based on movie ratings in batches...\n",
      "Creating user ratings lookup dictionary...\n",
      "Processing 8000 users in batches...\n",
      "Processing batch 1: users 1-100 of 8000\n",
      "Progress: 1.2% - Elapsed: 18.90s - Est. remaining: 1493.29s\n",
      "Successfully created vectors: 100\n",
      "Processing batch 2: users 101-200 of 8000\n",
      "Progress: 2.5% - Elapsed: 19.00s - Est. remaining: 1481.89s\n",
      "Successfully created vectors: 200\n",
      "Processing batch 3: users 201-300 of 8000\n",
      "Progress: 3.8% - Elapsed: 19.08s - Est. remaining: 1469.02s\n",
      "Successfully created vectors: 300\n",
      "Processing batch 4: users 301-400 of 8000\n",
      "Progress: 5.0% - Elapsed: 19.19s - Est. remaining: 1458.31s\n",
      "Successfully created vectors: 400\n",
      "Processing batch 5: users 401-500 of 8000\n",
      "Progress: 6.2% - Elapsed: 19.29s - Est. remaining: 1446.49s\n",
      "Successfully created vectors: 500\n",
      "Processing batch 6: users 501-600 of 8000\n",
      "Progress: 7.5% - Elapsed: 19.37s - Est. remaining: 1433.64s\n",
      "Successfully created vectors: 600\n",
      "Processing batch 7: users 601-700 of 8000\n",
      "Progress: 8.8% - Elapsed: 19.46s - Est. remaining: 1420.78s\n",
      "Successfully created vectors: 700\n",
      "Processing batch 8: users 701-800 of 8000\n",
      "Progress: 10.0% - Elapsed: 19.56s - Est. remaining: 1408.36s\n",
      "Successfully created vectors: 800\n",
      "Processing batch 9: users 801-900 of 8000\n",
      "Progress: 11.2% - Elapsed: 19.65s - Est. remaining: 1395.15s\n",
      "Successfully created vectors: 900\n",
      "Processing batch 10: users 901-1000 of 8000\n",
      "Progress: 12.5% - Elapsed: 19.74s - Est. remaining: 1381.87s\n",
      "Successfully created vectors: 1000\n",
      "Processing batch 11: users 1001-1100 of 8000\n",
      "Progress: 13.8% - Elapsed: 19.83s - Est. remaining: 1367.97s\n",
      "Successfully created vectors: 1100\n",
      "Processing batch 12: users 1101-1200 of 8000\n",
      "Progress: 15.0% - Elapsed: 19.92s - Est. remaining: 1354.71s\n",
      "Successfully created vectors: 1200\n",
      "Processing batch 13: users 1201-1300 of 8000\n",
      "Progress: 16.2% - Elapsed: 20.06s - Est. remaining: 1344.05s\n",
      "Successfully created vectors: 1300\n",
      "Processing batch 14: users 1301-1400 of 8000\n",
      "Progress: 17.5% - Elapsed: 20.14s - Est. remaining: 1329.28s\n",
      "Successfully created vectors: 1400\n",
      "Processing batch 15: users 1401-1500 of 8000\n",
      "Progress: 18.8% - Elapsed: 20.26s - Est. remaining: 1316.59s\n",
      "Successfully created vectors: 1500\n",
      "Processing batch 16: users 1501-1600 of 8000\n",
      "Progress: 20.0% - Elapsed: 20.35s - Est. remaining: 1302.34s\n",
      "Successfully created vectors: 1600\n",
      "Processing batch 17: users 1601-1700 of 8000\n",
      "Progress: 21.2% - Elapsed: 20.46s - Est. remaining: 1288.72s\n",
      "Successfully created vectors: 1700\n",
      "Processing batch 18: users 1701-1800 of 8000\n",
      "Progress: 22.5% - Elapsed: 20.57s - Est. remaining: 1275.39s\n",
      "Successfully created vectors: 1800\n",
      "Processing batch 19: users 1801-1900 of 8000\n",
      "Progress: 23.8% - Elapsed: 20.67s - Est. remaining: 1261.01s\n",
      "Successfully created vectors: 1900\n",
      "Processing batch 20: users 1901-2000 of 8000\n",
      "Progress: 25.0% - Elapsed: 20.76s - Est. remaining: 1245.90s\n",
      "Successfully created vectors: 2000\n",
      "Processing batch 21: users 2001-2100 of 8000\n",
      "Progress: 26.2% - Elapsed: 20.85s - Est. remaining: 1230.43s\n",
      "Successfully created vectors: 2100\n",
      "Processing batch 22: users 2101-2200 of 8000\n",
      "Progress: 27.5% - Elapsed: 20.96s - Est. remaining: 1215.60s\n",
      "Successfully created vectors: 2200\n",
      "Processing batch 23: users 2201-2300 of 8000\n",
      "Progress: 28.7% - Elapsed: 21.07s - Est. remaining: 1200.88s\n",
      "Successfully created vectors: 2300\n",
      "Processing batch 24: users 2301-2400 of 8000\n",
      "Progress: 30.0% - Elapsed: 21.16s - Est. remaining: 1185.06s\n",
      "Successfully created vectors: 2400\n",
      "Processing batch 25: users 2401-2500 of 8000\n",
      "Progress: 31.2% - Elapsed: 21.25s - Est. remaining: 1168.73s\n",
      "Successfully created vectors: 2500\n",
      "Processing batch 26: users 2501-2600 of 8000\n",
      "Progress: 32.5% - Elapsed: 21.35s - Est. remaining: 1152.66s\n",
      "Successfully created vectors: 2600\n",
      "Processing batch 27: users 2601-2700 of 8000\n",
      "Progress: 33.8% - Elapsed: 21.46s - Est. remaining: 1137.25s\n",
      "Successfully created vectors: 2700\n",
      "Processing batch 28: users 2701-2800 of 8000\n",
      "Progress: 35.0% - Elapsed: 21.56s - Est. remaining: 1121.14s\n",
      "Successfully created vectors: 2800\n",
      "Processing batch 29: users 2801-2900 of 8000\n",
      "Progress: 36.2% - Elapsed: 21.67s - Est. remaining: 1104.93s\n",
      "Successfully created vectors: 2900\n",
      "Processing batch 30: users 2901-3000 of 8000\n",
      "Progress: 37.5% - Elapsed: 21.81s - Est. remaining: 1090.27s\n",
      "Successfully created vectors: 3000\n",
      "Processing batch 31: users 3001-3100 of 8000\n",
      "Progress: 38.8% - Elapsed: 21.90s - Est. remaining: 1073.26s\n",
      "Successfully created vectors: 3100\n",
      "Processing batch 32: users 3101-3200 of 8000\n",
      "Progress: 40.0% - Elapsed: 22.00s - Est. remaining: 1055.90s\n",
      "Successfully created vectors: 3200\n",
      "Processing batch 33: users 3201-3300 of 8000\n",
      "Progress: 41.2% - Elapsed: 22.09s - Est. remaining: 1038.40s\n",
      "Successfully created vectors: 3300\n",
      "Processing batch 34: users 3301-3400 of 8000\n",
      "Progress: 42.5% - Elapsed: 22.20s - Est. remaining: 1021.02s\n",
      "Successfully created vectors: 3400\n",
      "Processing batch 35: users 3401-3500 of 8000\n",
      "Progress: 43.8% - Elapsed: 22.29s - Est. remaining: 1003.05s\n",
      "Successfully created vectors: 3500\n",
      "Processing batch 36: users 3501-3600 of 8000\n",
      "Progress: 45.0% - Elapsed: 22.39s - Est. remaining: 985.03s\n",
      "Successfully created vectors: 3600\n",
      "Processing batch 37: users 3601-3700 of 8000\n",
      "Progress: 46.2% - Elapsed: 22.49s - Est. remaining: 966.92s\n",
      "Successfully created vectors: 3700\n",
      "Processing batch 38: users 3701-3800 of 8000\n",
      "Progress: 47.5% - Elapsed: 22.56s - Est. remaining: 947.43s\n",
      "Successfully created vectors: 3800\n",
      "Processing batch 39: users 3801-3900 of 8000\n",
      "Progress: 48.8% - Elapsed: 22.66s - Est. remaining: 929.18s\n",
      "Successfully created vectors: 3900\n",
      "Processing batch 40: users 3901-4000 of 8000\n",
      "Progress: 50.0% - Elapsed: 22.75s - Est. remaining: 910.16s\n",
      "Successfully created vectors: 4000\n",
      "Processing batch 41: users 4001-4100 of 8000\n",
      "Progress: 51.2% - Elapsed: 22.86s - Est. remaining: 891.43s\n",
      "Successfully created vectors: 4100\n",
      "Processing batch 42: users 4101-4200 of 8000\n",
      "Progress: 52.5% - Elapsed: 22.94s - Est. remaining: 871.59s\n",
      "Successfully created vectors: 4200\n",
      "Processing batch 43: users 4201-4300 of 8000\n",
      "Progress: 53.8% - Elapsed: 23.04s - Est. remaining: 852.66s\n",
      "Successfully created vectors: 4300\n",
      "Processing batch 44: users 4301-4400 of 8000\n",
      "Progress: 55.0% - Elapsed: 23.13s - Est. remaining: 832.63s\n",
      "Successfully created vectors: 4400\n",
      "Processing batch 45: users 4401-4500 of 8000\n",
      "Progress: 56.2% - Elapsed: 23.23s - Est. remaining: 812.92s\n",
      "Successfully created vectors: 4500\n",
      "Processing batch 46: users 4501-4600 of 8000\n",
      "Progress: 57.5% - Elapsed: 23.33s - Est. remaining: 793.13s\n",
      "Successfully created vectors: 4600\n",
      "Processing batch 47: users 4601-4700 of 8000\n",
      "Progress: 58.8% - Elapsed: 23.42s - Est. remaining: 772.99s\n",
      "Successfully created vectors: 4700\n",
      "Processing batch 48: users 4701-4800 of 8000\n",
      "Progress: 60.0% - Elapsed: 23.52s - Est. remaining: 752.52s\n",
      "Successfully created vectors: 4800\n",
      "Processing batch 49: users 4801-4900 of 8000\n",
      "Progress: 61.3% - Elapsed: 23.61s - Est. remaining: 732.00s\n",
      "Successfully created vectors: 4900\n",
      "Processing batch 50: users 4901-5000 of 8000\n",
      "Progress: 62.5% - Elapsed: 23.70s - Est. remaining: 711.09s\n",
      "Successfully created vectors: 5000\n",
      "Processing batch 51: users 5001-5100 of 8000\n",
      "Progress: 63.7% - Elapsed: 23.84s - Est. remaining: 691.43s\n",
      "Successfully created vectors: 5100\n",
      "Processing batch 52: users 5101-5200 of 8000\n",
      "Progress: 65.0% - Elapsed: 23.93s - Est. remaining: 669.99s\n",
      "Successfully created vectors: 5200\n",
      "Processing batch 53: users 5201-5300 of 8000\n",
      "Progress: 66.2% - Elapsed: 24.03s - Est. remaining: 648.83s\n",
      "Successfully created vectors: 5300\n",
      "Processing batch 54: users 5301-5400 of 8000\n",
      "Progress: 67.5% - Elapsed: 24.12s - Est. remaining: 627.10s\n",
      "Successfully created vectors: 5400\n",
      "Processing batch 55: users 5401-5500 of 8000\n",
      "Progress: 68.8% - Elapsed: 24.21s - Est. remaining: 605.32s\n",
      "Successfully created vectors: 5500\n",
      "Processing batch 56: users 5501-5600 of 8000\n",
      "Progress: 70.0% - Elapsed: 24.30s - Est. remaining: 583.24s\n",
      "Successfully created vectors: 5600\n",
      "Processing batch 57: users 5601-5700 of 8000\n",
      "Progress: 71.2% - Elapsed: 24.40s - Est. remaining: 561.18s\n",
      "Successfully created vectors: 5700\n",
      "Processing batch 58: users 5701-5800 of 8000\n",
      "Progress: 72.5% - Elapsed: 24.48s - Est. remaining: 538.52s\n",
      "Successfully created vectors: 5800\n",
      "Processing batch 59: users 5801-5900 of 8000\n",
      "Progress: 73.8% - Elapsed: 24.58s - Est. remaining: 516.10s\n",
      "Successfully created vectors: 5900\n",
      "Processing batch 60: users 5901-6000 of 8000\n",
      "Progress: 75.0% - Elapsed: 24.68s - Est. remaining: 493.62s\n",
      "Successfully created vectors: 6000\n",
      "Processing batch 61: users 6001-6100 of 8000\n",
      "Progress: 76.2% - Elapsed: 24.78s - Est. remaining: 470.85s\n",
      "Successfully created vectors: 6100\n",
      "Processing batch 62: users 6101-6200 of 8000\n",
      "Progress: 77.5% - Elapsed: 24.87s - Est. remaining: 447.72s\n",
      "Successfully created vectors: 6200\n",
      "Processing batch 63: users 6201-6300 of 8000\n",
      "Progress: 78.8% - Elapsed: 24.96s - Est. remaining: 424.38s\n",
      "Successfully created vectors: 6300\n",
      "Processing batch 64: users 6301-6400 of 8000\n",
      "Progress: 80.0% - Elapsed: 25.05s - Est. remaining: 400.87s\n",
      "Successfully created vectors: 6400\n",
      "Processing batch 65: users 6401-6500 of 8000\n",
      "Progress: 81.2% - Elapsed: 25.14s - Est. remaining: 377.09s\n",
      "Successfully created vectors: 6500\n",
      "Processing batch 66: users 6501-6600 of 8000\n",
      "Progress: 82.5% - Elapsed: 25.23s - Est. remaining: 353.16s\n",
      "Successfully created vectors: 6600\n",
      "Processing batch 67: users 6601-6700 of 8000\n",
      "Progress: 83.8% - Elapsed: 25.32s - Est. remaining: 329.21s\n",
      "Successfully created vectors: 6700\n",
      "Processing batch 68: users 6701-6800 of 8000\n",
      "Progress: 85.0% - Elapsed: 25.45s - Est. remaining: 305.40s\n",
      "Successfully created vectors: 6800\n",
      "Processing batch 69: users 6801-6900 of 8000\n",
      "Progress: 86.2% - Elapsed: 25.55s - Est. remaining: 281.05s\n",
      "Successfully created vectors: 6900\n",
      "Processing batch 70: users 6901-7000 of 8000\n",
      "Progress: 87.5% - Elapsed: 25.62s - Est. remaining: 256.21s\n",
      "Successfully created vectors: 7000\n",
      "Processing batch 71: users 7001-7100 of 8000\n",
      "Progress: 88.8% - Elapsed: 25.72s - Est. remaining: 231.45s\n",
      "Successfully created vectors: 7100\n",
      "Processing batch 72: users 7101-7200 of 8000\n",
      "Progress: 90.0% - Elapsed: 25.87s - Est. remaining: 206.99s\n",
      "Successfully created vectors: 7200\n",
      "Processing batch 73: users 7201-7300 of 8000\n",
      "Progress: 91.2% - Elapsed: 25.96s - Est. remaining: 181.75s\n",
      "Successfully created vectors: 7299\n",
      "Processing batch 74: users 7301-7400 of 8000\n",
      "Progress: 92.5% - Elapsed: 26.07s - Est. remaining: 156.40s\n",
      "Successfully created vectors: 7399\n",
      "Processing batch 75: users 7401-7500 of 8000\n",
      "Progress: 93.8% - Elapsed: 26.16s - Est. remaining: 130.82s\n",
      "Successfully created vectors: 7499\n",
      "Processing batch 76: users 7501-7600 of 8000\n",
      "Progress: 95.0% - Elapsed: 26.28s - Est. remaining: 105.13s\n",
      "Successfully created vectors: 7599\n",
      "Processing batch 77: users 7601-7700 of 8000\n",
      "Progress: 96.2% - Elapsed: 26.39s - Est. remaining: 79.17s\n",
      "Successfully created vectors: 7699\n",
      "Processing batch 78: users 7701-7800 of 8000\n",
      "Progress: 97.5% - Elapsed: 26.49s - Est. remaining: 52.97s\n",
      "Successfully created vectors: 7799\n",
      "Processing batch 79: users 7801-7900 of 8000\n",
      "Progress: 98.8% - Elapsed: 26.58s - Est. remaining: 26.58s\n",
      "Successfully created vectors: 7899\n",
      "Processing batch 80: users 7901-8000 of 8000\n",
      "Progress: 100.0% - Elapsed: 26.66s - Est. remaining: 0.00s\n",
      "Successfully created vectors: 7999\n",
      "\n",
      "User vector generation complete:\n",
      "Successfully created vectors: 7999/8000 (100.0%)\n",
      "Users with no ratings: 0\n",
      "Users with no vectorized movies: 0\n",
      "Users with too low weight sum: 1\n",
      "\n",
      "Sample user vectors:\n",
      "User ID: 1.0\n",
      "Number of ratings: 4\n",
      "Vector shape: (100,)\n",
      "Vector norm: 1.0000\n",
      "First 5 dimensions: [ 0.0251818   0.04331956  0.16578044  0.03687409 -0.01010823]\n",
      "---\n",
      "User ID: 3.0\n",
      "Number of ratings: 4\n",
      "Vector shape: (100,)\n",
      "Vector norm: 1.0000\n",
      "First 5 dimensions: [ 2.2337167e-02 -1.0045159e-04  1.4259849e-01  1.1076116e-02\n",
      " -1.1802376e-02]\n",
      "---\n",
      "User ID: 4.0\n",
      "Number of ratings: 4\n",
      "Vector shape: (100,)\n",
      "Vector norm: 1.0000\n",
      "First 5 dimensions: [ 0.04520666 -0.00556394  0.15293542  0.01856429  0.01331614]\n",
      "---\n",
      "Generated and saved feature vectors for 7999 users\n",
      "\n",
      "Vector statistics:\n",
      "Average vector norm: 1.0000\n",
      "Vector dimensionality: 100\n",
      "\n",
      "================================================================================\n",
      "STEP 7: USER-MOVIE SIMILARITY CALCULATION\n",
      "================================================================================\n",
      "Calculating user-movie similarity with threshold 0.3 in batches...\n",
      "Processing batch 1: users 1-50 of 7999\n",
      "User 60.0: 15537/15538 movies above threshold (99.99%)\n",
      "Processed 50/7999 users (0.6%) - Elapsed: 1.30s - Est. remaining: 207.26s\n",
      "Processing batch 2: users 51-100 of 7999\n",
      "User 121.0: 15537/15538 movies above threshold (99.99%)\n",
      "Processed 100/7999 users (1.3%) - Elapsed: 2.68s - Est. remaining: 424.16s\n",
      "Processing batch 3: users 101-150 of 7999\n",
      "User 183.0: 15446/15538 movies above threshold (99.41%)\n",
      "Processed 150/7999 users (1.9%) - Elapsed: 4.01s - Est. remaining: 629.78s\n",
      "Processing batch 4: users 151-200 of 7999\n",
      "User 247.0: 15537/15538 movies above threshold (99.99%)\n",
      "Processed 200/7999 users (2.5%) - Elapsed: 5.34s - Est. remaining: 833.59s\n",
      "Processing batch 5: users 201-250 of 7999\n",
      "User 311.0: 0/15538 movies above threshold (0.00%)\n",
      "Processed 250/7999 users (3.1%) - Elapsed: 6.62s - Est. remaining: 1025.31s\n",
      "Processing batch 6: users 251-300 of 7999\n",
      "User 371.0: 15537/15538 movies above threshold (99.99%)\n",
      "Processed 300/7999 users (3.8%) - Elapsed: 7.94s - Est. remaining: 1222.30s\n",
      "Processing batch 7: users 301-350 of 7999\n",
      "User 433.0: 15537/15538 movies above threshold (99.99%)\n",
      "Processed 350/7999 users (4.4%) - Elapsed: 9.23s - Est. remaining: 1411.92s\n",
      "Processing batch 8: users 351-400 of 7999\n",
      "User 490.0: 15537/15538 movies above threshold (99.99%)\n",
      "Processed 400/7999 users (5.0%) - Elapsed: 10.65s - Est. remaining: 1619.18s\n",
      "Processing batch 9: users 401-450 of 7999\n",
      "User 554.0: 15536/15538 movies above threshold (99.99%)\n",
      "Processed 450/7999 users (5.6%) - Elapsed: 12.19s - Est. remaining: 1840.51s\n",
      "Processing batch 10: users 451-500 of 7999\n",
      "User 617.0: 15532/15538 movies above threshold (99.96%)\n",
      "Processed 500/7999 users (6.3%) - Elapsed: 13.64s - Est. remaining: 2045.66s\n",
      "Processing batch 11: users 501-550 of 7999\n",
      "User 681.0: 15527/15538 movies above threshold (99.93%)\n",
      "Processed 550/7999 users (6.9%) - Elapsed: 15.53s - Est. remaining: 2314.19s\n",
      "Processing batch 12: users 551-600 of 7999\n",
      "User 742.0: 15536/15538 movies above threshold (99.99%)\n",
      "Processed 600/7999 users (7.5%) - Elapsed: 17.40s - Est. remaining: 2575.46s\n",
      "Processing batch 13: users 601-650 of 7999\n",
      "User 802.0: 15538/15538 movies above threshold (100.00%)\n",
      "Processed 650/7999 users (8.1%) - Elapsed: 18.89s - Est. remaining: 2776.65s\n",
      "Processing batch 14: users 651-700 of 7999\n",
      "User 869.0: 15526/15538 movies above threshold (99.92%)\n",
      "Processed 700/7999 users (8.8%) - Elapsed: 20.26s - Est. remaining: 2958.00s\n",
      "Processing batch 15: users 701-750 of 7999\n",
      "User 932.0: 15536/15538 movies above threshold (99.99%)\n",
      "Processed 750/7999 users (9.4%) - Elapsed: 21.56s - Est. remaining: 3125.62s\n",
      "Processing batch 16: users 751-800 of 7999\n",
      "User 1003.0: 15535/15538 movies above threshold (99.98%)\n",
      "Processed 800/7999 users (10.0%) - Elapsed: 23.02s - Est. remaining: 3313.77s\n",
      "Processing batch 17: users 801-850 of 7999\n",
      "User 1071.0: 15510/15538 movies above threshold (99.82%)\n",
      "Processed 850/7999 users (10.6%) - Elapsed: 24.57s - Est. remaining: 3512.35s\n",
      "Processing batch 18: users 851-900 of 7999\n",
      "User 1129.0: 15534/15538 movies above threshold (99.97%)\n",
      "Processed 900/7999 users (11.3%) - Elapsed: 26.01s - Est. remaining: 3693.42s\n",
      "Processing batch 19: users 901-950 of 7999\n",
      "User 1189.0: 15520/15538 movies above threshold (99.88%)\n",
      "Processed 950/7999 users (11.9%) - Elapsed: 27.23s - Est. remaining: 3838.90s\n",
      "Processing batch 20: users 951-1000 of 7999\n",
      "User 1251.0: 15538/15538 movies above threshold (100.00%)\n",
      "Processed 1000/7999 users (12.5%) - Elapsed: 28.60s - Est. remaining: 4003.26s\n",
      "Processing batch 21: users 1001-1050 of 7999\n",
      "User 1320.0: 15526/15538 movies above threshold (99.92%)\n",
      "Processed 1050/7999 users (13.1%) - Elapsed: 30.10s - Est. remaining: 4183.81s\n",
      "Processing batch 22: users 1051-1100 of 7999\n",
      "User 1379.0: 15534/15538 movies above threshold (99.97%)\n",
      "Processed 1100/7999 users (13.8%) - Elapsed: 31.66s - Est. remaining: 4368.89s\n",
      "Processing batch 23: users 1101-1150 of 7999\n",
      "User 1438.0: 15536/15538 movies above threshold (99.99%)\n",
      "Processed 1150/7999 users (14.4%) - Elapsed: 33.27s - Est. remaining: 4557.91s\n",
      "Processing batch 24: users 1151-1200 of 7999\n",
      "User 1494.0: 15536/15538 movies above threshold (99.99%)\n",
      "Processed 1200/7999 users (15.0%) - Elapsed: 34.75s - Est. remaining: 4725.35s\n",
      "Processing batch 25: users 1201-1250 of 7999\n",
      "User 1554.0: 15536/15538 movies above threshold (99.99%)\n",
      "Processed 1250/7999 users (15.6%) - Elapsed: 36.35s - Est. remaining: 4906.18s\n",
      "Processing batch 26: users 1251-1300 of 7999\n",
      "User 1614.0: 15537/15538 movies above threshold (99.99%)\n",
      "Processed 1300/7999 users (16.3%) - Elapsed: 38.01s - Est. remaining: 5093.24s\n",
      "Processing batch 27: users 1301-1350 of 7999\n",
      "User 1677.0: 0/15538 movies above threshold (0.00%)\n",
      "Processed 1350/7999 users (16.9%) - Elapsed: 39.70s - Est. remaining: 5278.88s\n",
      "Processing batch 28: users 1351-1400 of 7999\n",
      "User 1744.0: 15537/15538 movies above threshold (99.99%)\n",
      "Processed 1400/7999 users (17.5%) - Elapsed: 41.00s - Est. remaining: 5410.87s\n",
      "Processing batch 29: users 1401-1450 of 7999\n",
      "User 1807.0: 15538/15538 movies above threshold (100.00%)\n",
      "Processed 1450/7999 users (18.1%) - Elapsed: 42.25s - Est. remaining: 5534.15s\n",
      "Processing batch 30: users 1451-1500 of 7999\n",
      "User 1870.0: 15536/15538 movies above threshold (99.99%)\n",
      "Processed 1500/7999 users (18.8%) - Elapsed: 43.47s - Est. remaining: 5650.79s\n",
      "Processing batch 31: users 1501-1550 of 7999\n",
      "User 1933.0: 15533/15538 movies above threshold (99.97%)\n",
      "Processed 1550/7999 users (19.4%) - Elapsed: 44.72s - Est. remaining: 5768.24s\n",
      "Processing batch 32: users 1551-1600 of 7999\n",
      "User 2000.0: 15528/15538 movies above threshold (99.94%)\n",
      "Processed 1600/7999 users (20.0%) - Elapsed: 46.08s - Est. remaining: 5896.80s\n",
      "Processing batch 33: users 1601-1650 of 7999\n",
      "User 2064.0: 15536/15538 movies above threshold (99.99%)\n",
      "Processed 1650/7999 users (20.6%) - Elapsed: 47.37s - Est. remaining: 6015.18s\n",
      "Processing batch 34: users 1651-1700 of 7999\n",
      "User 2127.0: 15537/15538 movies above threshold (99.99%)\n",
      "Processed 1700/7999 users (21.3%) - Elapsed: 48.65s - Est. remaining: 6129.07s\n",
      "Processing batch 35: users 1701-1750 of 7999\n",
      "User 2186.0: 15529/15538 movies above threshold (99.94%)\n",
      "Processed 1750/7999 users (21.9%) - Elapsed: 49.95s - Est. remaining: 6243.37s\n",
      "Processing batch 36: users 1751-1800 of 7999\n",
      "User 2246.0: 15538/15538 movies above threshold (100.00%)\n",
      "Processed 1800/7999 users (22.5%) - Elapsed: 51.27s - Est. remaining: 6355.98s\n",
      "Processing batch 37: users 1801-1850 of 7999\n",
      "User 2300.0: 15507/15538 movies above threshold (99.80%)\n",
      "Processed 1850/7999 users (23.1%) - Elapsed: 52.52s - Est. remaining: 6458.83s\n",
      "Processing batch 38: users 1851-1900 of 7999\n",
      "User 2356.0: 15537/15538 movies above threshold (99.99%)\n",
      "Processed 1900/7999 users (23.8%) - Elapsed: 53.81s - Est. remaining: 6563.99s\n",
      "Processing batch 39: users 1901-1950 of 7999\n",
      "User 2418.0: 15538/15538 movies above threshold (100.00%)\n",
      "Processed 1950/7999 users (24.4%) - Elapsed: 55.06s - Est. remaining: 6661.00s\n",
      "Processing batch 40: users 1951-2000 of 7999\n",
      "User 2481.0: 15535/15538 movies above threshold (99.98%)\n",
      "Processed 2000/7999 users (25.0%) - Elapsed: 56.32s - Est. remaining: 6757.77s\n",
      "Processing batch 41: users 2001-2050 of 7999\n",
      "User 2546.0: 0/15538 movies above threshold (0.00%)\n",
      "Processed 2050/7999 users (25.6%) - Elapsed: 57.56s - Est. remaining: 6848.45s\n",
      "Processing batch 42: users 2051-2100 of 7999\n",
      "User 2608.0: 15535/15538 movies above threshold (99.98%)\n",
      "Processed 2100/7999 users (26.3%) - Elapsed: 58.80s - Est. remaining: 6937.53s\n",
      "Processing batch 43: users 2101-2150 of 7999\n",
      "User 2662.0: 15537/15538 movies above threshold (99.99%)\n",
      "Processed 2150/7999 users (26.9%) - Elapsed: 60.06s - Est. remaining: 7025.56s\n",
      "Processing batch 44: users 2151-2200 of 7999\n",
      "User 2729.0: 15538/15538 movies above threshold (100.00%)\n",
      "Processed 2200/7999 users (27.5%) - Elapsed: 61.32s - Est. remaining: 7111.39s\n",
      "Processing batch 45: users 2201-2250 of 7999\n",
      "User 2797.0: 2947/15538 movies above threshold (18.97%)\n",
      "Processed 2250/7999 users (28.1%) - Elapsed: 62.58s - Est. remaining: 7195.56s\n",
      "Processing batch 46: users 2251-2300 of 7999\n",
      "User 2861.0: 15536/15538 movies above threshold (99.99%)\n",
      "Processed 2300/7999 users (28.8%) - Elapsed: 63.84s - Est. remaining: 7276.13s\n",
      "Processing batch 47: users 2301-2350 of 7999\n",
      "User 2925.0: 15534/15538 movies above threshold (99.97%)\n",
      "Processed 2350/7999 users (29.4%) - Elapsed: 65.11s - Est. remaining: 7356.18s\n",
      "Processing batch 48: users 2351-2400 of 7999\n",
      "User 2988.0: 15537/15538 movies above threshold (99.99%)\n",
      "Processed 2400/7999 users (30.0%) - Elapsed: 66.40s - Est. remaining: 7435.91s\n",
      "Processing batch 49: users 2401-2450 of 7999\n",
      "User 3049.0: 15536/15538 movies above threshold (99.99%)\n",
      "Processed 2450/7999 users (30.6%) - Elapsed: 67.64s - Est. remaining: 7507.00s\n",
      "Processing batch 50: users 2451-2500 of 7999\n",
      "User 3113.0: 749/15538 movies above threshold (4.82%)\n",
      "Processed 2500/7999 users (31.3%) - Elapsed: 68.94s - Est. remaining: 7582.07s\n",
      "Processing batch 51: users 2501-2550 of 7999\n",
      "User 3173.0: 15527/15538 movies above threshold (99.93%)\n",
      "Processed 2550/7999 users (31.9%) - Elapsed: 70.24s - Est. remaining: 7654.41s\n",
      "Processing batch 52: users 2551-2600 of 7999\n",
      "User 3238.0: 15532/15538 movies above threshold (99.96%)\n",
      "Processed 2600/7999 users (32.5%) - Elapsed: 71.47s - Est. remaining: 7717.38s\n",
      "Processing batch 53: users 2601-2650 of 7999\n",
      "User 3298.0: 0/15538 movies above threshold (0.00%)\n",
      "Processed 2650/7999 users (33.1%) - Elapsed: 72.75s - Est. remaining: 7782.98s\n",
      "Processing batch 54: users 2651-2700 of 7999\n",
      "User 3360.0: 15536/15538 movies above threshold (99.99%)\n",
      "Processed 2700/7999 users (33.8%) - Elapsed: 74.03s - Est. remaining: 7845.57s\n",
      "Processing batch 55: users 2701-2750 of 7999\n",
      "User 3422.0: 15525/15538 movies above threshold (99.92%)\n",
      "Processed 2750/7999 users (34.4%) - Elapsed: 75.30s - Est. remaining: 7905.46s\n",
      "Processing batch 56: users 2751-2800 of 7999\n",
      "User 3486.0: 15529/15538 movies above threshold (99.94%)\n",
      "Processed 2800/7999 users (35.0%) - Elapsed: 76.58s - Est. remaining: 7962.92s\n",
      "Processing batch 57: users 2801-2850 of 7999\n",
      "User 3546.0: 0/15538 movies above threshold (0.00%)\n",
      "Processed 2850/7999 users (35.6%) - Elapsed: 77.81s - Est. remaining: 8013.06s\n",
      "Processing batch 58: users 2851-2900 of 7999\n",
      "User 3614.0: 15537/15538 movies above threshold (99.99%)\n",
      "Processed 2900/7999 users (36.3%) - Elapsed: 79.09s - Est. remaining: 8065.87s\n",
      "Processing batch 59: users 2901-2950 of 7999\n",
      "User 3674.0: 15537/15538 movies above threshold (99.99%)\n",
      "Processed 2950/7999 users (36.9%) - Elapsed: 80.38s - Est. remaining: 8116.28s\n",
      "Processing batch 60: users 2951-3000 of 7999\n",
      "User 3743.0: 0/15538 movies above threshold (0.00%)\n",
      "Processed 3000/7999 users (37.5%) - Elapsed: 81.60s - Est. remaining: 8158.84s\n",
      "Processing batch 61: users 3001-3050 of 7999\n",
      "User 3805.0: 15531/15538 movies above threshold (99.95%)\n",
      "Processed 3050/7999 users (38.1%) - Elapsed: 82.86s - Est. remaining: 8201.16s\n",
      "Processing batch 62: users 3051-3100 of 7999\n",
      "User 3866.0: 5545/15538 movies above threshold (35.69%)\n",
      "Processed 3100/7999 users (38.8%) - Elapsed: 84.16s - Est. remaining: 8245.70s\n",
      "Processing batch 63: users 3101-3150 of 7999\n",
      "User 3923.0: 15535/15538 movies above threshold (99.98%)\n",
      "Processed 3150/7999 users (39.4%) - Elapsed: 85.44s - Est. remaining: 8286.00s\n",
      "Processing batch 64: users 3151-3200 of 7999\n",
      "User 3980.0: 15526/15538 movies above threshold (99.92%)\n",
      "Processed 3200/7999 users (40.0%) - Elapsed: 86.68s - Est. remaining: 8319.51s\n",
      "Processing batch 65: users 3201-3250 of 7999\n",
      "User 4040.0: 15538/15538 movies above threshold (100.00%)\n",
      "Processed 3250/7999 users (40.6%) - Elapsed: 87.92s - Est. remaining: 8351.01s\n",
      "Processing batch 66: users 3251-3300 of 7999\n",
      "User 4095.0: 15537/15538 movies above threshold (99.99%)\n",
      "Processed 3300/7999 users (41.3%) - Elapsed: 89.24s - Est. remaining: 8386.42s\n",
      "Processing batch 67: users 3301-3350 of 7999\n",
      "User 4157.0: 15535/15538 movies above threshold (99.98%)\n",
      "Processed 3350/7999 users (41.9%) - Elapsed: 90.48s - Est. remaining: 8412.69s\n",
      "Processing batch 68: users 3351-3400 of 7999\n",
      "User 4229.0: 0/15538 movies above threshold (0.00%)\n",
      "Processed 3400/7999 users (42.5%) - Elapsed: 91.79s - Est. remaining: 8442.45s\n",
      "Processing batch 69: users 3401-3450 of 7999\n",
      "User 4296.0: 15538/15538 movies above threshold (100.00%)\n",
      "Processed 3450/7999 users (43.1%) - Elapsed: 93.05s - Est. remaining: 8466.12s\n",
      "Processing batch 70: users 3451-3500 of 7999\n",
      "User 4354.0: 15531/15538 movies above threshold (99.95%)\n",
      "Processed 3500/7999 users (43.8%) - Elapsed: 94.32s - Est. remaining: 8486.74s\n",
      "Processing batch 71: users 3501-3550 of 7999\n",
      "User 4415.0: 15536/15538 movies above threshold (99.99%)\n",
      "Processed 3550/7999 users (44.4%) - Elapsed: 95.59s - Est. remaining: 8505.89s\n",
      "Processing batch 72: users 3551-3600 of 7999\n",
      "User 4483.0: 15537/15538 movies above threshold (99.99%)\n",
      "Processed 3600/7999 users (45.0%) - Elapsed: 96.85s - Est. remaining: 8520.50s\n",
      "Processing batch 73: users 3601-3650 of 7999\n",
      "User 4547.0: 15529/15538 movies above threshold (99.94%)\n",
      "Processed 3650/7999 users (45.6%) - Elapsed: 98.11s - Est. remaining: 8533.89s\n",
      "Processing batch 74: users 3651-3700 of 7999\n",
      "User 4606.0: 15538/15538 movies above threshold (100.00%)\n",
      "Processed 3700/7999 users (46.3%) - Elapsed: 99.40s - Est. remaining: 8546.40s\n",
      "Processing batch 75: users 3701-3750 of 7999\n",
      "User 4668.0: 15532/15538 movies above threshold (99.96%)\n",
      "Processed 3750/7999 users (46.9%) - Elapsed: 100.65s - Est. remaining: 8553.66s\n",
      "Processing batch 76: users 3751-3800 of 7999\n",
      "User 4723.0: 15537/15538 movies above threshold (99.99%)\n",
      "Processed 3800/7999 users (47.5%) - Elapsed: 102.22s - Est. remaining: 8584.15s\n",
      "Processing batch 77: users 3801-3850 of 7999\n",
      "User 4786.0: 15533/15538 movies above threshold (99.97%)\n",
      "Processed 3850/7999 users (48.1%) - Elapsed: 103.56s - Est. remaining: 8593.35s\n",
      "Processing batch 78: users 3851-3900 of 7999\n",
      "User 4852.0: 15529/15538 movies above threshold (99.94%)\n",
      "Processed 3900/7999 users (48.8%) - Elapsed: 104.87s - Est. remaining: 8597.29s\n",
      "Processing batch 79: users 3901-3950 of 7999\n",
      "User 4919.0: 15534/15538 movies above threshold (99.97%)\n",
      "Processed 3950/7999 users (49.4%) - Elapsed: 106.18s - Est. remaining: 8598.49s\n",
      "Processing batch 80: users 3951-4000 of 7999\n",
      "User 4979.0: 15537/15538 movies above threshold (99.99%)\n",
      "Processed 4000/7999 users (50.0%) - Elapsed: 107.49s - Est. remaining: 8597.39s\n",
      "Processing batch 81: users 4001-4050 of 7999\n",
      "User 5035.0: 15538/15538 movies above threshold (100.00%)\n",
      "Processed 4050/7999 users (50.6%) - Elapsed: 108.79s - Est. remaining: 8592.15s\n",
      "Processing batch 82: users 4051-4100 of 7999\n",
      "User 5098.0: 15536/15538 movies above threshold (99.99%)\n",
      "Processed 4100/7999 users (51.3%) - Elapsed: 110.13s - Est. remaining: 8587.61s\n",
      "Processing batch 83: users 4101-4150 of 7999\n",
      "User 5161.0: 15536/15538 movies above threshold (99.99%)\n",
      "Processed 4150/7999 users (51.9%) - Elapsed: 111.43s - Est. remaining: 8578.10s\n",
      "Processing batch 84: users 4151-4200 of 7999\n",
      "User 5226.0: 15537/15538 movies above threshold (99.99%)\n",
      "Processed 4200/7999 users (52.5%) - Elapsed: 112.74s - Est. remaining: 8565.80s\n",
      "Processing batch 85: users 4201-4250 of 7999\n",
      "User 5289.0: 15538/15538 movies above threshold (100.00%)\n",
      "Processed 4250/7999 users (53.1%) - Elapsed: 114.05s - Est. remaining: 8551.58s\n",
      "Processing batch 86: users 4251-4300 of 7999\n",
      "User 5355.0: 15537/15538 movies above threshold (99.99%)\n",
      "Processed 4300/7999 users (53.8%) - Elapsed: 115.37s - Est. remaining: 8535.10s\n",
      "Processing batch 87: users 4301-4350 of 7999\n",
      "User 5417.0: 15531/15538 movies above threshold (99.95%)\n",
      "Processed 4350/7999 users (54.4%) - Elapsed: 116.67s - Est. remaining: 8514.77s\n",
      "Processing batch 88: users 4351-4400 of 7999\n",
      "User 5480.0: 15517/15538 movies above threshold (99.86%)\n",
      "Processed 4400/7999 users (55.0%) - Elapsed: 118.02s - Est. remaining: 8494.89s\n",
      "Processing batch 89: users 4401-4450 of 7999\n",
      "User 5539.0: 15415/15538 movies above threshold (99.21%)\n",
      "Processed 4450/7999 users (55.6%) - Elapsed: 119.36s - Est. remaining: 8472.30s\n",
      "Processing batch 90: users 4451-4500 of 7999\n",
      "User 5606.0: 15536/15538 movies above threshold (99.99%)\n",
      "Processed 4500/7999 users (56.3%) - Elapsed: 120.72s - Est. remaining: 8447.67s\n",
      "Processing batch 91: users 4501-4550 of 7999\n",
      "User 5668.0: 15531/15538 movies above threshold (99.95%)\n",
      "Processed 4550/7999 users (56.9%) - Elapsed: 122.06s - Est. remaining: 8419.54s\n",
      "Processing batch 92: users 4551-4600 of 7999\n",
      "User 5724.0: 15530/15538 movies above threshold (99.95%)\n",
      "Processed 4600/7999 users (57.5%) - Elapsed: 123.37s - Est. remaining: 8386.67s\n",
      "Processing batch 93: users 4601-4650 of 7999\n",
      "User 5794.0: 11257/15538 movies above threshold (72.45%)\n",
      "Processed 4650/7999 users (58.1%) - Elapsed: 124.72s - Est. remaining: 8353.97s\n",
      "Processing batch 94: users 4651-4700 of 7999\n",
      "User 5848.0: 15536/15538 movies above threshold (99.99%)\n",
      "Processed 4700/7999 users (58.8%) - Elapsed: 126.14s - Est. remaining: 8322.73s\n",
      "Processing batch 95: users 4701-4750 of 7999\n",
      "User 5910.0: 15524/15538 movies above threshold (99.91%)\n",
      "Processed 4750/7999 users (59.4%) - Elapsed: 127.49s - Est. remaining: 8284.08s\n",
      "Processing batch 96: users 4751-4800 of 7999\n",
      "User 5973.0: 15535/15538 movies above threshold (99.98%)\n",
      "Processed 4800/7999 users (60.0%) - Elapsed: 128.80s - Est. remaining: 8240.45s\n",
      "Processing batch 97: users 4801-4850 of 7999\n",
      "User 6040.0: 15536/15538 movies above threshold (99.99%)\n",
      "Processed 4850/7999 users (60.6%) - Elapsed: 130.16s - Est. remaining: 8197.49s\n",
      "Processing batch 98: users 4851-4900 of 7999\n",
      "User 6101.0: 15528/15538 movies above threshold (99.94%)\n",
      "Processed 4900/7999 users (61.3%) - Elapsed: 131.53s - Est. remaining: 8152.39s\n",
      "Processing batch 99: users 4901-4950 of 7999\n",
      "User 6159.0: 15382/15538 movies above threshold (99.00%)\n",
      "Processed 4950/7999 users (61.9%) - Elapsed: 132.97s - Est. remaining: 8108.31s\n",
      "Processing batch 100: users 4951-5000 of 7999\n",
      "User 6218.0: 15537/15538 movies above threshold (99.99%)\n",
      "Processed 5000/7999 users (62.5%) - Elapsed: 134.31s - Est. remaining: 8056.01s\n",
      "Processing batch 101: users 5001-5050 of 7999\n",
      "User 6282.0: 15536/15538 movies above threshold (99.99%)\n",
      "Processed 5050/7999 users (63.1%) - Elapsed: 135.62s - Est. remaining: 7998.65s\n",
      "Processing batch 102: users 5051-5100 of 7999\n",
      "User 6347.0: 15518/15538 movies above threshold (99.87%)\n",
      "Processed 5100/7999 users (63.8%) - Elapsed: 136.91s - Est. remaining: 7938.27s\n",
      "Processing batch 103: users 5101-5150 of 7999\n",
      "User 6405.0: 8892/15538 movies above threshold (57.23%)\n",
      "Processed 5150/7999 users (64.4%) - Elapsed: 138.26s - Est. remaining: 7878.11s\n",
      "Processing batch 104: users 5151-5200 of 7999\n",
      "User 6464.0: 15538/15538 movies above threshold (100.00%)\n",
      "Processed 5200/7999 users (65.0%) - Elapsed: 139.63s - Est. remaining: 7816.21s\n",
      "Processing batch 105: users 5201-5250 of 7999\n",
      "User 6527.0: 43/15538 movies above threshold (0.28%)\n",
      "Processed 5250/7999 users (65.6%) - Elapsed: 140.96s - Est. remaining: 7750.01s\n",
      "Processing batch 106: users 5251-5300 of 7999\n",
      "User 6592.0: 15506/15538 movies above threshold (99.79%)\n",
      "Processed 5300/7999 users (66.3%) - Elapsed: 142.28s - Est. remaining: 7680.07s\n",
      "Processing batch 107: users 5301-5350 of 7999\n",
      "User 6659.0: 0/15538 movies above threshold (0.00%)\n",
      "Processed 5350/7999 users (66.9%) - Elapsed: 143.58s - Est. remaining: 7606.91s\n",
      "Processing batch 108: users 5351-5400 of 7999\n",
      "User 6718.0: 15533/15538 movies above threshold (99.97%)\n",
      "Processed 5400/7999 users (67.5%) - Elapsed: 144.93s - Est. remaining: 7533.71s\n",
      "Processing batch 109: users 5401-5450 of 7999\n",
      "User 6783.0: 15525/15538 movies above threshold (99.92%)\n",
      "Processed 5450/7999 users (68.1%) - Elapsed: 146.27s - Est. remaining: 7456.60s\n",
      "Processing batch 110: users 5451-5500 of 7999\n",
      "User 6844.0: 15522/15538 movies above threshold (99.90%)\n",
      "Processed 5500/7999 users (68.8%) - Elapsed: 147.59s - Est. remaining: 7376.31s\n",
      "Processing batch 111: users 5501-5550 of 7999\n",
      "User 6908.0: 15532/15538 movies above threshold (99.96%)\n",
      "Processed 5550/7999 users (69.4%) - Elapsed: 148.92s - Est. remaining: 7294.21s\n",
      "Processing batch 112: users 5551-5600 of 7999\n",
      "User 6974.0: 15538/15538 movies above threshold (100.00%)\n",
      "Processed 5600/7999 users (70.0%) - Elapsed: 150.17s - Est. remaining: 7204.97s\n",
      "Processing batch 113: users 5601-5650 of 7999\n",
      "User 7043.0: 0/15538 movies above threshold (0.00%)\n",
      "Processed 5650/7999 users (70.6%) - Elapsed: 151.45s - Est. remaining: 7115.21s\n",
      "Processing batch 114: users 5651-5700 of 7999\n",
      "User 7107.0: 15537/15538 movies above threshold (99.99%)\n",
      "Processed 5700/7999 users (71.3%) - Elapsed: 152.75s - Est. remaining: 7023.66s\n",
      "Processing batch 115: users 5701-5750 of 7999\n",
      "User 7178.0: 15537/15538 movies above threshold (99.99%)\n",
      "Processed 5750/7999 users (71.9%) - Elapsed: 154.22s - Est. remaining: 6936.79s\n",
      "Processing batch 116: users 5751-5800 of 7999\n",
      "User 7245.0: 15536/15538 movies above threshold (99.99%)\n",
      "Processed 5800/7999 users (72.5%) - Elapsed: 155.56s - Est. remaining: 6841.55s\n",
      "Processing batch 117: users 5801-5850 of 7999\n",
      "User 7310.0: 0/15538 movies above threshold (0.00%)\n",
      "Processed 5850/7999 users (73.1%) - Elapsed: 156.82s - Est. remaining: 6740.28s\n",
      "Processing batch 118: users 5851-5900 of 7999\n",
      "User 7373.0: 15528/15538 movies above threshold (99.94%)\n",
      "Processed 5900/7999 users (73.8%) - Elapsed: 158.07s - Est. remaining: 6635.80s\n",
      "Processing batch 119: users 5901-5950 of 7999\n",
      "User 7439.0: 15536/15538 movies above threshold (99.99%)\n",
      "Processed 5950/7999 users (74.4%) - Elapsed: 159.39s - Est. remaining: 6531.75s\n",
      "Processing batch 120: users 5951-6000 of 7999\n",
      "User 7500.0: 15537/15538 movies above threshold (99.99%)\n",
      "Processed 6000/7999 users (75.0%) - Elapsed: 160.69s - Est. remaining: 6424.35s\n",
      "Processing batch 121: users 6001-6050 of 7999\n",
      "User 7559.0: 15536/15538 movies above threshold (99.99%)\n",
      "Processed 6050/7999 users (75.6%) - Elapsed: 162.00s - Est. remaining: 6314.59s\n",
      "Processing batch 122: users 6051-6100 of 7999\n",
      "User 7622.0: 15538/15538 movies above threshold (100.00%)\n",
      "Processed 6100/7999 users (76.3%) - Elapsed: 163.28s - Est. remaining: 6201.20s\n",
      "Processing batch 123: users 6101-6150 of 7999\n",
      "User 7689.0: 15537/15538 movies above threshold (99.99%)\n",
      "Processed 6150/7999 users (76.9%) - Elapsed: 164.56s - Est. remaining: 6085.59s\n",
      "Processing batch 124: users 6151-6200 of 7999\n",
      "User 7751.0: 15537/15538 movies above threshold (99.99%)\n",
      "Processed 6200/7999 users (77.5%) - Elapsed: 165.85s - Est. remaining: 5967.15s\n",
      "Processing batch 125: users 6201-6250 of 7999\n",
      "User 7810.0: 15534/15538 movies above threshold (99.97%)\n",
      "Processed 6250/7999 users (78.1%) - Elapsed: 167.15s - Est. remaining: 5846.79s\n",
      "Processing batch 126: users 6251-6300 of 7999\n",
      "User 7874.0: 15534/15538 movies above threshold (99.97%)\n",
      "Processed 6300/7999 users (78.8%) - Elapsed: 168.46s - Est. remaining: 5724.33s\n",
      "Processing batch 127: users 6301-6350 of 7999\n",
      "User 7931.0: 15537/15538 movies above threshold (99.99%)\n",
      "Processed 6350/7999 users (79.4%) - Elapsed: 169.76s - Est. remaining: 5598.77s\n",
      "Processing batch 128: users 6351-6400 of 7999\n",
      "User 7999.0: 15538/15538 movies above threshold (100.00%)\n",
      "Processed 6400/7999 users (80.0%) - Elapsed: 171.05s - Est. remaining: 5470.20s\n",
      "Processing batch 129: users 6401-6450 of 7999\n",
      "User 8063.0: 15538/15538 movies above threshold (100.00%)\n",
      "Processed 6450/7999 users (80.6%) - Elapsed: 172.43s - Est. remaining: 5341.96s\n",
      "Processing batch 130: users 6451-6500 of 7999\n",
      "User 8120.0: 8/15538 movies above threshold (0.05%)\n",
      "Processed 6500/7999 users (81.3%) - Elapsed: 173.73s - Est. remaining: 5208.43s\n",
      "Processing batch 131: users 6501-6550 of 7999\n",
      "User 8185.0: 15535/15538 movies above threshold (99.98%)\n",
      "Processed 6550/7999 users (81.9%) - Elapsed: 175.00s - Est. remaining: 5071.55s\n",
      "Processing batch 132: users 6551-6600 of 7999\n",
      "User 8256.0: 15527/15538 movies above threshold (99.93%)\n",
      "Processed 6600/7999 users (82.5%) - Elapsed: 176.29s - Est. remaining: 4932.56s\n",
      "Processing batch 133: users 6601-6650 of 7999\n",
      "User 8314.0: 15529/15538 movies above threshold (99.94%)\n",
      "Processed 6650/7999 users (83.1%) - Elapsed: 177.59s - Est. remaining: 4791.31s\n",
      "Processing batch 134: users 6651-6700 of 7999\n",
      "User 8376.0: 15520/15538 movies above threshold (99.88%)\n",
      "Processed 6700/7999 users (83.8%) - Elapsed: 178.85s - Est. remaining: 4646.51s\n",
      "Processing batch 135: users 6701-6750 of 7999\n",
      "User 8444.0: 13659/15538 movies above threshold (87.91%)\n",
      "Processed 6750/7999 users (84.4%) - Elapsed: 180.13s - Est. remaining: 4499.57s\n",
      "Processing batch 136: users 6751-6800 of 7999\n",
      "User 8505.0: 15536/15538 movies above threshold (99.99%)\n",
      "Processed 6800/7999 users (85.0%) - Elapsed: 181.40s - Est. remaining: 4349.88s\n",
      "Processing batch 137: users 6801-6850 of 7999\n",
      "User 8567.0: 15533/15538 movies above threshold (99.97%)\n",
      "Processed 6850/7999 users (85.6%) - Elapsed: 182.70s - Est. remaining: 4198.52s\n",
      "Processing batch 138: users 6851-6900 of 7999\n",
      "User 8629.0: 15536/15538 movies above threshold (99.99%)\n",
      "Processed 6900/7999 users (86.3%) - Elapsed: 184.00s - Est. remaining: 4044.32s\n",
      "Processing batch 139: users 6901-6950 of 7999\n",
      "User 8693.0: 15537/15538 movies above threshold (99.99%)\n",
      "Processed 6950/7999 users (86.9%) - Elapsed: 185.41s - Est. remaining: 3889.98s\n",
      "Processing batch 140: users 6951-7000 of 7999\n",
      "User 8752.0: 15536/15538 movies above threshold (99.99%)\n",
      "Processed 7000/7999 users (87.5%) - Elapsed: 186.75s - Est. remaining: 3731.32s\n",
      "Processing batch 141: users 7001-7050 of 7999\n",
      "User 8815.0: 15522/15538 movies above threshold (99.90%)\n",
      "Processed 7050/7999 users (88.1%) - Elapsed: 188.02s - Est. remaining: 3568.66s\n",
      "Processing batch 142: users 7051-7100 of 7999\n",
      "User 8876.0: 15510/15538 movies above threshold (99.82%)\n",
      "Processed 7100/7999 users (88.8%) - Elapsed: 189.29s - Est. remaining: 3403.47s\n",
      "Processing batch 143: users 7101-7150 of 7999\n",
      "User 8938.0: 15536/15538 movies above threshold (99.99%)\n",
      "Processed 7150/7999 users (89.4%) - Elapsed: 190.59s - Est. remaining: 3236.26s\n",
      "Processing batch 144: users 7151-7200 of 7999\n",
      "User 9000.0: 15534/15538 movies above threshold (99.97%)\n",
      "Processed 7200/7999 users (90.0%) - Elapsed: 191.93s - Est. remaining: 3067.01s\n",
      "Processing batch 145: users 7201-7250 of 7999\n",
      "User 9064.0: 15344/15538 movies above threshold (98.75%)\n",
      "Processed 7250/7999 users (90.6%) - Elapsed: 193.22s - Est. remaining: 2894.41s\n",
      "Processing batch 146: users 7251-7300 of 7999\n",
      "User 9129.0: 15509/15538 movies above threshold (99.81%)\n",
      "Processed 7300/7999 users (91.3%) - Elapsed: 194.55s - Est. remaining: 2719.75s\n",
      "Processing batch 147: users 7301-7350 of 7999\n",
      "User 9187.0: 15532/15538 movies above threshold (99.96%)\n",
      "Processed 7350/7999 users (91.9%) - Elapsed: 195.78s - Est. remaining: 2541.21s\n",
      "Processing batch 148: users 7351-7400 of 7999\n",
      "User 9248.0: 15532/15538 movies above threshold (99.96%)\n",
      "Processed 7400/7999 users (92.5%) - Elapsed: 197.04s - Est. remaining: 2360.54s\n",
      "Processing batch 149: users 7401-7450 of 7999\n",
      "User 9314.0: 15533/15538 movies above threshold (99.97%)\n",
      "Processed 7450/7999 users (93.1%) - Elapsed: 198.32s - Est. remaining: 2177.55s\n",
      "Processing batch 150: users 7451-7500 of 7999\n",
      "User 9374.0: 15134/15538 movies above threshold (97.40%)\n",
      "Processed 7500/7999 users (93.8%) - Elapsed: 199.59s - Est. remaining: 1991.87s\n",
      "Processing batch 151: users 7501-7550 of 7999\n",
      "User 9437.0: 15538/15538 movies above threshold (100.00%)\n",
      "Processed 7550/7999 users (94.4%) - Elapsed: 200.89s - Est. remaining: 1803.99s\n",
      "Processing batch 152: users 7551-7600 of 7999\n",
      "User 9503.0: 0/15538 movies above threshold (0.00%)\n",
      "Processed 7600/7999 users (95.0%) - Elapsed: 202.18s - Est. remaining: 1613.36s\n",
      "Processing batch 153: users 7601-7650 of 7999\n",
      "User 9565.0: 15531/15538 movies above threshold (99.95%)\n",
      "Processed 7650/7999 users (95.6%) - Elapsed: 203.40s - Est. remaining: 1419.77s\n",
      "Processing batch 154: users 7651-7700 of 7999\n",
      "User 9621.0: 15534/15538 movies above threshold (99.97%)\n",
      "Processed 7700/7999 users (96.3%) - Elapsed: 204.64s - Est. remaining: 1223.74s\n",
      "Processing batch 155: users 7701-7750 of 7999\n",
      "User 9690.0: 15538/15538 movies above threshold (100.00%)\n",
      "Processed 7750/7999 users (96.9%) - Elapsed: 205.88s - Est. remaining: 1025.27s\n",
      "Processing batch 156: users 7751-7800 of 7999\n",
      "User 9752.0: 15537/15538 movies above threshold (99.99%)\n",
      "Processed 7800/7999 users (97.5%) - Elapsed: 207.13s - Est. remaining: 824.36s\n",
      "Processing batch 157: users 7801-7850 of 7999\n",
      "User 9815.0: 15533/15538 movies above threshold (99.97%)\n",
      "Processed 7850/7999 users (98.1%) - Elapsed: 208.42s - Est. remaining: 621.09s\n",
      "Processing batch 158: users 7851-7900 of 7999\n",
      "User 9878.0: 15535/15538 movies above threshold (99.98%)\n",
      "Processed 7900/7999 users (98.8%) - Elapsed: 209.66s - Est. remaining: 415.12s\n",
      "Processing batch 159: users 7901-7950 of 7999\n",
      "User 9935.0: 15537/15538 movies above threshold (99.99%)\n",
      "Processed 7950/7999 users (99.4%) - Elapsed: 210.90s - Est. remaining: 206.68s\n",
      "Processing batch 160: users 7951-7999 of 7999\n",
      "User 10000.0: 15537/15538 movies above threshold (99.99%)\n",
      "Processed 7999/7999 users (100.0%) - Elapsed: 212.12s - Est. remaining: 0.00s\n",
      "\n",
      "Similarity calculation complete:\n",
      "Total users processed: 7999\n",
      "Total movies per user: 15538\n",
      "Average movies above threshold per user: 13928.96\n",
      "\n",
      "Sample user-movie similarities:\n",
      "User ID: 1.0\n",
      "Number of movies above threshold: 15538\n",
      "Top 5 most similar movies:\n",
      "  'Lord of the Rings: The Return of the King, The (2003)' (ID: 7153): 0.9276\n",
      "  'Time Bandits (1981)' (ID: 2968): 0.9179\n",
      "  'Harry Potter and the Prisoner of Azkaban (2004)' (ID: 8368): 0.9163\n",
      "  'Final Fantasy: The Spirits Within (2001)' (ID: 4446): 0.9087\n",
      "  'Hunger Games, The (2012)' (ID: 91500): 0.9084\n",
      "---\n",
      "User ID: 3.0\n",
      "Number of movies above threshold: 15536\n",
      "Top 5 most similar movies:\n",
      "  'Hunger Games, The (2012)' (ID: 91500): 0.9293\n",
      "  'Oblivion (2013)' (ID: 101864): 0.9268\n",
      "  'Tron: Legacy (2010)' (ID: 82461): 0.9185\n",
      "  'Knowing (2009)' (ID: 67197): 0.9174\n",
      "  'Gravity (2013)' (ID: 104841): 0.9151\n",
      "---\n",
      "User ID: 4.0\n",
      "Number of movies above threshold: 15537\n",
      "Top 5 most similar movies:\n",
      "  'Amazing Spider-Man, The (2012)' (ID: 95510): 0.9077\n",
      "  'Green Hornet, The (2011)' (ID: 83349): 0.9076\n",
      "  'Public Enemies (2009)' (ID: 69640): 0.9025\n",
      "  'Bishop's Wife, The (1947)' (ID: 4184): 0.8974\n",
      "  'Time Bandits (1981)' (ID: 2968): 0.8971\n",
      "---\n",
      "Calculated and saved similarities for 7999 users\n",
      "\n",
      "Similarity statistics:\n",
      "Average number of similar movies per user: 13928.96\n",
      "Min: 0, Max: 15538\n",
      "\n",
      "================================================================================\n",
      "STEP 8: RECOMMENDATION GENERATION\n",
      "================================================================================\n",
      "Generating top-20 recommendations for all users in batches...\n",
      "Processing batch 1: users 1-100 of 7999\n",
      "Processed 100/7999 users (1.3%) - Elapsed: 0.60s - Est. remaining: 47.58s\n",
      "Users with recommendations so far: 91\n",
      "Processing batch 2: users 101-200 of 7999\n",
      "Processed 200/7999 users (2.5%) - Elapsed: 1.24s - Est. remaining: 44.49s\n",
      "Users with recommendations so far: 181\n",
      "Processing batch 3: users 201-300 of 7999\n",
      "Processed 300/7999 users (3.8%) - Elapsed: 1.85s - Est. remaining: 42.40s\n",
      "Users with recommendations so far: 276\n",
      "Processing batch 4: users 301-400 of 7999\n",
      "Processed 400/7999 users (5.0%) - Elapsed: 2.41s - Est. remaining: 37.42s\n",
      "Users with recommendations so far: 364\n",
      "Processing batch 5: users 401-500 of 7999\n",
      "Processed 500/7999 users (6.3%) - Elapsed: 2.97s - Est. remaining: 38.58s\n",
      "Users with recommendations so far: 459\n",
      "Processing batch 6: users 501-600 of 7999\n",
      "Processed 600/7999 users (7.5%) - Elapsed: 3.60s - Est. remaining: 41.12s\n",
      "Users with recommendations so far: 553\n",
      "Processing batch 7: users 601-700 of 7999\n",
      "Processed 700/7999 users (8.8%) - Elapsed: 4.17s - Est. remaining: 37.03s\n",
      "Users with recommendations so far: 641\n",
      "Processing batch 8: users 701-800 of 7999\n",
      "Processed 800/7999 users (10.0%) - Elapsed: 4.76s - Est. remaining: 38.12s\n",
      "Users with recommendations so far: 732\n",
      "Processing batch 9: users 801-900 of 7999\n",
      "Processed 900/7999 users (11.3%) - Elapsed: 5.35s - Est. remaining: 37.22s\n",
      "Users with recommendations so far: 823\n",
      "Processing batch 10: users 901-1000 of 7999\n",
      "Processed 1000/7999 users (12.5%) - Elapsed: 5.96s - Est. remaining: 38.70s\n",
      "Users with recommendations so far: 918\n",
      "Processing batch 11: users 1001-1100 of 7999\n",
      "Processed 1100/7999 users (13.8%) - Elapsed: 6.54s - Est. remaining: 35.88s\n",
      "Users with recommendations so far: 1013\n",
      "Processing batch 12: users 1101-1200 of 7999\n",
      "Processed 1200/7999 users (15.0%) - Elapsed: 7.22s - Est. remaining: 42.14s\n",
      "Users with recommendations so far: 1107\n",
      "Processing batch 13: users 1201-1300 of 7999\n",
      "Processed 1300/7999 users (16.3%) - Elapsed: 7.86s - Est. remaining: 36.15s\n",
      "Users with recommendations so far: 1201\n",
      "Processing batch 14: users 1301-1400 of 7999\n",
      "Processed 1400/7999 users (17.5%) - Elapsed: 8.41s - Est. remaining: 32.32s\n",
      "Users with recommendations so far: 1290\n",
      "Processing batch 15: users 1401-1500 of 7999\n",
      "Processed 1500/7999 users (18.8%) - Elapsed: 8.97s - Est. remaining: 33.18s\n",
      "Users with recommendations so far: 1386\n",
      "Processing batch 16: users 1501-1600 of 7999\n",
      "Processed 1600/7999 users (20.0%) - Elapsed: 9.54s - Est. remaining: 32.07s\n",
      "Users with recommendations so far: 1477\n",
      "Processing batch 17: users 1601-1700 of 7999\n",
      "Processed 1700/7999 users (21.3%) - Elapsed: 10.11s - Est. remaining: 32.01s\n",
      "Users with recommendations so far: 1570\n",
      "Processing batch 18: users 1701-1800 of 7999\n",
      "Processed 1800/7999 users (22.5%) - Elapsed: 10.67s - Est. remaining: 30.91s\n",
      "Users with recommendations so far: 1663\n",
      "Processing batch 19: users 1801-1900 of 7999\n",
      "Processed 1900/7999 users (23.8%) - Elapsed: 11.25s - Est. remaining: 31.03s\n",
      "Users with recommendations so far: 1753\n",
      "Processing batch 20: users 1901-2000 of 7999\n",
      "Processed 2000/7999 users (25.0%) - Elapsed: 11.83s - Est. remaining: 31.08s\n",
      "Users with recommendations so far: 1848\n",
      "Processing batch 21: users 2001-2100 of 7999\n",
      "Processed 2100/7999 users (26.3%) - Elapsed: 12.39s - Est. remaining: 29.93s\n",
      "Users with recommendations so far: 1942\n",
      "Processing batch 22: users 2101-2200 of 7999\n",
      "Processed 2200/7999 users (27.5%) - Elapsed: 12.97s - Est. remaining: 29.53s\n",
      "Users with recommendations so far: 2036\n",
      "Processing batch 23: users 2201-2300 of 7999\n",
      "Processed 2300/7999 users (28.8%) - Elapsed: 13.54s - Est. remaining: 29.10s\n",
      "Users with recommendations so far: 2130\n",
      "Processing batch 24: users 2301-2400 of 7999\n",
      "Processed 2400/7999 users (30.0%) - Elapsed: 14.11s - Est. remaining: 28.39s\n",
      "Users with recommendations so far: 2221\n",
      "Processing batch 25: users 2401-2500 of 7999\n",
      "Processed 2500/7999 users (31.3%) - Elapsed: 14.68s - Est. remaining: 27.10s\n",
      "Users with recommendations so far: 2312\n",
      "Processing batch 26: users 2501-2600 of 7999\n",
      "Processed 2600/7999 users (32.5%) - Elapsed: 15.27s - Est. remaining: 28.69s\n",
      "Users with recommendations so far: 2407\n",
      "Processing batch 27: users 2601-2700 of 7999\n",
      "Processed 2700/7999 users (33.8%) - Elapsed: 15.87s - Est. remaining: 27.94s\n",
      "Users with recommendations so far: 2500\n",
      "Processing batch 28: users 2701-2800 of 7999\n",
      "Processed 2800/7999 users (35.0%) - Elapsed: 16.46s - Est. remaining: 27.10s\n",
      "Users with recommendations so far: 2593\n",
      "Processing batch 29: users 2801-2900 of 7999\n",
      "Processed 2900/7999 users (36.3%) - Elapsed: 17.03s - Est. remaining: 26.21s\n",
      "Users with recommendations so far: 2687\n",
      "Processing batch 30: users 2901-3000 of 7999\n",
      "Processed 3000/7999 users (37.5%) - Elapsed: 17.60s - Est. remaining: 25.35s\n",
      "Users with recommendations so far: 2777\n",
      "Processing batch 31: users 3001-3100 of 7999\n",
      "Processed 3100/7999 users (38.8%) - Elapsed: 18.14s - Est. remaining: 23.37s\n",
      "Users with recommendations so far: 2863\n",
      "Processing batch 32: users 3101-3200 of 7999\n",
      "Processed 3200/7999 users (40.0%) - Elapsed: 18.76s - Est. remaining: 26.76s\n",
      "Users with recommendations so far: 2957\n",
      "Processing batch 33: users 3201-3300 of 7999\n",
      "Processed 3300/7999 users (41.3%) - Elapsed: 19.36s - Est. remaining: 24.28s\n",
      "Users with recommendations so far: 3051\n",
      "Processing batch 34: users 3301-3400 of 7999\n",
      "Processed 3400/7999 users (42.5%) - Elapsed: 19.93s - Est. remaining: 23.04s\n",
      "Users with recommendations so far: 3138\n",
      "Processing batch 35: users 3401-3500 of 7999\n",
      "Processed 3500/7999 users (43.8%) - Elapsed: 20.52s - Est. remaining: 23.53s\n",
      "Users with recommendations so far: 3229\n",
      "Processing batch 36: users 3501-3600 of 7999\n",
      "Processed 3600/7999 users (45.0%) - Elapsed: 21.11s - Est. remaining: 23.46s\n",
      "Users with recommendations so far: 3323\n",
      "Processing batch 37: users 3601-3700 of 7999\n",
      "Processed 3700/7999 users (46.3%) - Elapsed: 21.71s - Est. remaining: 22.88s\n",
      "Users with recommendations so far: 3419\n",
      "Processing batch 38: users 3701-3800 of 7999\n",
      "Processed 3800/7999 users (47.5%) - Elapsed: 22.29s - Est. remaining: 21.70s\n",
      "Users with recommendations so far: 3510\n",
      "Processing batch 39: users 3801-3900 of 7999\n",
      "Processed 3900/7999 users (48.8%) - Elapsed: 22.90s - Est. remaining: 22.37s\n",
      "Users with recommendations so far: 3602\n",
      "Processing batch 40: users 3901-4000 of 7999\n",
      "Processed 4000/7999 users (50.0%) - Elapsed: 23.47s - Est. remaining: 20.07s\n",
      "Users with recommendations so far: 3695\n",
      "Processing batch 41: users 4001-4100 of 7999\n",
      "Processed 4100/7999 users (51.3%) - Elapsed: 24.06s - Est. remaining: 20.66s\n",
      "Users with recommendations so far: 3787\n",
      "Processing batch 42: users 4101-4200 of 7999\n",
      "Processed 4200/7999 users (52.5%) - Elapsed: 24.66s - Est. remaining: 20.01s\n",
      "Users with recommendations so far: 3882\n",
      "Processing batch 43: users 4201-4300 of 7999\n",
      "Processed 4300/7999 users (53.8%) - Elapsed: 25.23s - Est. remaining: 18.77s\n",
      "Users with recommendations so far: 3975\n",
      "Processing batch 44: users 4301-4400 of 7999\n",
      "Processed 4400/7999 users (55.0%) - Elapsed: 25.80s - Est. remaining: 18.03s\n",
      "Users with recommendations so far: 4069\n",
      "Processing batch 45: users 4401-4500 of 7999\n",
      "Processed 4500/7999 users (56.3%) - Elapsed: 26.40s - Est. remaining: 18.58s\n",
      "Users with recommendations so far: 4161\n",
      "Processing batch 46: users 4501-4600 of 7999\n",
      "Processed 4600/7999 users (57.5%) - Elapsed: 27.01s - Est. remaining: 18.63s\n",
      "Users with recommendations so far: 4259\n",
      "Processing batch 47: users 4601-4700 of 7999\n",
      "Processed 4700/7999 users (58.8%) - Elapsed: 27.61s - Est. remaining: 17.37s\n",
      "Users with recommendations so far: 4352\n",
      "Processing batch 48: users 4701-4800 of 7999\n",
      "Processed 4800/7999 users (60.0%) - Elapsed: 28.19s - Est. remaining: 16.40s\n",
      "Users with recommendations so far: 4441\n",
      "Processing batch 49: users 4801-4900 of 7999\n",
      "Processed 4900/7999 users (61.3%) - Elapsed: 28.76s - Est. remaining: 15.64s\n",
      "Users with recommendations so far: 4533\n",
      "Processing batch 50: users 4901-5000 of 7999\n",
      "Processed 5000/7999 users (62.5%) - Elapsed: 29.35s - Est. remaining: 15.41s\n",
      "Users with recommendations so far: 4625\n",
      "Processing batch 51: users 5001-5100 of 7999\n",
      "Processed 5100/7999 users (63.8%) - Elapsed: 29.99s - Est. remaining: 15.92s\n",
      "Users with recommendations so far: 4717\n",
      "Processing batch 52: users 5101-5200 of 7999\n",
      "Processed 5200/7999 users (65.0%) - Elapsed: 30.67s - Est. remaining: 16.67s\n",
      "Users with recommendations so far: 4809\n",
      "Processing batch 53: users 5201-5300 of 7999\n",
      "Processed 5300/7999 users (66.3%) - Elapsed: 31.30s - Est. remaining: 14.89s\n",
      "Users with recommendations so far: 4900\n",
      "Processing batch 54: users 5301-5400 of 7999\n",
      "Processed 5400/7999 users (67.5%) - Elapsed: 31.97s - Est. remaining: 14.80s\n",
      "Users with recommendations so far: 4990\n",
      "Processing batch 55: users 5401-5500 of 7999\n",
      "Processed 5500/7999 users (68.8%) - Elapsed: 32.62s - Est. remaining: 14.36s\n",
      "Users with recommendations so far: 5083\n",
      "Processing batch 56: users 5501-5600 of 7999\n",
      "Processed 5600/7999 users (70.0%) - Elapsed: 33.28s - Est. remaining: 14.32s\n",
      "Users with recommendations so far: 5175\n",
      "Processing batch 57: users 5601-5700 of 7999\n",
      "Processed 5700/7999 users (71.3%) - Elapsed: 34.07s - Est. remaining: 15.77s\n",
      "Users with recommendations so far: 5265\n",
      "Processing batch 58: users 5701-5800 of 7999\n",
      "Processed 5800/7999 users (72.5%) - Elapsed: 34.73s - Est. remaining: 12.53s\n",
      "Users with recommendations so far: 5359\n",
      "Processing batch 59: users 5801-5900 of 7999\n",
      "Processed 5900/7999 users (73.8%) - Elapsed: 35.41s - Est. remaining: 12.22s\n",
      "Users with recommendations so far: 5450\n",
      "Processing batch 60: users 5901-6000 of 7999\n",
      "Processed 6000/7999 users (75.0%) - Elapsed: 36.04s - Est. remaining: 11.15s\n",
      "Users with recommendations so far: 5548\n",
      "Processing batch 61: users 6001-6100 of 7999\n",
      "Processed 6100/7999 users (76.3%) - Elapsed: 36.64s - Est. remaining: 9.76s\n",
      "Users with recommendations so far: 5642\n",
      "Processing batch 62: users 6101-6200 of 7999\n",
      "Processed 6200/7999 users (77.5%) - Elapsed: 37.22s - Est. remaining: 8.80s\n",
      "Users with recommendations so far: 5730\n",
      "Processing batch 63: users 6201-6300 of 7999\n",
      "Processed 6300/7999 users (78.8%) - Elapsed: 37.85s - Est. remaining: 9.25s\n",
      "Users with recommendations so far: 5825\n",
      "Processing batch 64: users 6301-6400 of 7999\n",
      "Processed 6400/7999 users (80.0%) - Elapsed: 38.45s - Est. remaining: 8.39s\n",
      "Users with recommendations so far: 5917\n",
      "Processing batch 65: users 6401-6500 of 7999\n",
      "Processed 6500/7999 users (81.3%) - Elapsed: 39.02s - Est. remaining: 7.29s\n",
      "Users with recommendations so far: 6009\n",
      "Processing batch 66: users 6501-6600 of 7999\n",
      "Processed 6600/7999 users (82.5%) - Elapsed: 39.65s - Est. remaining: 7.72s\n",
      "Users with recommendations so far: 6107\n",
      "Processing batch 67: users 6601-6700 of 7999\n",
      "Processed 6700/7999 users (83.8%) - Elapsed: 40.28s - Est. remaining: 7.19s\n",
      "Users with recommendations so far: 6202\n",
      "Processing batch 68: users 6701-6800 of 7999\n",
      "Processed 6800/7999 users (85.0%) - Elapsed: 40.92s - Est. remaining: 6.69s\n",
      "Users with recommendations so far: 6298\n",
      "Processing batch 69: users 6801-6900 of 7999\n",
      "Processed 6900/7999 users (86.3%) - Elapsed: 41.52s - Est. remaining: 5.47s\n",
      "Users with recommendations so far: 6390\n",
      "Processing batch 70: users 6901-7000 of 7999\n",
      "Processed 7000/7999 users (87.5%) - Elapsed: 42.15s - Est. remaining: 5.28s\n",
      "Users with recommendations so far: 6481\n",
      "Processing batch 71: users 7001-7100 of 7999\n",
      "Processed 7100/7999 users (88.8%) - Elapsed: 42.83s - Est. remaining: 5.29s\n",
      "Users with recommendations so far: 6575\n",
      "Processing batch 72: users 7101-7200 of 7999\n",
      "Processed 7200/7999 users (90.0%) - Elapsed: 43.55s - Est. remaining: 5.03s\n",
      "Users with recommendations so far: 6671\n",
      "Processing batch 73: users 7201-7300 of 7999\n",
      "Processed 7300/7999 users (91.3%) - Elapsed: 44.28s - Est. remaining: 4.29s\n",
      "Users with recommendations so far: 6764\n",
      "Processing batch 74: users 7301-7400 of 7999\n",
      "Processed 7400/7999 users (92.5%) - Elapsed: 44.89s - Est. remaining: 3.04s\n",
      "Users with recommendations so far: 6850\n",
      "Processing batch 75: users 7401-7500 of 7999\n",
      "Processed 7500/7999 users (93.8%) - Elapsed: 45.59s - Est. remaining: 3.10s\n",
      "Users with recommendations so far: 6947\n",
      "Processing batch 76: users 7501-7600 of 7999\n",
      "Processed 7600/7999 users (95.0%) - Elapsed: 46.25s - Est. remaining: 2.21s\n",
      "Users with recommendations so far: 7039\n",
      "Processing batch 77: users 7601-7700 of 7999\n",
      "Processed 7700/7999 users (96.3%) - Elapsed: 46.85s - Est. remaining: 1.55s\n",
      "Users with recommendations so far: 7126\n",
      "Processing batch 78: users 7701-7800 of 7999\n",
      "Processed 7800/7999 users (97.5%) - Elapsed: 47.45s - Est. remaining: 1.01s\n",
      "Users with recommendations so far: 7218\n",
      "Processing batch 79: users 7801-7900 of 7999\n",
      "Processed 7900/7999 users (98.8%) - Elapsed: 48.07s - Est. remaining: 0.52s\n",
      "Users with recommendations so far: 7309\n",
      "Processing batch 80: users 7901-7999 of 7999\n",
      "Processed 7999/7999 users (100.0%) - Elapsed: 48.71s - Est. remaining: 0.00s\n",
      "Users with recommendations so far: 7404\n",
      "\n",
      "Recommendation generation complete:\n",
      "Users with recommendations: 7404/7999 (92.6%)\n",
      "Total recommendations generated: 147592\n",
      "Average recommendations per user: 19.93\n",
      "\n",
      "Sample recommendations for 3 users:\n",
      "User ID: 1.0\n",
      "Top 5 recommended movies:\n",
      "  1. 'Hunger Games, The (2012)' (ID: 91500): 0.9084\n",
      "  2. 'Hellboy II: The Golden Army (2008)' (ID: 57640): 0.9069\n",
      "  3. 'Amazing Spider-Man, The (2012)' (ID: 95510): 0.9053\n",
      "  4. 'Talented Mr. Ripley, The (1999)' (ID: 3176): 0.9030\n",
      "  5. 'Hellboy (2004)' (ID: 7373): 0.9025\n",
      "---\n",
      "User ID: 3.0\n",
      "Top 5 recommended movies:\n",
      "  1. 'Hunger Games, The (2012)' (ID: 91500): 0.9293\n",
      "  2. 'Oblivion (2013)' (ID: 101864): 0.9268\n",
      "  3. 'Tron: Legacy (2010)' (ID: 82461): 0.9185\n",
      "  4. 'Knowing (2009)' (ID: 67197): 0.9174\n",
      "  5. 'Gravity (2013)' (ID: 104841): 0.9151\n",
      "---\n",
      "User ID: 4.0\n",
      "Top 5 recommended movies:\n",
      "  1. 'Amazing Spider-Man, The (2012)' (ID: 95510): 0.9077\n",
      "  2. 'Green Hornet, The (2011)' (ID: 83349): 0.9076\n",
      "  3. 'Public Enemies (2009)' (ID: 69640): 0.9025\n",
      "  4. 'Bishop's Wife, The (1947)' (ID: 4184): 0.8974\n",
      "  5. 'Time Bandits (1981)' (ID: 2968): 0.8971\n",
      "---\n",
      "Processed recommendation chunk 1: users 1-1000 of 7404\n",
      "Processed recommendation chunk 2: users 1001-2000 of 7404\n",
      "Processed recommendation chunk 3: users 2001-3000 of 7404\n",
      "Processed recommendation chunk 4: users 3001-4000 of 7404\n",
      "Processed recommendation chunk 5: users 4001-5000 of 7404\n",
      "Processed recommendation chunk 6: users 5001-6000 of 7404\n",
      "Processed recommendation chunk 7: users 6001-7000 of 7404\n",
      "Processed recommendation chunk 8: users 7001-7404 of 7404\n",
      "Saved recommendation chunk 1: recommendations 1-10000 of 147592\n",
      "Saved recommendation chunk 2: recommendations 10001-20000 of 147592\n",
      "Saved recommendation chunk 3: recommendations 20001-30000 of 147592\n",
      "Saved recommendation chunk 4: recommendations 30001-40000 of 147592\n",
      "Saved recommendation chunk 5: recommendations 40001-50000 of 147592\n",
      "Saved recommendation chunk 6: recommendations 50001-60000 of 147592\n",
      "Saved recommendation chunk 7: recommendations 60001-70000 of 147592\n",
      "Saved recommendation chunk 8: recommendations 70001-80000 of 147592\n",
      "Saved recommendation chunk 9: recommendations 80001-90000 of 147592\n",
      "Saved recommendation chunk 10: recommendations 90001-100000 of 147592\n",
      "Saved recommendation chunk 11: recommendations 100001-110000 of 147592\n",
      "Saved recommendation chunk 12: recommendations 110001-120000 of 147592\n",
      "Saved recommendation chunk 13: recommendations 120001-130000 of 147592\n",
      "Saved recommendation chunk 14: recommendations 130001-140000 of 147592\n",
      "Saved recommendation chunk 15: recommendations 140001-147592 of 147592\n",
      "Saved recommendations to CSV file with 147592 entries\n",
      "\n",
      "================================================================================\n",
      "STEP 9: MODEL EVALUATION\n",
      "================================================================================\n",
      "Running evaluation with RMSE and MAE metrics...\n",
      "Evaluating recommendation model using RMSE and MAE with batching...\n",
      "Users in test set: 2000\n",
      "Users in training set: 8000\n",
      "Users to evaluate (intersection): 0\n",
      "Using user-based split - no common users between train and test.\n",
      "Evaluating using average rating for all predictions instead.\n",
      "\n",
      "Evaluation results using average rating baseline:\n",
      "Total predictions: 301199\n",
      "RMSE: 1.0382\n",
      "MAE: 0.8301\n",
      "\n",
      "Stored evaluation metrics:\n",
      "  rmse: 1.038200124778843\n",
      "  mae: 0.8300724034642937\n",
      "  num_predictions: 301199\n",
      "  evaluation_method: average_rating_baseline\n",
      "Saved evaluation metrics to CSV files\n",
      "\n",
      "================================================================================\n",
      "SUMMARY OF CONTENT-BASED RECOMMENDATION SYSTEM\n",
      "================================================================================\n",
      "\n",
      "Data Information:\n",
      "- Processed 15597 movie feature records\n",
      "- Vocabulary size: 56636 unique words\n",
      "- Generated feature vectors for 15538 movies\n",
      "- Generated feature vectors for 7999 users\n",
      "- Average similar movies per user: 13928.96\n",
      "- Average recommendations per user: 19.93\n",
      "\n",
      "Performance Metrics:\n",
      "- RMSE: 1.0382\n",
      "- MAE: 0.8301\n",
      "- Total predictions: 301199\n",
      "\n",
      "Advantages of this approach:\n",
      "- Log-Likelihood identifies more meaningful words compared to TF-IDF\n",
      "- Word2Vec captures semantic relationships between words\n",
      "- Handles new movies effectively (cold start for items)\n",
      "- Generates personalized recommendations based on content preferences\n",
      "- Doesn't require item-item similarity calculations\n",
      "- Memory-optimized batch processing prevents RAM overflow during long runs\n",
      "\n",
      "Saved Files:\n",
      "- content_based_evaluation.csv (0.00 MB)\n",
      "- content_based_recommendations.csv (8.62 MB)\n",
      "- content_based_recommendations.pkl (2.25 MB)\n",
      "- corpus_word_counts.pkl (0.83 MB)\n",
      "- movie_id_to_idx.pkl (0.10 MB)\n",
      "- movie_ll_values.pkl (8.09 MB)\n",
      "- movie_vectors.pkl (6.47 MB)\n",
      "- user_id_to_idx.pkl (0.17 MB)\n",
      "- user_movie_similarities.pkl (1328.46 MB)\n",
      "- user_vectors.pkl (3.45 MB)\n",
      "- word2vec_model (8.38 MB)\n",
      "\n",
      "Final memory usage: 6503.32 MB\n",
      "\n",
      "Content-Based Filtering Model Successfully Implemented!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "import logging\n",
    "import heapq\n",
    "from datetime import datetime\n",
    "from collections import Counter, defaultdict\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "import math\n",
    "from gensim.models import Word2Vec\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import ast  # To safely evaluate string representations of lists\n",
    "import sys\n",
    "import gc  # Add garbage collector for memory management\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CONTENT-BASED MOVIE RECOMMENDATION SYSTEM WITH LOG-LIKELIHOOD AND WORD2VEC\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Set paths\n",
    "input_path = \"./\"  # Current directory where stage1.py saved the files\n",
    "output_path = \"./rec/content-recommendations\"\n",
    "top_n = 20\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)\n",
    "\n",
    "# # Initialize NLTK tools\n",
    "# nltk.download('punkt', quiet=True)\n",
    "# nltk.download('stopwords', quiet=True)\n",
    "# nltk.download('wordnet', quiet=True)\n",
    "# stop_words = set(stopwords.words('english'))\n",
    "# lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Model parameters/\n",
    "similarity_threshold = 0.3  # Minimum similarity to consider\n",
    "word2vec_dim = 100  # Dimensionality of Word2Vec embeddings\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 1: DATA LOADING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "def load_data():\n",
    "    \"\"\"Load processed data from stage1.py\"\"\"\n",
    "    print(\"Loading processed data from stage1.py...\")\n",
    "    \n",
    "    # Data containers\n",
    "    data = {}\n",
    "    \n",
    "    # Load movie features\n",
    "    movie_features_path = os.path.join(input_path, './processed/processed_movie_features.csv')\n",
    "    if os.path.exists(movie_features_path):\n",
    "        # First, load without the tokens column to save memory\n",
    "        data['movie_features'] = pd.read_csv(movie_features_path)\n",
    "        # Convert string representation of tokens and top_keywords back to lists\n",
    "        data['movie_features']['tokens'] = data['movie_features']['tokens'].apply(\n",
    "            lambda x: ast.literal_eval(x) if isinstance(x, str) else []\n",
    "        )\n",
    "        data['movie_features']['top_keywords'] = data['movie_features']['top_keywords'].apply(\n",
    "            lambda x: ast.literal_eval(x) if isinstance(x, str) else []\n",
    "        )\n",
    "        print(f\"Loaded features for {len(data['movie_features'])} movies\")\n",
    "        print(\"\\nSample of movie features data:\")\n",
    "        print(data['movie_features'][['movieId', 'title', 'top_keywords']].head(3))\n",
    "        \n",
    "        # Print token statistics\n",
    "        token_lengths = [len(tokens) for tokens in data['movie_features']['tokens']]\n",
    "        print(f\"\\nAverage token count per movie: {np.mean(token_lengths):.2f}\")\n",
    "        print(f\"Min token count: {min(token_lengths)}, Max token count: {max(token_lengths)}\")\n",
    "    else:\n",
    "        print(f\"Error: Movie features not found at {movie_features_path}\")\n",
    "        sys.exit(1)\n",
    "    \n",
    "    # Load normalized ratings\n",
    "    ratings_path = os.path.join(input_path, './processed/normalized_ratings.csv')\n",
    "    if os.path.exists(ratings_path):\n",
    "        # Read in chunks to save memory\n",
    "        chunk_size = 100000  # Adjust based on dataset size\n",
    "        chunks = []\n",
    "        for chunk in pd.read_csv(ratings_path, chunksize=chunk_size):\n",
    "            chunks.append(chunk)\n",
    "        data['ratings'] = pd.concat(chunks)\n",
    "        print(f\"\\nLoaded {len(data['ratings'])} normalized ratings\")\n",
    "        print(\"\\nSample of normalized ratings data:\")\n",
    "        print(data['ratings'].head(3))\n",
    "        \n",
    "        # Print rating statistics\n",
    "        print(f\"\\nNumber of unique users: {data['ratings']['userId'].nunique()}\")\n",
    "        print(f\"Number of unique movies: {data['ratings']['movieId'].nunique()}\")\n",
    "        print(f\"Rating sparsity: {(1 - len(data['ratings']) / (data['ratings']['userId'].nunique() * data['ratings']['movieId'].nunique())) * 100:.4f}%\")\n",
    "    else:\n",
    "        print(f\"Error: Normalized ratings not found at {ratings_path}\")\n",
    "        sys.exit(1)\n",
    "    \n",
    "    # Create training and testing sets with 80-20 split\n",
    "    if 'ratings' in data:\n",
    "        # Sort by timestamp if available to ensure reproducibility\n",
    "        if 'timestamp' in data['ratings'].columns:\n",
    "            data['ratings'] = data['ratings'].sort_values('timestamp')\n",
    "        \n",
    "        # Group by user to ensure each user has both training and testing data\n",
    "        user_groups = data['ratings'].groupby('userId')\n",
    "        train_chunks = []\n",
    "        test_chunks = []\n",
    "        \n",
    "        user_count = 0\n",
    "        total_users = len(user_groups)\n",
    "        \n",
    "        for user_id, group in user_groups:\n",
    "            n = len(group)\n",
    "            split_idx = int(n * 0.8)\n",
    "            train_chunks.append(group.iloc[:split_idx])\n",
    "            test_chunks.append(group.iloc[split_idx:])\n",
    "            \n",
    "            user_count += 1\n",
    "            # Process in batches to avoid excessive memory usage\n",
    "            if len(train_chunks) >= 1000 or user_count == total_users:\n",
    "                gc.collect()  # Force garbage collection\n",
    "        \n",
    "        # Get all unique user IDs\n",
    "        all_user_ids = data['ratings']['userId'].unique()\n",
    "\n",
    "        # Split users into train (80%) and test (20%) sets\n",
    "        np.random.seed(42)  # For reproducibility\n",
    "        np.random.shuffle(all_user_ids)\n",
    "\n",
    "        split_idx = int(len(all_user_ids) * 0.8)\n",
    "        train_users = all_user_ids[:split_idx]\n",
    "        test_users = all_user_ids[split_idx:]\n",
    "\n",
    "        # Split ratings based on user assignments\n",
    "        data['train_ratings'] = data['ratings'][data['ratings']['userId'].isin(train_users)]\n",
    "        data['test_ratings'] = data['ratings'][data['ratings']['userId'].isin(test_users)]\n",
    "        \n",
    "        # Free memory\n",
    "        del train_chunks, test_chunks\n",
    "        gc.collect()\n",
    "        \n",
    "        print(f\"\\nSplit ratings into {len(data['train_ratings'])} training and {len(data['test_ratings'])} testing samples\")\n",
    "        print(f\"Training set covers {data['train_ratings']['userId'].nunique()} users and {data['train_ratings']['movieId'].nunique()} movies\")\n",
    "        print(f\"Testing set covers {data['test_ratings']['userId'].nunique()} users and {data['test_ratings']['movieId'].nunique()} movies\")\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Load the data\n",
    "data = load_data()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 2: CORPUS ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Build corpus word counts from movie features\n",
    "if 'movie_features' in data:\n",
    "    print(\"Building vocabulary and word frequency counts...\")\n",
    "    \n",
    "    corpus_word_counts = Counter()\n",
    "    \n",
    "    # Process in batches to avoid memory spikes\n",
    "    batch_size = 1000\n",
    "    total_movies = len(data['movie_features'])\n",
    "    \n",
    "    for i in range(0, total_movies, batch_size):\n",
    "        batch_end = min(i + batch_size, total_movies)\n",
    "        batch = data['movie_features'].iloc[i:batch_end]\n",
    "        \n",
    "        for tokens in batch['tokens']:\n",
    "            corpus_word_counts.update(tokens)\n",
    "        \n",
    "        # Log progress\n",
    "        print(f\"Processed {batch_end}/{total_movies} movies ({batch_end/total_movies*100:.1f}%)\")\n",
    "    \n",
    "    data['corpus_word_counts'] = corpus_word_counts\n",
    "    \n",
    "    # Save corpus word counts\n",
    "    with open(os.path.join(output_path, 'corpus_word_counts.pkl'), 'wb') as f:\n",
    "        pickle.dump(corpus_word_counts, f)\n",
    "    \n",
    "    print(f\"Built vocabulary with {len(corpus_word_counts)} unique words\")\n",
    "    print(f\"Total words in corpus: {sum(corpus_word_counts.values())}\")\n",
    "    \n",
    "    # Display top 20 most common words\n",
    "    print(\"\\nTop 20 most common words in the corpus:\")\n",
    "    for word, count in corpus_word_counts.most_common(20):\n",
    "        print(f\"'{word}': {count}\")\n",
    "\n",
    "    # Clear memory\n",
    "    gc.collect()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 3: LOG-LIKELIHOOD CALCULATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "def calculate_log_likelihood(movie_features, corpus_word_counts, batch_size=100):\n",
    "    \"\"\"Calculate Log-Likelihood values for words in each movie in batches\"\"\"\n",
    "    print(\"Calculating Log-Likelihood values for all movies in batches...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Calculate total corpus size\n",
    "    total_corpus_size = sum(corpus_word_counts.values())\n",
    "    print(f\"Total corpus size: {total_corpus_size} words\")\n",
    "    \n",
    "    # Initialize container for movie features\n",
    "    movie_ll_values = {}\n",
    "    \n",
    "    # Process each movie document in batches\n",
    "    total_movies = len(movie_features)\n",
    "    \n",
    "    for batch_start in range(0, total_movies, batch_size):\n",
    "        batch_end = min(batch_start + batch_size, total_movies)\n",
    "        print(f\"Processing batch {batch_start//batch_size + 1}: movies {batch_start+1}-{batch_end} of {total_movies}\")\n",
    "        \n",
    "        # Get batch of movies\n",
    "        batch = movie_features.iloc[batch_start:batch_end]\n",
    "        \n",
    "        for _, row in batch.iterrows():\n",
    "            movie_id = row['movieId']\n",
    "            tokens = row['tokens']\n",
    "            \n",
    "            if not tokens:\n",
    "                continue\n",
    "            \n",
    "            # Count word occurrences in this movie\n",
    "            movie_word_counts = Counter(tokens)\n",
    "            movie_size = sum(movie_word_counts.values())\n",
    "            \n",
    "            # Calculate Log-Likelihood for each word\n",
    "            movie_ll_values[movie_id] = {}\n",
    "            \n",
    "            for word, count in movie_word_counts.items():\n",
    "                # Observed frequencies\n",
    "                a = count  # Occurrences in this movie\n",
    "                b = corpus_word_counts[word] - count  # Occurrences in other movies\n",
    "                c = movie_size  # Total words in this movie\n",
    "                d = total_corpus_size - movie_size  # Total words in other movies\n",
    "                \n",
    "                # Expected counts based on corpus distribution\n",
    "                e1 = c * (a + b) / (c + d)\n",
    "                e2 = d * (a + b) / (c + d)\n",
    "                \n",
    "                # Log-Likelihood calculation\n",
    "                ll = 0\n",
    "                if a > 0 and e1 > 0:\n",
    "                    ll += a * math.log(a / e1)\n",
    "                if b > 0 and e2 > 0:\n",
    "                    ll += b * math.log(b / e2)\n",
    "                \n",
    "                ll = 2 * ll\n",
    "                movie_ll_values[movie_id][word] = ll\n",
    "        \n",
    "        # Log progress and elapsed time\n",
    "        elapsed = time.time() - start_time\n",
    "        progress = batch_end / total_movies * 100\n",
    "        remaining = elapsed / (batch_end - batch_start) * (total_movies - batch_end) if batch_end < total_movies else 0\n",
    "        print(f\"Progress: {progress:.1f}% - Elapsed: {elapsed:.2f}s - Est. remaining: {remaining:.2f}s\")\n",
    "        \n",
    "        # Force garbage collection after each batch\n",
    "        gc.collect()\n",
    "    \n",
    "    # Show sample LL values for a movie\n",
    "    if movie_ll_values:\n",
    "        sample_movie_id = next(iter(movie_ll_values.keys()))\n",
    "        sample_movie_title = movie_features[movie_features['movieId'] == sample_movie_id]['title'].values[0]\n",
    "        print(f\"\\nSample Log-Likelihood values for movie '{sample_movie_title}' (ID: {sample_movie_id}):\")\n",
    "        \n",
    "        # Get top 10 words by LL value\n",
    "        top_ll_words = sorted(movie_ll_values[sample_movie_id].items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "        for word, ll_value in top_ll_words:\n",
    "            print(f\"Word: '{word}', LL Value: {ll_value:.2f}\")\n",
    "    \n",
    "    return movie_ll_values\n",
    "\n",
    "# Calculate Log-Likelihood if movie features are available\n",
    "if 'movie_features' in data and 'corpus_word_counts' in data:\n",
    "    movie_ll_values = calculate_log_likelihood(data['movie_features'], data['corpus_word_counts'], batch_size=100)\n",
    "    data['movie_ll_values'] = movie_ll_values\n",
    "    \n",
    "    # Save Log-Likelihood values\n",
    "    with open(os.path.join(output_path, 'movie_ll_values.pkl'), 'wb') as f:\n",
    "        pickle.dump(movie_ll_values, f)\n",
    "    \n",
    "    print(f\"Calculated Log-Likelihood values for {len(movie_ll_values)} movies\")\n",
    "    \n",
    "    # Calculate average number of words with high LL values\n",
    "    high_ll_counts = []\n",
    "    for movie_id, ll_dict in movie_ll_values.items():\n",
    "        high_ll_words = [word for word, value in ll_dict.items() if value > 10]  # Threshold of 10\n",
    "        high_ll_counts.append(len(high_ll_words))\n",
    "    \n",
    "    print(f\"Average number of words with LL > 10 per movie: {np.mean(high_ll_counts):.2f}\")\n",
    "    print(f\"Min: {min(high_ll_counts)}, Max: {max(high_ll_counts)}\")\n",
    "    \n",
    "    # Free memory\n",
    "    gc.collect()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 4: WORD2VEC MODEL TRAINING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "def train_word2vec(movie_features, vector_size=100, batch_size=1000):\n",
    "    \"\"\"Train Word2Vec model on movie tokens with memory optimization\"\"\"\n",
    "    print(f\"Training Word2Vec model with {vector_size} dimensions...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Extract token lists from movie features in batches\n",
    "    tokenized_corpus = []\n",
    "    total_movies = len(movie_features)\n",
    "    \n",
    "    for i in range(0, total_movies, batch_size):\n",
    "        batch_end = min(i + batch_size, total_movies)\n",
    "        batch = movie_features.iloc[i:batch_end]\n",
    "        \n",
    "        batch_tokens = list(batch['tokens'])\n",
    "        tokenized_corpus.extend(batch_tokens)\n",
    "        \n",
    "        # Log progress\n",
    "        print(f\"Loaded tokens from {batch_end}/{total_movies} movies ({batch_end/total_movies*100:.1f}%)\")\n",
    "    \n",
    "    # Print corpus statistics\n",
    "    total_tokens = sum(len(tokens) for tokens in tokenized_corpus)\n",
    "    print(f\"Training corpus size: {total_tokens} tokens from {len(tokenized_corpus)} documents\")\n",
    "    \n",
    "    # Train Word2Vec model using CBOW approach with memory optimization\n",
    "    print(\"Starting Word2Vec training (this may take a few minutes)...\")\n",
    "    word2vec_model = Word2Vec(\n",
    "        sentences=tokenized_corpus,\n",
    "        vector_size=vector_size,\n",
    "        window=5,\n",
    "        min_count=5,\n",
    "        workers=4,\n",
    "        epochs=25,  # Reduced from 50 to save memory\n",
    "        sg=1  # CBOW model\n",
    "    )\n",
    "    \n",
    "    # Free memory - no longer need the full corpus\n",
    "    del tokenized_corpus\n",
    "    gc.collect()\n",
    "    \n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"Word2Vec training completed in {elapsed:.2f} seconds\")\n",
    "    \n",
    "    # Print model statistics\n",
    "    vocab_size = len(word2vec_model.wv)\n",
    "    print(f\"Word2Vec model vocabulary size: {vocab_size} words\")\n",
    "    \n",
    "    # Show some example vectors for common words\n",
    "    print(\"\\nExample word vectors from the trained model:\")\n",
    "    common_words = [word for word, _ in data['corpus_word_counts'].most_common(10)]\n",
    "    for word in common_words:\n",
    "        if word in word2vec_model.wv:\n",
    "            # Show just the first 5 dimensions of the vector\n",
    "            print(f\"'{word}': {word2vec_model.wv[word][:5]}...\")\n",
    "    \n",
    "    # Show some word similarities\n",
    "    if len(word2vec_model.wv) > 0:\n",
    "        print(\"\\nExample word similarities:\")\n",
    "        try:\n",
    "            # Try some movie-related terms\n",
    "            for word in ['action', 'love', 'hero', 'villain']:\n",
    "                if word in word2vec_model.wv:\n",
    "                    similar_words = word2vec_model.wv.most_similar(word, topn=5)\n",
    "                    print(f\"Words similar to '{word}': {similar_words}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Could not compute word similarities: {str(e)}\")\n",
    "    \n",
    "    return word2vec_model\n",
    "\n",
    "# Train Word2Vec if movie features are available\n",
    "if 'movie_features' in data:\n",
    "    word2vec_model = train_word2vec(data['movie_features'], word2vec_dim)\n",
    "    data['word2vec_model'] = word2vec_model\n",
    "    \n",
    "    # Save Word2Vec model\n",
    "    word2vec_path = os.path.join(output_path, 'word2vec_model')\n",
    "    word2vec_model.save(word2vec_path)\n",
    "    \n",
    "    print(f\"Trained and saved Word2Vec model with {len(word2vec_model.wv)} words\")\n",
    "    \n",
    "    # Free memory\n",
    "    gc.collect()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 5: MOVIE VECTOR GENERATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "def generate_movie_vectors(movie_ll_values, word2vec_model, movie_features, batch_size=100):\n",
    "    \"\"\"Generate movie feature vectors using Log-Likelihood and Word2Vec in batches\"\"\"\n",
    "    print(\"Generating movie feature vectors using Log-Likelihood + Word2Vec in batches...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    movie_vectors = {}\n",
    "    successful_vectors = 0\n",
    "    no_words_found = 0\n",
    "    low_ll_sum = 0\n",
    "    \n",
    "    # Get movie IDs from LL values\n",
    "    movie_ids = list(movie_ll_values.keys())\n",
    "    total_movies = len(movie_ids)\n",
    "    \n",
    "    # Process movies in batches\n",
    "    for batch_start in range(0, total_movies, batch_size):\n",
    "        batch_end = min(batch_start + batch_size, total_movies)\n",
    "        batch_movie_ids = movie_ids[batch_start:batch_end]\n",
    "        \n",
    "        print(f\"Processing batch {batch_start//batch_size + 1}: movies {batch_start+1}-{batch_end} of {total_movies}\")\n",
    "        \n",
    "        for movie_id in batch_movie_ids:\n",
    "            # Sort words by LL value and select top 200\n",
    "            ll_values = movie_ll_values[movie_id]\n",
    "            top_words = sorted(ll_values.items(), key=lambda x: x[1], reverse=True)[:200]\n",
    "            \n",
    "            if not top_words:\n",
    "                no_words_found += 1\n",
    "                continue\n",
    "            \n",
    "            # Combine Word2Vec vectors weighted by Log-Likelihood values\n",
    "            weighted_vectors = []\n",
    "            ll_sum = 0\n",
    "            words_used = 0\n",
    "            \n",
    "            for word, ll_value in top_words:\n",
    "                if ll_value <= 0:\n",
    "                    continue\n",
    "                \n",
    "                if word in word2vec_model.wv:\n",
    "                    weighted_vectors.append(word2vec_model.wv[word] * ll_value)\n",
    "                    ll_sum += ll_value\n",
    "                    words_used += 1\n",
    "            \n",
    "            if weighted_vectors and ll_sum > 0:\n",
    "                # Calculate the weighted average vector\n",
    "                movie_vector = np.sum(weighted_vectors, axis=0) / ll_sum\n",
    "                \n",
    "                # Normalize to unit length\n",
    "                norm = np.linalg.norm(movie_vector)\n",
    "                if norm > 0:\n",
    "                    movie_vector = movie_vector / norm\n",
    "                    movie_vectors[movie_id] = movie_vector\n",
    "                    successful_vectors += 1\n",
    "            else:\n",
    "                low_ll_sum += 1\n",
    "        \n",
    "        # Log progress and elapsed time\n",
    "        elapsed = time.time() - start_time\n",
    "        progress = batch_end / total_movies * 100\n",
    "        remaining = elapsed / (batch_end - batch_start) * (total_movies - batch_end) if batch_end < total_movies else 0\n",
    "        print(f\"Progress: {progress:.1f}% - Elapsed: {elapsed:.2f}s - Est. remaining: {remaining:.2f}s\")\n",
    "        print(f\"Successfully created vectors: {successful_vectors}/{batch_end}\")\n",
    "        \n",
    "        # Force garbage collection after each batch\n",
    "        gc.collect()\n",
    "    \n",
    "    print(f\"\\nVector generation complete:\")\n",
    "    print(f\"Successfully created vectors: {successful_vectors}/{total_movies} ({successful_vectors/total_movies*100:.1f}%)\")\n",
    "    print(f\"Movies with no words found: {no_words_found}\")\n",
    "    print(f\"Movies with too low LL sum: {low_ll_sum}\")\n",
    "    \n",
    "    # Display sample movie vectors\n",
    "    if movie_vectors:\n",
    "        print(\"\\nSample movie vectors:\")\n",
    "        for movie_id in list(movie_vectors.keys())[:3]:\n",
    "            movie_title = movie_features[movie_features['movieId'] == movie_id]['title'].values[0]\n",
    "            vector = movie_vectors[movie_id]\n",
    "            print(f\"Movie: '{movie_title}' (ID: {movie_id})\")\n",
    "            print(f\"Vector shape: {vector.shape}\")\n",
    "            print(f\"Vector norm: {np.linalg.norm(vector):.4f}\")\n",
    "            print(f\"First 5 dimensions: {vector[:5]}\")\n",
    "            print(\"---\")\n",
    "    \n",
    "    return movie_vectors\n",
    "\n",
    "# Generate movie vectors if Word2Vec and LL values are available\n",
    "if 'word2vec_model' in data and 'movie_ll_values' in data:\n",
    "    movie_vectors = generate_movie_vectors(\n",
    "        data['movie_ll_values'], \n",
    "        data['word2vec_model'],\n",
    "        data['movie_features'],\n",
    "        batch_size=100\n",
    "    )\n",
    "    data['movie_vectors'] = movie_vectors\n",
    "    \n",
    "    # Save movie vectors\n",
    "    with open(os.path.join(output_path, 'movie_vectors.pkl'), 'wb') as f:\n",
    "        pickle.dump(movie_vectors, f)\n",
    "    \n",
    "    # Create movie ID to index mapping\n",
    "    movie_id_to_idx = {movie_id: i for i, movie_id in enumerate(movie_vectors.keys())}\n",
    "    data['movie_id_to_idx'] = movie_id_to_idx\n",
    "    \n",
    "    # Save the mapping\n",
    "    with open(os.path.join(output_path, 'movie_id_to_idx.pkl'), 'wb') as f:\n",
    "        pickle.dump(movie_id_to_idx, f)\n",
    "    \n",
    "    print(f\"Generated and saved feature vectors for {len(movie_vectors)} movies\")\n",
    "    \n",
    "    # Calculate and display vector statistics\n",
    "    vector_norms = [np.linalg.norm(v) for v in movie_vectors.values()]\n",
    "    print(f\"\\nVector statistics:\")\n",
    "    print(f\"Average vector norm: {np.mean(vector_norms):.4f}\")\n",
    "    print(f\"Vector dimensionality: {word2vec_dim}\")\n",
    "    \n",
    "    # Free memory\n",
    "    gc.collect()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 6: USER VECTOR GENERATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "def generate_user_vectors(movie_vectors, train_ratings, batch_size=100):\n",
    "    \"\"\"Generate user feature vectors based on rated movies and their content in batches\"\"\"\n",
    "    print(\"Generating user feature vectors based on movie ratings in batches...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    user_vectors = {}\n",
    "    successful_vectors = 0\n",
    "    no_ratings_found = 0\n",
    "    no_vectors_for_movies = 0\n",
    "    low_weight_sum = 0\n",
    "    \n",
    "    # Create a rating cache for quick lookups\n",
    "    # This can be memory intensive for large datasets, but speeds up processing\n",
    "    user_ratings_dict = {}\n",
    "    print(\"Creating user ratings lookup dictionary...\")\n",
    "    \n",
    "    # Process in chunks to avoid memory issues\n",
    "    for _, row in train_ratings.iterrows():\n",
    "        user_id = row['userId']\n",
    "        movie_id = row['movieId']\n",
    "        rating = row['rating']\n",
    "        \n",
    "        if user_id not in user_ratings_dict:\n",
    "            user_ratings_dict[user_id] = {}\n",
    "        \n",
    "        user_ratings_dict[user_id][movie_id] = rating\n",
    "    \n",
    "    # Process each user\n",
    "    user_ids = list(user_ratings_dict.keys())\n",
    "    total_users = len(user_ids)\n",
    "    print(f\"Processing {total_users} users in batches...\")\n",
    "    \n",
    "    # Process users in batches\n",
    "    for batch_start in range(0, total_users, batch_size):\n",
    "        batch_end = min(batch_start + batch_size, total_users)\n",
    "        batch_user_ids = user_ids[batch_start:batch_end]\n",
    "        \n",
    "        print(f\"Processing batch {batch_start//batch_size + 1}: users {batch_start+1}-{batch_end} of {total_users}\")\n",
    "        \n",
    "        for user_id in batch_user_ids:\n",
    "            # Get user ratings\n",
    "            user_ratings = user_ratings_dict[user_id]\n",
    "            \n",
    "            if len(user_ratings) == 0:\n",
    "                no_ratings_found += 1\n",
    "                continue\n",
    "            \n",
    "            weighted_vectors = []\n",
    "            weight_sum = 0\n",
    "            movies_with_vectors = 0\n",
    "            movies_without_vectors = 0\n",
    "            \n",
    "            for movie_id, rating in user_ratings.items():\n",
    "                # Center rating at 3.0 as described in the papers\n",
    "                weight = rating - 3.0\n",
    "                \n",
    "                # Skip if movie vector is not available\n",
    "                if movie_id not in movie_vectors:\n",
    "                    movies_without_vectors += 1\n",
    "                    continue\n",
    "                else:\n",
    "                    movies_with_vectors += 1\n",
    "                \n",
    "                if weight != 0:\n",
    "                    weighted_vectors.append(movie_vectors[movie_id] * weight)\n",
    "                    weight_sum += abs(weight)\n",
    "            \n",
    "            if weighted_vectors and weight_sum > 0:\n",
    "                # Calculate the weighted average vector\n",
    "                user_vector = np.sum(weighted_vectors, axis=0) / weight_sum\n",
    "                \n",
    "                # Normalize to unit length\n",
    "                norm = np.linalg.norm(user_vector)\n",
    "                if norm > 0:\n",
    "                    user_vector = user_vector / norm\n",
    "                    user_vectors[user_id] = user_vector\n",
    "                    successful_vectors += 1\n",
    "            else:\n",
    "                low_weight_sum += 1\n",
    "        \n",
    "        # Log progress\n",
    "        elapsed = time.time() - start_time\n",
    "        progress = batch_end / total_users * 100\n",
    "        remaining = elapsed / (batch_end - batch_start) * (total_users - batch_end) if batch_end < total_users else 0\n",
    "        print(f\"Progress: {progress:.1f}% - Elapsed: {elapsed:.2f}s - Est. remaining: {remaining:.2f}s\")\n",
    "        print(f\"Successfully created vectors: {successful_vectors}\")\n",
    "        \n",
    "        # Force garbage collection after each batch\n",
    "        gc.collect()\n",
    "    \n",
    "    print(f\"\\nUser vector generation complete:\")\n",
    "    print(f\"Successfully created vectors: {successful_vectors}/{total_users} ({successful_vectors/total_users*100:.1f}%)\")\n",
    "    print(f\"Users with no ratings: {no_ratings_found}\")\n",
    "    print(f\"Users with no vectorized movies: {no_vectors_for_movies}\")\n",
    "    print(f\"Users with too low weight sum: {low_weight_sum}\")\n",
    "    \n",
    "    # Free memory\n",
    "    del user_ratings_dict\n",
    "    gc.collect()\n",
    "    \n",
    "    # Display sample user vectors\n",
    "    if user_vectors:\n",
    "        print(\"\\nSample user vectors:\")\n",
    "        for user_id in list(user_vectors.keys())[:3]:\n",
    "            vector = user_vectors[user_id]\n",
    "            user_rating_count = len([r for r in train_ratings[train_ratings['userId'] == user_id]])\n",
    "            print(f\"User ID: {user_id}\")\n",
    "            print(f\"Number of ratings: {user_rating_count}\")\n",
    "            print(f\"Vector shape: {vector.shape}\")\n",
    "            print(f\"Vector norm: {np.linalg.norm(vector):.4f}\")\n",
    "            print(f\"First 5 dimensions: {vector[:5]}\")\n",
    "            print(\"---\")\n",
    "    \n",
    "    return user_vectors\n",
    "\n",
    "# Generate user vectors if movie vectors and training ratings are available\n",
    "if 'movie_vectors' in data and 'train_ratings' in data:\n",
    "    user_vectors = generate_user_vectors(data['movie_vectors'], data['train_ratings'], batch_size=100)\n",
    "    data['user_vectors'] = user_vectors\n",
    "    \n",
    "    # Save user vectors\n",
    "    with open(os.path.join(output_path, 'user_vectors.pkl'), 'wb') as f:\n",
    "        pickle.dump(user_vectors, f)\n",
    "    \n",
    "    # Create user ID to index mapping\n",
    "    user_id_to_idx = {user_id: i for i, user_id in enumerate(user_vectors.keys())}\n",
    "    data['user_id_to_idx'] = user_id_to_idx\n",
    "    \n",
    "    # Save the mapping\n",
    "    with open(os.path.join(output_path, 'user_id_to_idx.pkl'), 'wb') as f:\n",
    "        pickle.dump(user_id_to_idx, f)\n",
    "    \n",
    "    print(f\"Generated and saved feature vectors for {len(user_vectors)} users\")\n",
    "    \n",
    "    # Calculate and display vector statistics\n",
    "    vector_norms = [np.linalg.norm(v) for v in user_vectors.values()]\n",
    "    print(f\"\\nVector statistics:\")\n",
    "    print(f\"Average vector norm: {np.mean(vector_norms):.4f}\")\n",
    "    print(f\"Vector dimensionality: {word2vec_dim}\")\n",
    "    \n",
    "    # Free memory\n",
    "    gc.collect()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 7: USER-MOVIE SIMILARITY CALCULATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "def calculate_user_movie_similarity(user_vectors, movie_vectors, threshold=0.3, batch_size=50):\n",
    "    \"\"\"Calculate similarity between users and movies in batches\"\"\"\n",
    "    print(f\"Calculating user-movie similarity with threshold {threshold} in batches...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Store similarities in a dictionary of dictionaries\n",
    "    # {user_id: {movie_id: similarity_score}}\n",
    "    user_movie_similarities = {}\n",
    "    \n",
    "    # Get all user IDs\n",
    "    user_ids = list(user_vectors.keys())\n",
    "    total_users = len(user_ids)\n",
    "    total_movies = len(movie_vectors)\n",
    "    \n",
    "    # Process users in batches\n",
    "    for batch_start in range(0, total_users, batch_size):\n",
    "        batch_end = min(batch_start + batch_size, total_users)\n",
    "        batch_user_ids = user_ids[batch_start:batch_end]\n",
    "        \n",
    "        print(f\"Processing batch {batch_start//batch_size + 1}: users {batch_start+1}-{batch_end} of {total_users}\")\n",
    "        \n",
    "        for user_id in batch_user_ids:\n",
    "            user_vector = user_vectors[user_id]\n",
    "            user_sims = {}\n",
    "            user_similarities = 0\n",
    "            user_above_threshold = 0\n",
    "            \n",
    "            # Calculate similarity for all movies at once (vectorized)\n",
    "            # Convert both user and movie vectors to arrays for faster computation\n",
    "            user_vector_array = np.array(user_vector).reshape(1, -1)\n",
    "            \n",
    "            # Process movies in chunks to avoid memory issues\n",
    "            movie_ids = list(movie_vectors.keys())\n",
    "            movie_chunk_size = 1000  # Adjust based on memory availability\n",
    "            \n",
    "            for movie_chunk_start in range(0, len(movie_ids), movie_chunk_size):\n",
    "                movie_chunk_end = min(movie_chunk_start + movie_chunk_size, len(movie_ids))\n",
    "                chunk_movie_ids = movie_ids[movie_chunk_start:movie_chunk_end]\n",
    "                \n",
    "                # Create array of movie vectors for this chunk\n",
    "                movie_vectors_array = np.array([movie_vectors[mid] for mid in chunk_movie_ids])\n",
    "                \n",
    "                # Calculate cosine similarity in a vectorized way\n",
    "                similarities = np.dot(user_vector_array, movie_vectors_array.T)[0]\n",
    "                \n",
    "                # Filter by threshold and store\n",
    "                for i, sim in enumerate(similarities):\n",
    "                    if sim > threshold:\n",
    "                        movie_id = chunk_movie_ids[i]\n",
    "                        user_sims[movie_id] = float(sim)  # Convert to native Python float\n",
    "                        user_above_threshold += 1\n",
    "                    user_similarities += 1\n",
    "            \n",
    "            user_movie_similarities[user_id] = user_sims\n",
    "            \n",
    "            # Log progress for this user\n",
    "            if len(batch_user_ids) <= 10 or (user_id == batch_user_ids[-1]):\n",
    "                print(f\"User {user_id}: {user_above_threshold}/{total_movies} movies above threshold ({user_above_threshold/total_movies*100:.2f}%)\")\n",
    "        \n",
    "        # Log progress for this batch\n",
    "        elapsed = time.time() - start_time\n",
    "        progress = batch_end / total_users * 100\n",
    "        remaining = (elapsed / (batch_end - batch_start)) * (total_users - batch_end) if batch_end < total_users else 0\n",
    "        print(f\"Processed {batch_end}/{total_users} users ({progress:.1f}%) - Elapsed: {elapsed:.2f}s - Est. remaining: {remaining:.2f}s\")\n",
    "        \n",
    "        # Force garbage collection after each batch\n",
    "        gc.collect()\n",
    "    \n",
    "    avg_above_threshold = sum(len(sims) for sims in user_movie_similarities.values()) / len(user_movie_similarities) if user_movie_similarities else 0\n",
    "    \n",
    "    print(f\"\\nSimilarity calculation complete:\")\n",
    "    print(f\"Total users processed: {len(user_movie_similarities)}\")\n",
    "    print(f\"Total movies per user: {total_movies}\")\n",
    "    print(f\"Average movies above threshold per user: {avg_above_threshold:.2f}\")\n",
    "    \n",
    "    # Display sample user similarities\n",
    "    if user_movie_similarities:\n",
    "        print(\"\\nSample user-movie similarities:\")\n",
    "        for user_id in list(user_movie_similarities.keys())[:3]:\n",
    "            sims = user_movie_similarities[user_id]\n",
    "            print(f\"User ID: {user_id}\")\n",
    "            print(f\"Number of movies above threshold: {len(sims)}\")\n",
    "            if sims:\n",
    "                top_movies = sorted(sims.items(), key=lambda x: x[1], reverse=True)[:5]\n",
    "                print(\"Top 5 most similar movies:\")\n",
    "                for movie_id, sim in top_movies:\n",
    "                    movie_title = data['movie_features'][data['movie_features']['movieId'] == movie_id]['title'].values[0] if 'movie_features' in data else f\"Movie {movie_id}\"\n",
    "                    print(f\"  '{movie_title}' (ID: {movie_id}): {sim:.4f}\")\n",
    "            print(\"---\")\n",
    "    \n",
    "    return user_movie_similarities\n",
    "# Calculate similarities if user and movie vectors are available\n",
    "if 'user_vectors' in data and 'movie_vectors' in data:\n",
    "    user_movie_similarities = calculate_user_movie_similarity(\n",
    "        data['user_vectors'], \n",
    "        data['movie_vectors'], \n",
    "        threshold=similarity_threshold,\n",
    "        batch_size=50\n",
    "    )\n",
    "    data['user_movie_similarities'] = user_movie_similarities\n",
    "    \n",
    "    # Save the similarities\n",
    "    with open(os.path.join(output_path, 'user_movie_similarities.pkl'), 'wb') as f:\n",
    "        pickle.dump(user_movie_similarities, f)\n",
    "    \n",
    "    print(f\"Calculated and saved similarities for {len(user_movie_similarities)} users\")\n",
    "    \n",
    "    # Calculate and display similarity statistics\n",
    "    similarity_counts = [len(sims) for sims in user_movie_similarities.values()]\n",
    "    print(f\"\\nSimilarity statistics:\")\n",
    "    print(f\"Average number of similar movies per user: {np.mean(similarity_counts):.2f}\")\n",
    "    print(f\"Min: {min(similarity_counts)}, Max: {max(similarity_counts)}\")\n",
    "    \n",
    "    # Free memory\n",
    "    gc.collect()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 8: RECOMMENDATION GENERATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "def get_user_rated_movies(user_id, train_ratings, cached_rated_movies=None):\n",
    "    \"\"\"Get the set of movies already rated by a user with caching for efficiency\"\"\"\n",
    "    # Initialize cache if not provided\n",
    "    if cached_rated_movies is None:\n",
    "        cached_rated_movies = {}\n",
    "        \n",
    "    # Return from cache if available\n",
    "    if user_id in cached_rated_movies:\n",
    "        return cached_rated_movies[user_id]\n",
    "    \n",
    "    # Get from ratings dataframe\n",
    "    if train_ratings is None:\n",
    "        return set()\n",
    "    \n",
    "    user_data = train_ratings[train_ratings['userId'] == user_id]\n",
    "    rated_movies = set(user_data['movieId'].values)\n",
    "    \n",
    "    # Cache for future use\n",
    "    cached_rated_movies[user_id] = rated_movies\n",
    "    \n",
    "    return rated_movies\n",
    "\n",
    "def get_top_n_recommendations(user_id, user_movie_similarities, train_ratings, cached_rated_movies=None, n=10):\n",
    "    \"\"\"\n",
    "    Generate top-N recommendations for a specific user\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    user_id : int\n",
    "        The user ID to generate recommendations for\n",
    "    user_movie_similarities : dict\n",
    "        Dictionary of user-movie similarities\n",
    "    train_ratings : pd.DataFrame\n",
    "        DataFrame of user ratings\n",
    "    cached_rated_movies : dict, optional\n",
    "        Cache of user rated movies for efficiency\n",
    "    n : int, optional\n",
    "        Number of recommendations to generate\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    list of tuples\n",
    "        (movie_id, similarity_score) pairs sorted by similarity in descending order\n",
    "    \"\"\"\n",
    "    if user_id not in user_movie_similarities:\n",
    "        return []\n",
    "    \n",
    "    # Get movies already rated by the user (using cache)\n",
    "    rated_movies = get_user_rated_movies(user_id, train_ratings, cached_rated_movies)\n",
    "    \n",
    "    # Get user's similarities\n",
    "    user_sims = user_movie_similarities[user_id]\n",
    "    \n",
    "    # Filter out already rated movies and sort by similarity\n",
    "    candidates = [(movie_id, sim) for movie_id, sim in user_sims.items() \n",
    "                 if movie_id not in rated_movies]\n",
    "    \n",
    "    # Sort by similarity (descending)\n",
    "    recommendations = sorted(candidates, key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Return top N\n",
    "    return recommendations[:n]\n",
    "\n",
    "def predict_rating(user_id, movie_id, user_movie_similarities, train_ratings):\n",
    "    \"\"\"\n",
    "    Predict a user's rating for a movie\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    user_id : int\n",
    "        The user ID\n",
    "    movie_id : int\n",
    "        The movie ID\n",
    "    user_movie_similarities : dict\n",
    "        Dictionary of user-movie similarities\n",
    "    train_ratings : pd.DataFrame\n",
    "        DataFrame of user ratings\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    float\n",
    "        Predicted rating (0.5-5.0 scale)\n",
    "    \"\"\"\n",
    "    # If user not in similarity matrix, return average rating\n",
    "    if user_id not in user_movie_similarities:\n",
    "        return 3.0\n",
    "    \n",
    "    # Get user's average rating from training data\n",
    "    user_train = train_ratings[train_ratings['userId'] == user_id]\n",
    "    user_avg_rating = user_train['rating'].mean() if len(user_train) > 0 else 3.0\n",
    "    \n",
    "    # If movie not in similarity matrix, return user's average rating\n",
    "    if movie_id not in user_movie_similarities[user_id]:\n",
    "        return user_avg_rating\n",
    "    \n",
    "    # Convert similarity score to rating prediction\n",
    "    # Similarity is in range [0,1], convert to rating range [0.5,5]\n",
    "    sim_score = user_movie_similarities[user_id][movie_id]\n",
    "    predicted_rating = 0.5 + 4.5 * sim_score\n",
    "    \n",
    "    return predicted_rating\n",
    "\n",
    "def generate_recommendations_for_all_users(user_movie_similarities, train_ratings, movie_features, n=10, batch_size=100):\n",
    "    \"\"\"Generate recommendations for all users with memory efficiency in mind\"\"\"\n",
    "    print(f\"Generating top-{n} recommendations for all users in batches...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Create a shared cache for rated movies\n",
    "    cached_rated_movies = {}\n",
    "    \n",
    "    # Get all user IDs\n",
    "    user_ids = list(user_movie_similarities.keys())\n",
    "    total_users = len(user_ids)\n",
    "    \n",
    "    all_recommendations = {}\n",
    "    users_with_recommendations = 0\n",
    "    \n",
    "    # Process users in batches\n",
    "    for batch_start in range(0, total_users, batch_size):\n",
    "        batch_end = min(batch_start + batch_size, total_users)\n",
    "        batch_user_ids = user_ids[batch_start:batch_end]\n",
    "        \n",
    "        print(f\"Processing batch {batch_start//batch_size + 1}: users {batch_start+1}-{batch_end} of {total_users}\")\n",
    "        batch_start_time = time.time()\n",
    "        \n",
    "        for user_id in batch_user_ids:\n",
    "            recommendations = get_top_n_recommendations(\n",
    "                user_id, \n",
    "                user_movie_similarities, \n",
    "                train_ratings, \n",
    "                cached_rated_movies,\n",
    "                n\n",
    "            )\n",
    "            \n",
    "            if recommendations:\n",
    "                all_recommendations[user_id] = recommendations\n",
    "                users_with_recommendations += 1\n",
    "        \n",
    "        # Log progress after each batch\n",
    "        batch_time = time.time() - batch_start_time\n",
    "        elapsed = time.time() - start_time\n",
    "        progress = batch_end / total_users * 100\n",
    "        remaining = batch_time * ((total_users - batch_end) / len(batch_user_ids)) if batch_end < total_users else 0\n",
    "        \n",
    "        print(f\"Processed {batch_end}/{total_users} users ({progress:.1f}%) - Elapsed: {elapsed:.2f}s - Est. remaining: {remaining:.2f}s\")\n",
    "        print(f\"Users with recommendations so far: {users_with_recommendations}\")\n",
    "        \n",
    "        # Force garbage collection after each batch\n",
    "        gc.collect()\n",
    "    \n",
    "    # Calculate statistics\n",
    "    if all_recommendations:\n",
    "        total_recommendations = sum(len(recs) for recs in all_recommendations.values())\n",
    "        avg_recommendations = total_recommendations / users_with_recommendations if users_with_recommendations > 0 else 0\n",
    "        \n",
    "        print(f\"\\nRecommendation generation complete:\")\n",
    "        print(f\"Users with recommendations: {users_with_recommendations}/{total_users} ({users_with_recommendations/total_users*100:.1f}%)\")\n",
    "        print(f\"Total recommendations generated: {total_recommendations}\")\n",
    "        print(f\"Average recommendations per user: {avg_recommendations:.2f}\")\n",
    "    \n",
    "    # Display sample recommendations for a few users\n",
    "    if all_recommendations:\n",
    "        print(\"\\nSample recommendations for 3 users:\")\n",
    "        for user_id in list(all_recommendations.keys())[:3]:\n",
    "            print(f\"User ID: {user_id}\")\n",
    "            print(\"Top 5 recommended movies:\")\n",
    "            \n",
    "            for rank, (movie_id, score) in enumerate(all_recommendations[user_id][:5], 1):\n",
    "                movie_title = \"Unknown\"\n",
    "                if movie_features is not None:\n",
    "                    movie_row = movie_features[movie_features['movieId'] == movie_id]\n",
    "                    if not movie_row.empty and 'title' in movie_row.columns:\n",
    "                        movie_title = movie_row.iloc[0]['title']\n",
    "                print(f\"  {rank}. '{movie_title}' (ID: {movie_id}): {score:.4f}\")\n",
    "            print(\"---\")\n",
    "    \n",
    "    return all_recommendations\n",
    "\n",
    "# Generate recommendations if similarities are available\n",
    "if 'user_movie_similarities' in data and 'train_ratings' in data:\n",
    "    all_recommendations = generate_recommendations_for_all_users(\n",
    "        data['user_movie_similarities'], \n",
    "        data['train_ratings'],\n",
    "        data['movie_features'],\n",
    "        n=top_n,\n",
    "        batch_size=100\n",
    "    )\n",
    "    data['all_recommendations'] = all_recommendations\n",
    "    \n",
    "    # Save recommendations\n",
    "    with open(os.path.join(output_path, 'content_based_recommendations.pkl'), 'wb') as f:\n",
    "        pickle.dump(all_recommendations, f)\n",
    "    \n",
    "    # Also save in a more readable CSV format\n",
    "    recommendations_list = []\n",
    "    \n",
    "    # Process in chunks to avoid memory issues\n",
    "    chunk_size = 1000\n",
    "    user_ids = list(all_recommendations.keys())\n",
    "    total_users = len(user_ids)\n",
    "    \n",
    "    for chunk_start in range(0, total_users, chunk_size):\n",
    "        chunk_end = min(chunk_start + chunk_size, total_users)\n",
    "        user_chunk = user_ids[chunk_start:chunk_end]\n",
    "        \n",
    "        chunk_recommendations = []\n",
    "        for user_id in user_chunk:\n",
    "            for rank, (movie_id, score) in enumerate(all_recommendations[user_id], 1):\n",
    "                movie_title = \"Unknown\"\n",
    "                if 'movie_features' in data:\n",
    "                    movie_row = data['movie_features'][data['movie_features']['movieId'] == movie_id]\n",
    "                    if not movie_row.empty and 'title' in movie_row.columns:\n",
    "                        movie_title = movie_row.iloc[0]['title']\n",
    "                        \n",
    "                chunk_recommendations.append({\n",
    "                    'userId': user_id,\n",
    "                    'movieId': movie_id,\n",
    "                    'title': movie_title,\n",
    "                    'rank': rank,\n",
    "                    'similarity_score': score\n",
    "                })\n",
    "        \n",
    "        recommendations_list.extend(chunk_recommendations)\n",
    "        print(f\"Processed recommendation chunk {chunk_start//chunk_size + 1}: users {chunk_start+1}-{chunk_end} of {total_users}\")\n",
    "        gc.collect()\n",
    "    \n",
    "    if recommendations_list:\n",
    "        # Write CSV in chunks to avoid memory issues\n",
    "        chunk_size = 10000\n",
    "        total_recs = len(recommendations_list)\n",
    "        \n",
    "        for chunk_start in range(0, total_recs, chunk_size):\n",
    "            chunk_end = min(chunk_start + chunk_size, total_recs)\n",
    "            chunk = recommendations_list[chunk_start:chunk_end]\n",
    "            \n",
    "            chunk_df = pd.DataFrame(chunk)\n",
    "            \n",
    "            # For first chunk, write with header\n",
    "            if chunk_start == 0:\n",
    "                chunk_df.to_csv(os.path.join(output_path, 'content_based_recommendations.csv'), index=False, mode='w')\n",
    "            else:\n",
    "                # For subsequent chunks, append without header\n",
    "                chunk_df.to_csv(os.path.join(output_path, 'content_based_recommendations.csv'), index=False, mode='a', header=False)\n",
    "            \n",
    "            print(f\"Saved recommendation chunk {chunk_start//chunk_size + 1}: recommendations {chunk_start+1}-{chunk_end} of {total_recs}\")\n",
    "            \n",
    "        print(f\"Saved recommendations to CSV file with {total_recs} entries\")\n",
    "    \n",
    "    # Free memory\n",
    "    del recommendations_list\n",
    "    gc.collect()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 9: MODEL EVALUATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Thay Äá»i hÃ m evaluate_with_rmse_mae nhÆ° sau:\n",
    "def evaluate_with_rmse_mae(user_movie_similarities, train_ratings, test_ratings, batch_size=100):\n",
    "    \"\"\"\n",
    "    Evaluate the recommendations using RMSE and MAE with batching for memory efficiency\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    user_movie_similarities : dict\n",
    "        Dictionary of user-movie similarities\n",
    "    train_ratings : pd.DataFrame\n",
    "        DataFrame of training ratings\n",
    "    test_ratings : pd.DataFrame\n",
    "        DataFrame of test ratings\n",
    "    batch_size : int\n",
    "        Size of user batches to process\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary of evaluation metrics\n",
    "    \"\"\"\n",
    "    print(\"Evaluating recommendation model using RMSE and MAE with batching...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Láº¥y common users giá»¯a test_ratings vÃ  training users\n",
    "    test_users = set(test_ratings['userId'].unique())\n",
    "    train_users = set(train_ratings['userId'].unique())\n",
    "    users_to_evaluate = test_users.intersection(train_users)\n",
    "    \n",
    "    print(f\"Users in test set: {len(test_users)}\")\n",
    "    print(f\"Users in training set: {len(train_users)}\")\n",
    "    print(f\"Users to evaluate (intersection): {len(users_to_evaluate)}\")\n",
    "    \n",
    "    # Kiá»m tra náº¿u chÃºng ta Äang sá»­ dá»¥ng user-based split\n",
    "    if len(users_to_evaluate) == 0:\n",
    "        print(\"Using user-based split - no common users between train and test.\")\n",
    "        print(\"Evaluating using average rating for all predictions instead.\")\n",
    "        \n",
    "        # Láº¥y average rating tá»« training set\n",
    "        avg_rating = train_ratings['rating'].mean()\n",
    "        \n",
    "        # Äáº¿m sá» lÆ°á»£ng dá»± ÄoÃ¡n\n",
    "        total_predictions = len(test_ratings)\n",
    "        \n",
    "        # TÃ­nh MSE vÃ  MAE báº±ng cÃ¡ch dÃ¹ng average rating lÃ m dá»± ÄoÃ¡n\n",
    "        squared_errors_sum = ((test_ratings['rating'] - avg_rating) ** 2).sum()\n",
    "        absolute_errors_sum = (abs(test_ratings['rating'] - avg_rating)).sum()\n",
    "        \n",
    "        # TÃ­nh RMSE vÃ  MAE\n",
    "        overall_rmse = np.sqrt(squared_errors_sum / total_predictions)\n",
    "        overall_mae = absolute_errors_sum / total_predictions\n",
    "        \n",
    "        print(\"\\nEvaluation results using average rating baseline:\")\n",
    "        print(f\"Total predictions: {total_predictions}\")\n",
    "        print(f\"RMSE: {overall_rmse:.4f}\")\n",
    "        print(f\"MAE: {overall_mae:.4f}\")\n",
    "        \n",
    "        # Táº¡o metrics dictionary\n",
    "        metrics = {\n",
    "            'rmse': overall_rmse,\n",
    "            'mae': overall_mae,\n",
    "            'num_predictions': total_predictions,\n",
    "            'evaluation_method': 'average_rating_baseline'\n",
    "        }\n",
    "        \n",
    "        return metrics\n",
    "    \n",
    "    # Náº¿u cÃ³ common users, tiáº¿p tá»¥c vá»i cÃ¡ch ÄÃ¡nh giÃ¡ gá»c\n",
    "    # (Pháº§n code gá»c cá»§a báº¡n báº¯t Äáº§u tá»« ÄÃ¢y, giá»¯ nguyÃªn)\n",
    "    users_with_similarity = set(user_movie_similarities.keys())\n",
    "    users_in_test_with_similarity = users_to_evaluate.intersection(users_with_similarity)\n",
    "    \n",
    "    print(f\"Users in test set with similarity data: {len(users_in_test_with_similarity)}/{len(users_to_evaluate)} ({len(users_in_test_with_similarity)/len(users_to_evaluate)*100:.1f}%)\")\n",
    "    \n",
    "    # Track metrics in chunks instead of storing all predictions\n",
    "    squared_errors_sum = 0\n",
    "    absolute_errors_sum = 0\n",
    "    total_predictions = 0\n",
    "    users_evaluated = 0\n",
    "    \n",
    "    # Process users in batches\n",
    "    user_list = list(users_in_test_with_similarity)\n",
    "    for batch_start in range(0, len(user_list), batch_size):\n",
    "        batch_end = min(batch_start + batch_size, len(user_list))\n",
    "        batch_users = user_list[batch_start:batch_end]\n",
    "        \n",
    "        print(f\"Evaluating batch {batch_start//batch_size + 1}: users {batch_start+1}-{batch_end} of {len(user_list)}\")\n",
    "        batch_start_time = time.time()\n",
    "        \n",
    "        batch_squared_errors = 0\n",
    "        batch_absolute_errors = 0\n",
    "        batch_predictions = 0\n",
    "        \n",
    "        for user_id in batch_users:\n",
    "            # Get user test ratings\n",
    "            user_test = test_ratings[test_ratings['userId'] == user_id]\n",
    "            \n",
    "            if len(user_test) == 0:\n",
    "                continue\n",
    "            \n",
    "            # Get user's average rating from training data\n",
    "            user_train = train_ratings[train_ratings['userId'] == user_id]\n",
    "            user_avg_rating = user_train['rating'].mean() if len(user_train) > 0 else 3.0\n",
    "            \n",
    "            # Predict ratings for test items\n",
    "            for _, row in user_test.iterrows():\n",
    "                movie_id = row['movieId']\n",
    "                true_rating = row['rating']\n",
    "                \n",
    "                # Get similarity-based prediction\n",
    "                if movie_id in user_movie_similarities.get(user_id, {}):\n",
    "                    # Convert similarity score to rating prediction\n",
    "                    sim_score = user_movie_similarities[user_id][movie_id]\n",
    "                    predicted_rating = 0.5 + 4.5 * sim_score\n",
    "                else:\n",
    "                    # Use user's average rating as fallback\n",
    "                    predicted_rating = user_avg_rating\n",
    "                \n",
    "                # Calculate error\n",
    "                squared_error = (predicted_rating - true_rating) ** 2\n",
    "                absolute_error = abs(predicted_rating - true_rating)\n",
    "                \n",
    "                batch_squared_errors += squared_error\n",
    "                batch_absolute_errors += absolute_error\n",
    "                batch_predictions += 1\n",
    "            \n",
    "            users_evaluated += 1\n",
    "        \n",
    "        # Accumulate batch metrics\n",
    "        squared_errors_sum += batch_squared_errors\n",
    "        absolute_errors_sum += batch_absolute_errors\n",
    "        total_predictions += batch_predictions\n",
    "        \n",
    "        # Log progress\n",
    "        batch_time = time.time() - batch_start_time\n",
    "        elapsed = time.time() - start_time\n",
    "        progress = batch_end / len(user_list) * 100\n",
    "        remaining = batch_time * ((len(user_list) - batch_end) / len(batch_users)) if batch_end < len(user_list) else 0\n",
    "        \n",
    "        # Periodically calculate and log intermediate metrics\n",
    "        if batch_predictions > 0:\n",
    "            batch_rmse = np.sqrt(batch_squared_errors / batch_predictions)\n",
    "            batch_mae = batch_absolute_errors / batch_predictions\n",
    "            print(f\"Batch metrics - RMSE: {batch_rmse:.4f}, MAE: {batch_mae:.4f}, Predictions: {batch_predictions}\")\n",
    "        \n",
    "        print(f\"Processed {batch_end}/{len(user_list)} users ({progress:.1f}%) - Elapsed: {elapsed:.2f}s - Est. remaining: {remaining:.2f}s\")\n",
    "        \n",
    "        # Force garbage collection after each batch\n",
    "        gc.collect()\n",
    "    \n",
    "    # Calculate overall RMSE and MAE\n",
    "    if total_predictions > 0:\n",
    "        overall_rmse = np.sqrt(squared_errors_sum / total_predictions)\n",
    "        overall_mae = absolute_errors_sum / total_predictions\n",
    "    else:\n",
    "        overall_rmse = 0.0\n",
    "        overall_mae = 0.0\n",
    "    \n",
    "    print(\"\\nEvaluation results:\")\n",
    "    print(f\"Users evaluated: {users_evaluated}\")\n",
    "    print(f\"Total predictions: {total_predictions}\")\n",
    "    print(f\"RMSE: {overall_rmse:.4f}\")\n",
    "    print(f\"MAE: {overall_mae:.4f}\")\n",
    "    \n",
    "    # Create metrics dictionary\n",
    "    metrics = {\n",
    "        'rmse': overall_rmse,\n",
    "        'mae': overall_mae,\n",
    "        'num_users_evaluated': users_evaluated,\n",
    "        'num_predictions': total_predictions\n",
    "    }\n",
    "    \n",
    "    return metrics\n",
    "# Evaluate recommendations if test ratings are available\n",
    "if 'user_movie_similarities' in data and 'train_ratings' in data and 'test_ratings' in data:\n",
    "    # Call the new evaluation function\n",
    "    print(\"Running evaluation with RMSE and MAE metrics...\")\n",
    "    evaluation_metrics = evaluate_with_rmse_mae(\n",
    "        data['user_movie_similarities'],\n",
    "        data['train_ratings'],\n",
    "        data['test_ratings'],\n",
    "        batch_size=100\n",
    "    )\n",
    "    \n",
    "    # Store the metrics in the data dictionary\n",
    "    data['evaluation_metrics'] = evaluation_metrics\n",
    "    \n",
    "    # Print the metrics to confirm they're stored correctly\n",
    "    print(\"\\nStored evaluation metrics:\")\n",
    "    for key, value in evaluation_metrics.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "    \n",
    "    # Save metrics to CSV\n",
    "    evaluation_results = pd.DataFrame([evaluation_metrics])\n",
    "    evaluation_results.to_csv(os.path.join(output_path, 'content_based_evaluation.csv'), index=False)\n",
    "    \n",
    "    # Also save user metrics\n",
    "    if 'user_metrics' in data:\n",
    "        user_metrics_df = pd.DataFrame.from_dict(data['user_metrics'], orient='index')\n",
    "        user_metrics_df.reset_index(inplace=True)\n",
    "        user_metrics_df.rename(columns={'index': 'userId'}, inplace=True)\n",
    "        user_metrics_df.to_csv(os.path.join(output_path, 'user_metrics.csv'), index=False)\n",
    "    \n",
    "    print(f\"Saved evaluation metrics to CSV files\")\n",
    "    \n",
    "    # Free memory\n",
    "    gc.collect()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SUMMARY OF CONTENT-BASED RECOMMENDATION SYSTEM\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Data information\n",
    "print(\"\\nData Information:\")\n",
    "if 'movie_features' in data:\n",
    "    print(f\"- Processed {len(data['movie_features'])} movie feature records\")\n",
    "if 'corpus_word_counts' in data:\n",
    "    print(f\"- Vocabulary size: {len(data['corpus_word_counts'])} unique words\")\n",
    "if 'movie_vectors' in data:\n",
    "    print(f\"- Generated feature vectors for {len(data['movie_vectors'])} movies\")\n",
    "if 'user_vectors' in data:\n",
    "    print(f\"- Generated feature vectors for {len(data['user_vectors'])} users\")\n",
    "if 'user_movie_similarities' in data:\n",
    "    avg_similar_movies = sum(len(sims) for sims in data['user_movie_similarities'].values()) / len(data['user_movie_similarities'])\n",
    "    print(f\"- Average similar movies per user: {avg_similar_movies:.2f}\")\n",
    "if 'all_recommendations' in data:\n",
    "    avg_recommendations = sum(len(recs) for recs in data['all_recommendations'].values()) / len(data['all_recommendations'])\n",
    "    print(f\"- Average recommendations per user: {avg_recommendations:.2f}\")\n",
    "\n",
    "# Safely display evaluation metrics without assuming specific keys\n",
    "print(\"\\nPerformance Metrics:\")\n",
    "if 'evaluation_metrics' in data:\n",
    "    # Safely check for each expected metric\n",
    "    if 'rmse' in data['evaluation_metrics']:\n",
    "        print(f\"- RMSE: {data['evaluation_metrics']['rmse']:.4f}\")\n",
    "    if 'mae' in data['evaluation_metrics']:\n",
    "        print(f\"- MAE: {data['evaluation_metrics']['mae']:.4f}\")\n",
    "    if 'num_users_evaluated' in data['evaluation_metrics']:\n",
    "        print(f\"- Users evaluated: {data['evaluation_metrics']['num_users_evaluated']}\")\n",
    "    if 'num_predictions' in data['evaluation_metrics']:\n",
    "        print(f\"- Total predictions: {data['evaluation_metrics']['num_predictions']}\")\n",
    "else:\n",
    "    print(\"- No evaluation metrics available\")\n",
    "\n",
    "# Model advantages\n",
    "print(\"\\nAdvantages of this approach:\")\n",
    "print(\"- Log-Likelihood identifies more meaningful words compared to TF-IDF\")\n",
    "print(\"- Word2Vec captures semantic relationships between words\")\n",
    "print(\"- Handles new movies effectively (cold start for items)\")\n",
    "print(\"- Generates personalized recommendations based on content preferences\")\n",
    "print(\"- Doesn't require item-item similarity calculations\")\n",
    "print(\"- Memory-optimized batch processing prevents RAM overflow during long runs\")\n",
    "\n",
    "# Saved files\n",
    "print(\"\\nSaved Files:\")\n",
    "for file in os.listdir(output_path):\n",
    "    file_path = os.path.join(output_path, file)\n",
    "    file_size = os.path.getsize(file_path) / (1024 * 1024)  # Size in MB\n",
    "    print(f\"- {file} ({file_size:.2f} MB)\")\n",
    "\n",
    "# Memory usage information\n",
    "import psutil\n",
    "process = psutil.Process(os.getpid())\n",
    "memory_usage = process.memory_info().rss / (1024 * 1024)  # MB\n",
    "print(f\"\\nFinal memory usage: {memory_usage:.2f} MB\")\n",
    "\n",
    "print(\"\\nContent-Based Filtering Model Successfully Implemented!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
